<!DOCTYPE HTML>
<html lang="en" class="sidebar-visible no-js light">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Systems Librarianship</title>
        <meta name="robots" content="noindex" />


        <!-- Custom HTML head -->
        
        <meta name="description" content="Entry level book on systems librarianship.">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->

    </head>
    <body>
    <div id="body-container">
        <!-- Provide site root to javascript -->
        <script>
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            var html = document.querySelector('html');
            var sidebar = null;
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded "><a href="p1-systems-librarianship.html"><strong aria-hidden="true">1.</strong> Systems Librarianship</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="1a-history-linux-unix.html"><strong aria-hidden="true">1.1.</strong> History of Unix and Linux</a></li><li class="chapter-item expanded "><a href="1b-what-is-linux.html"><strong aria-hidden="true">1.2.</strong> What is Linux?</a></li><li class="chapter-item expanded "><a href="1c-what-is-sysadmin.html"><strong aria-hidden="true">1.3.</strong> What is Systems Administration?</a></li><li class="chapter-item expanded "><a href="1d-what-is-syslib.html"><strong aria-hidden="true">1.4.</strong> What is Systems Librarianship?</a></li></ol></li><li class="chapter-item expanded "><a href="p2-project-management.html"><strong aria-hidden="true">2.</strong> Project Management</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="2a-using-gcloud-virtual-machines.html"><strong aria-hidden="true">2.1.</strong> Using gcloud for Virtual Machines</a></li><li class="chapter-item expanded "><a href="2b-using-git-github-for-documentation.html"><strong aria-hidden="true">2.2.</strong> Using Git and GitHub for Documentation</a></li></ol></li><li class="chapter-item expanded "><a href="p3-learning-the-command-line.html"><strong aria-hidden="true">3.</strong> Learning the Command Line</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="3a-learn-the-cli.html"><strong aria-hidden="true">3.1.</strong> Learn the CLI</a></li><li class="chapter-item expanded "><a href="3b-learn-nano.html"><strong aria-hidden="true">3.2.</strong> Using the Nano Text Editor</a></li><li class="chapter-item expanded "><a href="3c-searching-with-grep.html"><strong aria-hidden="true">3.3.</strong> Searching with grep</a></li><li class="chapter-item expanded "><a href="3d-managing-software.html"><strong aria-hidden="true">3.4.</strong> Managing Software</a></li><li class="chapter-item expanded "><a href="3e-library-search.html"><strong aria-hidden="true">3.5.</strong> Library Search</a></li></ol></li><li class="chapter-item expanded "><a href="p4-creating-a-lamp-server.html"><strong aria-hidden="true">4.</strong> Creating a LAMP Server</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="4a-installing-the-apache-web-server.html"><strong aria-hidden="true">4.1.</strong> Installing the Apache Web Server</a></li><li class="chapter-item expanded "><a href="4b-installing-configuring-php.html"><strong aria-hidden="true">4.2.</strong> Installing and Configuring PHP</a></li><li class="chapter-item expanded "><a href="4c-installing-configuring-mysql.html"><strong aria-hidden="true">4.3.</strong> Installing and Configuring MySQL</a></li><li class="chapter-item expanded "><a href="4d-basic-opac.html"><strong aria-hidden="true">4.4.</strong> Creating a Bare Bones OPAC</a></li><li class="chapter-item expanded "><a href="4e-basic-opac-admin.html"><strong aria-hidden="true">4.5.</strong> Creating a Bare Bones Cataloging Module</a></li></ol></li><li class="chapter-item expanded "><a href="p5-installing-content-management-systems.html"><strong aria-hidden="true">5.</strong> Installing Content Management Systems</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="5a-install-wordpress.html"><strong aria-hidden="true">5.1.</strong> Install Wordpress</a></li><li class="chapter-item expanded "><a href="5b-install-omeka.html"><strong aria-hidden="true">5.2.</strong> Install Omeka</a></li></ol></li><li class="chapter-item expanded "><a href="p6-installing-an-ILS.html"><strong aria-hidden="true">6.</strong> Installing an Integrated Library System</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="6a-install-koha.html"><strong aria-hidden="true">6.1.</strong> Install Koha</a></li></ol></li><li class="chapter-item expanded "><a href="p7-conclusion.html"><strong aria-hidden="true">7.</strong> Conclusion</a></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">Systems Librarianship</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                        <a href="https://github.com/cseanburns/systems_librarianship" title="Git repository" aria-label="Git repository">
                            <i id="git-repository-button" class="fa fa-github"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="systems-librarianship"><a class="header" href="#systems-librarianship">Systems Librarianship</a></h1>
<p>Author: C. Sean Burns<br />
Date, version 2: 2024-01-08<br />
Email: <a href="sean.burns@uky.edu">sean.burns@uky.edu</a><br />
Website: <a href="https://cseanburns.github.io/csb/">cseanburns.github.io/csb/</a><br />
GitHub: <a href="https://github.com/cseanburns">@cseanburns</a></p>
<h2 id="introduction"><a class="header" href="#introduction">Introduction</a></h2>
<p>The goal of this book is to
provide a technical introduction to
the basics of systems librarianship
using Linux.
The book is used alongside a course
on systems librarianship that the author teaches.</p>
<p>The course and book goals include:</p>
<ol>
<li>how to use the Linux command line in order to become more efficient computer
users and more comfortable with using computers in general;</li>
<li>how to use cloud computing resources and create virtual machines;</li>
<li>how to manage projects using Git and GitHub;</li>
<li>how to create a LAMP server, websites, and create a bare bones OPAC;</li>
<li>how to install and configure content management systems, and;</li>
<li>how to install and configure an integrated library system.</li>
<li>to foster self-efficacy with computers and an enthusiasm for foundational
computer technologies</li>
</ol>
<h2 id="about-this-book"><a class="header" href="#about-this-book">About This Book</a></h2>
<p>The Systems Librarianship course is
a brand new course (2023).
I created the course to help future
and current librarians become proficient
in the kinds of technology used to manage
and provide electronic resources.</p>
<p>Since I use this book for my
Systems Librarianship course,
which I will likely teach each spring semester,
this book will be a live document.
Each semester that I teach this course,
I will update the content in order
to address changes in the technology and to
edit for clarity when I discover some aspect
of the book causes confusion or
does not provide enough information.</p>
<p>A small part of this book will draw from
my course on
<a href="https://cseanburns.github.io/linux_sysadmin/">Linux Systems Administration</a>,
which I teach in the fall semesters.</p>
<p>This book is not a
comprehensive introduction to
systems librarianship.
For example,
this book does not cover software coding nor
managerial duties, like issuing
requests for proposals for software products,
or budgeting.
It is designed as an entry level course in
the technical aspects of systems librarianship,
and it is meant to go hand-in-hand with 
other courses taught in our program.
That includes my course on
<a href="https://cseanburns.net/WWW/ERM-book/">electronic resource management</a>
but also other courses that my colleagues teach.</p>
<p>I am using <a href="https://github.com/rust-lang/mdBook">mdBook</a> to build this work.
Please use the search function on this site to search for
specific topics or keywords.
If the reader desires a PDF copy of this work,
the printer icon at the top right of the page
will print to PDFs.</p>
<p>The content in this book is open access and
licensed under the <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">Creative Commons Attribution-NonCommercial-ShareAlike 4.0</a> license.
Feel free to fork it on <a href="https://github.com/cseanburns/systems_librarianship">GitHub</a> and
modify it for your own needs.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="history-of-unix-and-linux"><a class="header" href="#history-of-unix-and-linux">History of Unix and Linux</a></h1>
<p>An outline of the history of Unix and Linux.</p>
<p><strong>Note</strong>: this section is borrowed from my
<a href="https://cseanburns.github.io/linux_sysadmin/">Linux Systems Administration</a>
course.</p>
<h2 id="location-bell-labs-part-of-att-new-jersey-late-1960s-through-early-1970s"><a class="header" href="#location-bell-labs-part-of-att-new-jersey-late-1960s-through-early-1970s">Location: Bell Labs, part of AT&amp;T (New Jersey), late 1960s through early 1970s</a></h2>
<p>In the late 1960s through the early 1970s at Bell Labs,
part of AT&amp;T in New Jersey,
the journey began with an operating system called Multics. 
Multics was a pioneering time-sharing system,
allowing more than one person to use it at once.
Despite its innovative approach,
Multics was fraught with issues and was slowly abandoned. 
In the midst of this abandonment,
<a href="http://cs.bell-labs.co/who/ken/">Ken Thompson</a>
stumbled upon an old PDP-7 and started 
writing what would become UNIX.
During this time,
he created the <a href="https://en.wikipedia.org/wiki/Ed_(text_editor)">ed</a> line editor,
pronounced e.d.,
but generally sounded out.
This specific version of UNIX would
later be known as Research Unix.
The project caught the attention of
<a href="https://www.bell-labs.com/usr/dmr/www/">Dennis Ritchie</a>,
the creator of the C programming language,
who joined Thompson's efforts, and
together they laid the groundwork for
a revolution in computing.</p>
<h2 id="location-berkeley-ca-university-of-california-berkeley-early-to-mid-1970s"><a class="header" href="#location-berkeley-ca-university-of-california-berkeley-early-to-mid-1970s">Location: Berkeley, CA (University of California, Berkeley), early to mid 1970s</a></h2>
<p>In the early to mid-1970s at the
University of California, Berkeley,
the evolution of UNIX continued.
While not classified as 'free software,'
UNIX's code was low-cost and easily shared among
tech enthusiasts.
Ken Thompson visited Berkeley,
where he helped install Version 6 of <a href="https://en.wikipedia.org/wiki/Berkeley_Software_Distribution">UNIX</a>,
marking a significant moment in the system's history.
At Berkeley, several contributors,
including <a href="https://en.wikipedia.org/wiki/Bill_Joy">Bill Joy</a>,
played vital roles in its development.
Joy was particularly influential,
creating the <a href="https://sites.google.com/a/bostic.com/keithbostic/vi/">vi</a> text editor,
a precursor of the popular <a href="https://www.vim.org/">Vim</a> editor,
and many other essential programs.
He also co-founded Sun Microsystems.
This installation and collaborative effort at
Berkeley eventually led to the creation of the
Berkeley Software Distribution, or <a href="https://en.wikipedia.org/wiki/Berkeley_Software_Distribution">BSD</a>,
a landmark in the history of UNIX
and computing as a whole.</p>
<h2 id="att"><a class="header" href="#att">AT&amp;T</a></h2>
<p>Until its breakup in 1984,
AT&amp;T operated under a unique agreement with the
U.S. government that restricted the company from
profiting off patents not directly related
to its telecommunications businesses.
This arrangement helped shield AT&amp;T from
monopolistic charges,
but it also came with a significant limitation:
they could not commercialize UNIX.
The landscape changed dramatically after the
breakup of AT&amp;T.
The constraints lifted,
allowing System V UNIX to emerge as
the standard bearer of commercial UNIX.
This transition marked a turning point
in the history of computing,
positioning UNIX as a central player
in the commercial technology market.</p>
<h2 id="location-boston-ma-mit-early-1980s-through-early-1990s"><a class="header" href="#location-boston-ma-mit-early-1980s-through-early-1990s">Location: Boston, MA (MIT), early 1980s through early 1990s</a></h2>
<p>In Boston, MA, at MIT during the early 1980s
through the early 1990s,
a significant shift in the software industry
was taking place.
In the late 1970s,
<a href="https://en.wikipedia.org/wiki/Richard_Stallman">Richard Stallman</a> observed the growing
trend of software becoming commercialized.
This commercialization led to hardware vendors
ceasing to share the code they developed
to make their hardware work.
This paradigm change was further solidified by the 
Copyright Act of 1976,
making software code eligible for copyright protection. 
Stallman, who thrived in a hacker culture,
began to battle against this new direction.
He responded by creating the <a href="https://www.gnu.org/gnu/gnu.html">GNU project</a>,
embracing the free software philosophy,
and developing influential tools such as GNU Emacs,
a popular text editor,
and many other programs.
The GNU project was an ambitious attempt
to create a completely free software operating
system that was Unix-like,
called GNU.
By the early 1990s,
Stallman and others had developed all
the utilities needed for a full operating system,
except for a kernel,
which they named <a href="https://www.gnu.org/software/hurd/">GNU Hurd</a>.
This encompassing project included
the creation of the Bash shell,
written by <a href="https://opuslogica.com/">Brian Fox</a>,
reflecting a profound commitment
to free and open software.</p>
<p>The GNU philosophy includes several
propositions that define free software:</p>
<blockquote>
<p>The four freedoms, per GNU Project:
0. The freedom to run the program as you wish,
for any purpose (freedom 0).</p>
<ol>
<li>The freedom to study how the program works,
and change it so it does your computing as you wish (freedom 1).
Access to the source code is a precondition for this.</li>
<li>The freedom to redistribute copies so you can help others (freedom 2).</li>
<li>The freedom to distribute copies of your modified
versions to others (freedom 3).
By doing this you can give the whole community a chance
to benefit from your changes.
Access to the source code is a precondition for this.</li>
</ol>
</blockquote>
<p><a href="https://www.gnu.org/philosophy/free-sw.html">The Four Freedoms</a></p>
<h2 id="the-unix-wars-and-the-lawsuit-late-1980s-through-the-early-1990s"><a class="header" href="#the-unix-wars-and-the-lawsuit-late-1980s-through-the-early-1990s">The Unix wars and the lawsuit, late 1980s through the early 1990s</a></h2>
<p>During the late 1980s through the early 1990s,
the so-called &quot;Unix wars&quot; and an
ensuing lawsuit marked a contentious period
in the history of computing.
Following its breakup,
AT&amp;T began to commercialize Unix,
leading to distinct differences between
AT&amp;T Unix and BSD Unix.
The former was aimed at commercial markets,
while the latter was targeted at
researchers and academics.
These contrasting objectives led to legal friction, 
culminating in UNIX Systems Laboratories, Inc.
(USL, part of AT&amp;T) suing
Berkeley Software Design, Inc.
(BSDi, part of the University of California, Berkeley)
for copyright and trademark violations.
Ultimately, USL lost the case,
but not before the lawsuit had created significant 
obstacles for BSD Unix.
The legal battle delayed the adoption of BSD Unix,
leaving a lasting impact on the
development and dissemination of Unix systems.</p>
<h2 id="linux-linus-torvalds-university-of-helsinki-finland-early-1990s"><a class="header" href="#linux-linus-torvalds-university-of-helsinki-finland-early-1990s">Linux, Linus Torvalds, University of Helsinki, Finland, early 1990s</a></h2>
<p>In the early 1990s at the University of Helsinki
in Finland,
a significant development in the
world of computing unfolded.
On August 25, 1991,
<a href="https://www.cs.helsinki.fi/u/torvalds/">Linus Torvalds</a> announced that he had
started working on a free operating system kernel 
specifically for the 386 CPU architecture and
his hardware.
This <a href="https://www.kernel.org/">kernel</a> would later be famously named Linux.
It's essential to understand that Linux
technically refers only to the kernel,
which handles startup, devices,
memory, resources, and more,
but does not provide user land
utilities—the kind of software
that people use on their computers.</p>
<p>Torvalds' motivation for this project was
both to learn about OS development and
to have access to a Unix-like system.
He already had access to an Unix-like
system called <a href="https://www.minix3.org/">MINIX</a>,
but MINIX was limited by technical and
copyright restrictions.
Interestingly, Torvalds has stated that if a
BSD or GNU Hurd operating system were
available at that time,
he might not have created the Linux kernel at all. 
However, he and others took the
GNU utilities and created what is
now widely referred to as Linux or GNU/Linux.
This amalgamation of Torvalds' kernel and
GNU utilities marked a critical point
in the evolution of free and open-source software, 
fostering a global community of developers and users.</p>
<h2 id="distributions-early-1990s-through-today"><a class="header" href="#distributions-early-1990s-through-today">Distributions, early 1990s through today</a></h2>
<p>Soon after the development of Linux in the early 1990s,
a trend began to emerge that continues to this day. 
Enthusiasts and developers started creating
their own Linux and GNU-based operating systems, 
customizing them to suit various needs and preferences. 
They would then distribute these customized
versions to others,
sharing their innovations and insights with a
wider community.
As a result of this practice,
these Linux operating systems became
known as &quot;distributions.&quot;
This phenomenon has led to a rich ecosystem of
Linux distributions,
catering to different user bases,
industries, and interests, and
has played a central role in the
continued growth and
diversification of open-source computing.</p>
<p>The two oldest distributions that are still in
active development include:</p>
<ul>
<li><a href="http://www.slackware.com/">Slackware</a></li>
<li><a href="https://www.debian.org/">Debian</a></li>
</ul>
<h2 id="short-history-of-bsd-1970s-through-today"><a class="header" href="#short-history-of-bsd-1970s-through-today">Short History of BSD, 1970s through today</a></h2>
<p>The history of Berkeley Software Distribution (BSD)
spans from the 1970s to today and is closely
intertwined with the evolution of Unix.
Early Unix version numbers 1-6
eventually led to the development of BSD versions 1-4.
By the time of BSD 4.3,
all versions still contained some AT&amp;T code.
A desire to remove this proprietary code led to the 
creation of BSD Net/1.</p>
<p>The effort continued until all AT&amp;T
code was successfully removed by BSD Net/2.
This version was then ported to the Intel 386
processor, resulting in 386BSD,
made available in 1992,
a year after the Linux kernel was released.</p>
<p>386BSD eventually split into two distinct projects:
<a href="https://www.netbsd.org/">NetBSD</a> and <a href="https://www.freebsd.org/">FreeBSD</a>.
Later, NetBSD itself split into another project,
giving rise to <a href="https://www.openbsd.org/">OpenBSD</a>.
All three of these BSDs are still in
active development today,
and each has a unique focus:</p>
<ul>
<li><strong>NetBSD</strong> is known for its focus on portability, finding
applications in various environments such as MacOS and even
NASA projects.</li>
<li><strong>FreeBSD</strong> is recognized for its wide applicability and has
been utilized by notable companies and products like WhatsApp,
Netflix, PlayStation 4, and MacOS.</li>
<li><strong>OpenBSD</strong> emphasizes security and has contributed several
essential applications in this domain.</li>
</ul>
<p>This intricate journey of BSD,
marked by splits, adaptations, and varied focuses,
has cemented its place in the history of
operating systems,
allowing it to cater to a wide range of
applications and audiences.</p>
<blockquote>
<p>MacOS is based on <a href="http://www.puredarwin.org/">Darwin</a>,
is <a href="https://www.opengroup.org/membership/forums/platform/unix">technically UNIX</a>, and is
partly based on FreeBSD with some code
coming from the other BSDs.
See <a href="https://apple.stackexchange.com/questions/401832/why-is-macos-often-referred-to-as-darwin">Why is macOS often referred to as 'Darwin'?</a>
for a short history.</p>
</blockquote>
<h2 id="short-history-of-gnu-1980s-through-today"><a class="header" href="#short-history-of-gnu-1980s-through-today">Short History of GNU, 1980s through today</a></h2>
<p>The history of GNU,
particularly the GNU Hurd kernel,
traces back to the 1980s and continues to evolve today. 
The GNU Hurd, despite its long development process, 
remains in a pre-production state.
The latest release of this kernel was version 0.9,
which came out in December 2016.
Even though it has not yet reached full maturity,
a complete operating system based on the GNU Hurd
can be downloaded and run.
For example,
<a href="https://www.debian.org/ports/hurd/">Debian GNU/Hurd</a>
represents one such implementation.
This ongoing work on the GNU Hurd exemplifies
the free and open-source community's
commitment to innovation and collaboration,
maintaining a spirit of exploration that has
driven the software landscape for decades.</p>
<h2 id="free-and-open-source-licenses"><a class="header" href="#free-and-open-source-licenses">Free and Open Source Licenses</a></h2>
<p>In the free software and open source landscape,
there are several important free and/or open source
licenses that are used.
The two biggest software licenses are
based on the software used by GNU/Linux
and the software based on the BSDs.
They each take very different approaches to free
and/or open source software.
The biggest difference is this:</p>
<ul>
<li>Software based on software licensed under the GPL
must also be licensed under the GPL.
This is referred to as <a href="https://www.gnu.org/licenses/copyleft.en.html">copyleft</a> software,
and the idea is to propagate free software.
<ul>
<li><a href="https://www.gnu.org/licenses/gpl-3.0.en.html">GNU General Public License (GPL)</a></li>
</ul>
</li>
<li>Software based on software licensed under the BSD
license may be closed source and
primarily must only attribute the original source code and author.
<ul>
<li><a href="https://opensource.org/licenses/BSD-3-Clause">BSD License</a></li>
</ul>
</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="what-is-linux"><a class="header" href="#what-is-linux">What is Linux?</a></h1>
<h2 id="the-linux-kernel"><a class="header" href="#the-linux-kernel">The Linux Kernel</a></h2>
<p>Technically, <a href="https://kernel.org/">Linux is a kernel</a>, and
a kernel is a part of an operating system that
oversees CPU activity like multitasking, as well as networking,
memory management, device management, file systems, and more.
The kernel alone does not make an operating system.
It needs user land applications and programs,
the kind we use on a daily basis, to form a whole,
as well as ways for these user land utilities to
interact with the kernel.</p>
<h2 id="linux-and-gnu"><a class="header" href="#linux-and-gnu">Linux and GNU</a></h2>
<p>The earliest versions of the Linux kernel were combined
with tools, utilities, and programs from the <a href="https://www.gnu.org/software/software.html">GNU project</a>
to form a complete operating system,
without necessarily a graphical user interface.
This association continues to this day.
Additional non-GNU, but
free and open source programs under different licenses,
have been added to form a more functional and user friendly system.
However, since the Linux kernel needs user land applications
to form an operating system, and
since user land applications from GNU cannot work without a kernel,
some argue that the operating system
should be called <a href="https://en.wikipedia.org/wiki/GNU/Linux_naming_controversy">GNU/Linux</a>
and not just Linux.
This has not gained wide acceptance, though.
Regardless, credit is due to both camps for their contribution,
as well as many others who have made substantial contributions
to the operating system.</p>
<h2 id="linux-uses"><a class="header" href="#linux-uses">Linux Uses</a></h2>
<p>We are using Linux as a server in this course, which
means we will use Linux to provide various services.
Our first focus is to learn to use Linux itself, but
by the end of the course,
we will also learn how to provide web and database services.
Linux can be used to provide <a href="https://en.wikipedia.org/wiki/Server_(computing)">other services</a> that
we won't cover in this course, such as:</p>
<ul>
<li>file servers</li>
<li>mail servers</li>
<li>print servers</li>
<li>game servers</li>
<li>computing servers</li>
</ul>
<p>Although it's a small overall percentage,
many people use Linux as their main
desktop/laptop operating system.
I belong in this camp.
Linux has been my main OS since the early 2000s.
While our work on the Linux server means that we will
almost entirely work on the command line,
this does not mean that my Linux
desktop environment is all command line.
In fact, there are many graphical user environments,
often called <a href="https://en.wikipedia.org/wiki/Desktop_environment">desktop environments</a>,
available to Linux users.
Since I'm currently using the Ubuntu Desktop distribution,
my default desktop environment is called <a href="https://www.gnome.org/">Gnome</a>.
<a href="https://kde.org/">KDE</a> is another popular desktop environment, but
there are many other attractive and useful ones.
And it's easy to install and switch between
multiple ones on the same OS.</p>
<p>Linux has become quite a pervasive operating system.
Linux powers the hundreds of the
fastest supercomputers in the world.
It, or other Unix-like operating systems,
are the foundation of most web servers.
The Linux kernel also forms the basis of the Android
operating system and of Chrome OS.
The only place where Linux does not dominate is
in the desktop/laptop space.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="what-is-systems-administration"><a class="header" href="#what-is-systems-administration">What is Systems Administration?</a></h1>
<h2 id="introduction-1"><a class="header" href="#introduction-1">Introduction</a></h2>
<p>What is systems administration or
who is a systems administrator (or <strong>sysadmin</strong>)?
Let's start off with some definitions provided by
the <a href="https://www.nist.gov/">National Institute of Standards and Technology</a>:</p>
<blockquote>
<p>An individual, group, or organization responsible for setting up and
maintaining a system or specific system elements, implements approved secure
baseline configurations, incorporates secure configuration settings for IT
products, and conducts/assists with configuration monitoring activities as
needed.</p>
</blockquote>
<p>Or:</p>
<blockquote>
<p>Individual or group responsible for overseeing the day-to-day operability of a
computer system or network. This position normally carries special privileges
including access to the protection state and software of a system.</p>
</blockquote>
<p>See: <a href="https://csrc.nist.gov/glossary/term/system_administrator">Systems Administrator @NIST</a></p>
<h2 id="specialized-positions"><a class="header" href="#specialized-positions">Specialized Positions</a></h2>
<p>In addition to the above definitions,
which broadly define the role,
there are a number of related or specialized positions.
We'll touch on the first three in this course:</p>
<ul>
<li>Web server administrator:
<ul>
<li>&quot;web server administrators are system architects responsible for the
overall design, implementation, and maintenance of Web servers. They may or
may not be responsible for Web content, which is traditionally the
responsibility of the Webmaster (<a href="https://csrc.nist.gov/glossary/term/web_server_administrator">Web Server Administrator&quot;
@NIST</a>).</li>
</ul>
</li>
<li>Database administrator:
<ul>
<li>like web admins, and to paraphrase above, database administrators are system
architects responsible for the overall design, implementation, and
maintenance of database management systems. </li>
</ul>
</li>
<li>Network administrator:
<ul>
<li>&quot;a person who manages a network within an organization. Responsibilities
include network security, installing new applications, distributing software
upgrades, monitoring daily activity, enforcing licensing agreements,
developing a storage management program, and providing for routine backups&quot;
(<a href="https://csrc.nist.gov/glossary/term/network_administrator">Network Administrator @NIST</a>).</li>
</ul>
</li>
<li>Mail server administrator:
<ul>
<li>&quot;mail server administrators are system architects responsible for the
overall design and implementation of mail servers&quot; (<a href="https://csrc.nist.gov/glossary/term/mail_server_administrator">Mail Server
Administrators @NIST</a>).</li>
</ul>
</li>
</ul>
<p>Depending on where a system administrator works,
they may specialize in any of the above administrative areas, or
if they work for a small organization,
all of the above duties may be rolled into one position.
Some of the positions have evolved quite a bit over the last
couple of decades.
For example, it wasn't too long ago when organizations would
operate their own mail servers, but
this has largely been outsourced to third-party providers,
such as Google (via Gmail) and Microsoft (via Outlook).
People are still needed to work with these
third-party email providers, but
the nature of the work is different than operating
independent mail servers.</p>
<h2 id="certifications"><a class="header" href="#certifications">Certifications</a></h2>
<p>It's not always necessary to get certified
as a systems administrator to get work as one, but
there might be cases where it is necessary; for example,
in government positions or in large corporations.
It also might be the case that you can get work
as an entry level systems administrator and
then pursue certification with
the support of your organization.</p>
<p>Some common starting certifications are:</p>
<ul>
<li><a href="https://www.redhat.com/en/services/certification/rhcsa">Red Hat Certified System Administrator (RHCSA)</a></li>
<li><a href="https://www.comptia.org/certifications/server">CompTIA Server+</a></li>
<li><a href="https://www.comptia.org/certifications/a">CompTIA A+</a></li>
</ul>
<p>Plus, Google offers, via <a href="https://www.coursera.org/">Coursera</a>, a
beginners <a href="https://www.coursera.org/professional-certificates/google-it-support">Google IT Support Professional Certificate</a>
that may be helpful.</p>
<h2 id="associations"><a class="header" href="#associations">Associations</a></h2>
<p>Getting involved in associations and related
organizations is a great way to learn and
to connect with others in the field.
Here are few ways to connect.</p>
<p><a href="https://lopsa.org/AboutLOPSA">LOPSA</a>, or
The League of Professional System Administrators,
is a non-profit association that seeks to advance
the field and membership is free for students.</p>
<p><a href="https://www.acm.org/">ACM</a>, or the Association for Computing Machinery,
has a number of relevant
<a href="https://www.acm.org/special-interest-groups/alphabetical-listing">special interest groups (SIGs)</a>
that might be beneficial to systems administrators. </p>
<p><a href="http://www.npa.org/">NPA</a>, or the Network Professional Association,
is an organization that &quot;supports IT/Network 
professionals.&quot;</p>
<h2 id="codes-of-ethics"><a class="header" href="#codes-of-ethics">Codes of Ethics</a></h2>
<p>Systems administrators manage computer systems
that contain a lot of data about us and
this raises privacy and competency issues,
which is why some have created code of ethics statements.
Both LOPSA and NPA have created such statements
that are well worth reviewing and discussing.</p>
<ul>
<li>LOPSA: <a href="https://lopsa.org/CodeOfEthics">Code of Ethics</a></li>
<li>NPA: <a href="https://www.npa.org/public/about_codeofethics.cfm">Code of Ethics</a></li>
</ul>
<h2 id="keeping-up"><a class="header" href="#keeping-up">Keeping Up</a></h2>
<p>Technology changes fast.
In fact, even though I teach this course
about every year,
I need to revise the
course each time, sometimes substantially,
to reflect changes that have developed
over short periods of time.
It's also your responsibility,
as sysadmins,
to keep up, too.</p>
<p>I therefore suggest that you continue your
education by reading and practicing.
For example, there are lots of books on 
systems administration.
<a href="https://www.npa.org/public/about_codeofethics.cfm">O'Reilly</a> continually
publishes on the topic.
RedHat,
the makers of the Red Hat Linux distribution,
and sponsors of <a href="https://www.linuxjournal.com/">Fedora Linux</a> and
<a href="https://centos.org/">CentOS Linux</a>,
provides the <a href="https://www.redhat.com/sysadmin/">Enable Sysadmin</a> site,
with new articles each day,
authored by systems administrators,
on the field.
Opensource.com, also supported by Red Hat,
<a href="https://opensource.com/tags/sysadmin">publishes articles on systems administration</a>.
<a href="https://www.redhat.com/en/command-line-heroes">Command Line Heroes</a> is a fun and
informative podcast on technology and
sysadmin related topics.
<a href="https://www.linuxjournal.com/">Linux Journal</a> publishes great articles
on Linux related topics.</p>
<h2 id="conclusion"><a class="header" href="#conclusion">Conclusion</a></h2>
<p>In this section I provided definitions of systems administrators
and also the related or more specialized positions,
such as database administrator, network administrator,
and others.</p>
<p>I provided links to various certifications you might
pursue as a systems administrator, and
links to associations that might benefit you and your career.</p>
<p>Technology manages so much of our daily lives, and
computer systems store lots of data about us.
Since systems administrators manage these systems,
they hold a great amount of responsibility
to protect them and our data.
Therefore, I provided links to two code of ethics
statements that we will discuss.</p>
<p>It's also important to keep up with the technology,
which changes fast.
The work of a systems administrator is much different
today than it was ten or twenty years ago, and
that surely indicates that it could be much different in
another ten to twenty years.
If we don't keep up,
we won't be of much use to the people we serve.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="what-is-systems-librarianship"><a class="header" href="#what-is-systems-librarianship">What is Systems Librarianship</a></h1>
<h2 id="introduction-2"><a class="header" href="#introduction-2">Introduction</a></h2>
<p>Of course, let's begin with the question,
what is systems librarianship?
Normally we might go to the literature
to answer a question like this.
Indeed, the literature is helpful,
but it's sparse.
The <a href="https://libguides.uky.edu/803">LISTA</a> database only
returns 131 results
with a 45 year coverage
for a search using the thesauri term
<strong>SYSTEMS Librarians</strong>.
I can get more results if I expand
the search query, but
then I get less relevant results, and
the main idea is the same:
this is an understudied area of
librarianship.</p>
<p>It's been that way for a while.
<a href="https://doi.org/10.1300/J111v09n04_06">Susan K. Martin</a>
wrote the following over 35 years ago:</p>
<blockquote>
<p>Of the specialist positions that exist in libraries, none
is as underexamined as those of the systems
librarians---the people who identify the needs of the
library for automated systems, cause these systems to be
implemented, and analyze the operations of the library (p.
57).</p>
</blockquote>
<p>Perhaps as a result of this
underexamination,
sometimes there is confusion around
the requirements and skills needed in
this area of librarianship.
Martin (1988) captured this tension
when she wrote the following in 1988,
which is still true today:</p>
<blockquote>
<p>Over the years the library world has argued whether
systems librarians should be librarians who have learned
information technologies, or computer experts who have
learned about libraries (p. 61).</p>
</blockquote>
<p>The argument is partly
a matter of jurisdiction.
<a href="https://www.proquest.com/docview/220452054/abstract/A48FC30B10D94886PQ/1?accountid=11836">Abbott (1998)</a>,
writing on librarianship in the sociology of professions,
illustrated how:</p>
<blockquote>
<p>The future of librarianship thus hinges on what happens to
the perpetually changing work of the profession in its
three contexts: the context of larger social and culture
forces, the context of other competing occupations, and
the context of competing organizations and commodities. To
these complex contextual forces, any profession responds
with varying policies and internal changes (pp. 434-5).</p>
</blockquote>
<p>Essentially, Abbott means that professions,
like librarianship,
are always changing.
The mechanisms for that change are
structural and cultural <a href="https://www.jstor.org/stable/40664150">(Abbott, 2010)</a>,
but a changing profession means that
its &quot;link of jurisdiction&quot;
(Abbott, 1998, p. 435) changes, too.
It not only changes, but
professions constantly compete with each
other over to adopt new areas
of jurisdiction.
So when we ask,
as Martin (1998) did,
whether librarians should learn
information technologies or whether
computer experts should learn libraries,
I find myself thinking the prior is
more important for libraries
and their patrons.
It means that librarians are expanding
their jurisdiction by also becoming
computer experts rather than
computer experts expanding theirs.</p>
<p>That leads us to the next questions:
what does it mean to be a computer
expert for a systems librarian?
What does a systems librarians need
to do and know?</p>
<p>The answer is that it is a mix.
Some part of the work involves
systems administration, but
that has broad meanings, and
systems librarianship is more specific.
Or, it has a more specific domain:
the domain of libraries and librarianship.</p>
<p>A systems librarian might thus be considered
a library systems administrator.
Under this view, they need to be someone
who knows about libraries,
how libraries work,
what they do,
about their patrons,
what their values are,
and then use that knowledge to build
the infrastructure to support that.</p>
<p>Given this, and the technologies involved,
such work requires constant learning.
<a href="https://doi.org/10.1108/07378830310494445">Jordan (2003)</a> 
identified three areas of learning:</p>
<ul>
<li>pre-service education in library schools</li>
<li>on the job training</li>
<li>professional development in the form of workshops,
courses, and conferences (p. 273)</li>
</ul>
<p>Pre-service, formal education is a small part
of any professional's career,
regardless if that profession is
in medicine, law, or librarianship.
Thus the goal of pre-service
education is to prepare people
to adapt and grow in their fields.
Jordan (2003) wrote that:</p>
<blockquote>
<p>While formal training is undoubtedly important, the
ability to learn new technologies independently lies at
the foundation of systems librarians' professional life,
because they often have to use technologies, or make
planning decisions about specific technologies, before
they become common enough to be the subject of formal
training sessions (p. 273).</p>
</blockquote>
<p>Even though Jordan's article
is 20 years old and
the technology has changed a lot,
the basic duties of the systems librarian
remain the same
(Fu, 2014; <a href="https://rowman.com/ISBN/9781538107133/Systems-Librarianship-A-Practical-Guide-for-Librarians">Gonzales, 2020</a>).
<a href="https://www.worldcat.org/title/1038159656">Wilson (1998)</a>,
as cited in Jordan (2003),
refers to a list of the
&quot;typical responsibilities of systems librarians.&quot;
These responsibilities look different today,
because the technology is different,
but conceptually,
they're the same as they were then.
In fact, this work will focus
on a subset of this list that includes:</p>
<ul>
<li>integrated library system management</li>
<li>server management</li>
<li>documentation</li>
<li>technology exploration and evaluation (Jordan, 2003, p. 274)</li>
</ul>
<p>Gonzales (2020) highlights these and
more current areas that include:</p>
<ul>
<li>content management systems</li>
<li>electronic resource management systems</li>
<li>website redesign</li>
<li>help and support</li>
</ul>
<p>Other items on Jordan's (2003) list are
still relevant, but
due to various constraints,
this work will not cover the following
areas:</p>
<ul>
<li>network design and management</li>
<li>desktop computing</li>
<li>application development</li>
<li>planning and budget</li>
<li>specification and purchasing</li>
<li>miscellaneous technology support</li>
<li>technical risk management (p. 274)</li>
</ul>
<p>In short,
this work specifically focuses on
a few of the bigger technical aspects of
systems librarianship.
Other works (or courses) and
other sources will provide learning
opportunities on the more
managerial and administrative functions
of systems librarianship and librarianship, in general.</p>
<blockquote>
<p>If you are interested in learning
more about network design and administration,
then I encourage you to read my chapters on
<a href="https://cseanburns.github.io/linux_sysadmin/19-networking-tcpip.html">Networking and TCP/IP</a> and
<a href="https://cseanburns.github.io/linux_sysadmin/20-dns-domain-names.html">DNS and Domain Names</a> in my
book on
<a href="https://cseanburns.github.io/linux_sysadmin/">Systems Administration with Linux</a>.</p>
<p>If you are interested in learning about
application development,
then you can pursue courses in a variety
of programming languages,
such as R, Python, JavaScript, and PHP,
as well as courses on relational databases,
such as MySQL or PostgreSQL, and so forth.</p>
</blockquote>
<p>As Jordan (2003) identified,
there is a lack of formalized training
in systems librarianship in LIS schools.
This is as true today as it was in 2003.
This course was created to address the
lack of that training.
However, as Jordan (2003) noted,
pre-service education is only a start.
Technology is constantly changing, and
that means we must always embrace 
learning opportunities,
such as through workshops, conferences,
and on the job training.
LIS programs are only two or so years
long (if attending full time), but
our careers will hopefully span decades.
So all this course can ever be
is just a starting point.</p>
<p>It is a big start, though.
This course should lay a strong foundation for
self-growth and self-education
in the variety of technologies
that we will learn and use here.
Although separate areas of librarianship,
my work (and course) on
<a href="https://cseanburns.github.io/electronic_resource_mgmt/">electronic resource management</a>
complement this one in many ways.
For example, this work supports several
parts of the technology section in the
<a href="https://www.nasig.org/Competencies-Eresources">NASIG Core Competencies for Electronic Resources
Librarians</a>.
It is no coincidence these two areas of
librarianship often overlap or are
assumed in a single librarian position.</p>
<h2 id="cloud-computing"><a class="header" href="#cloud-computing">Cloud Computing</a></h2>
<p>Lastly, I want to mention cloud computing.
This has become a major area of change in
the last decade or so.
It used to be more common for librarians
to install their integrated library system software
and store their bibliographic data on their premises.
In the last ten years,
there has been more migration to the cloud,
which means that both the integrated library system
software and the bibliographic data are stored off-site.
<a href="https://doi.org/10.1108/10650751311294528">Liu &amp; Cai (2013)</a> highlight the beginning
of this trend toward cloud computing
that continues to play a large role in
systems librarianship <a href="https://doi.org/10.1108/DLP-03-2021-0022">(Naveed et al., 2021)</a>.
As Liu and Cai note:</p>
<blockquote>
<p>Systems librarians used to make their livings by managing
hosted library systems. This situation is silently
changing with the library systems moving onto the cloud
(p. 26).</p>
</blockquote>
<p>This trend has changed some aspects of
systems librarianship.
It means that systems librarians,
while still a technical area of librarianship,
need to work more closely with the vendors
who themselves are hosting library systems.
However, the trend does not erase all
locally hosted solutions.
Many libraries and other information agencies
continue to support local collections and
will either host those locally or work
to get the bibliographic information for those
collections ingested into their cloud-based
integrated library systems.</p>
<h2 id="conclusion-1"><a class="header" href="#conclusion-1">Conclusion</a></h2>
<p>The remainder of the course
will be more technical and
will prepare you to work and understand the
systems that support the modern library.
We will cover a lot, too!
We will begin with setting up
virtual machine instances on Google Cloud.
We will use a distribution of the Linux
operating system for these virtual machines.
We will then learn the basics of the
Linux command line.
Next, we will learn how to use
the version control system called <code>git</code>.
We will use <code>git</code> to document our work flows and
push that documentation to <a href="https://github.com">GitHub.com</a>.
On our Linux servers,
we will create a web server out of
what is called a <a href="https://en.wikipedia.org/wiki/LAMP_(software_bundle)">LAMP stack</a>,
which stands for
<a href="https://www.kernel.org/">Linux</a>,
<a href="https://www.apache.org/">Apache</a>,
<a href="https://www.mysql.com/">MySQL</a>, and
<a href="https://www.php.net/">PHP</a>.
We will use the web server
to setup a basic website and
a bare bones OPAC.
(I'll provide the code for this.)
Then we will learn how to install
and setup two content management systems:
Wordpress and Omeka.
Lastly, we will spend the final
two weeks of the semester
installing and setting up the
open source <a href="https://koha-community.org/">Koha ILS</a>.</p>
<p>Let's get started!</p>
<h2 id="references"><a class="header" href="#references">References</a></h2>
<p>Abbott, A. (1998). Professionalism and the future of
librarianship. Library Trends, 46(3), 430–443.
<a href="https://www.proquest.com/docview/220452054/abstract/A48FC30B10D94886PQ/1?accountid=11836">https://www.proquest.com/docview/220452054/abstract/A48FC30B10D94886PQ/1?accountid=11836</a></p>
<p>Abbott, A. (2010). Varieties of ignorance. <em>The American
Sociologist, 41</em>(2), 174–189.
<a href="https://www.jstor.org/stable/40664150">https://www.jstor.org/stable/40664150</a></p>
<p>Gonzales, B. M. (2020). Systems librarianship: A practical
guide for librarians. Rowman &amp; Littlefield Publishers.
<a href="https://rowman.com/ISBN/9781538107133/Systems-Librarianship-A-Practical-Guide-for-Librarians">https://rowman.com/ISBN/9781538107133/Systems-Librarianship-A-Practical-Guide-for-Librarians</a></p>
<p>Fu, P. (2014). Supporting the next-generation ILS: The
changing roles of systems librarians. <em>Journal of Library
Innovation, 5</em>(1), 30–42.</p>
<p>Jordan, M. (2003). The self‐education of systems librarians.
Library Hi Tech, 21(3), 273–279.
<a href="https://doi.org/10.1108/07378830310494445">https://doi.org/10.1108/07378830310494445</a></p>
<p>Liu, W., &amp; Cai, H. (Heather). (2013). Embracing the shift to
cloud computing: Knowledge and skills for systems
librarians. OCLC Systems &amp; Services: International Digital
Library Perspectives, 29(1), 22–29.
<a href="https://doi.org/10.1108/10650751311294528">https://doi.org/10.1108/10650751311294528</a></p>
<p>Martin, S. K. (1988). The role of the systems librarian.
<em>Journal of Library Administration, 9</em>(4), 57–68.
<a href="https://doi.org/10.1300/J111v09n04_06">https://doi.org/10.1300/J111v09n04_06</a></p>
<p>Naveed, M. A., Siddique, N., &amp; Mahmood, K. (2021).
Development and validation of core technology competencies
for systems librarian. <em>Digital Library Perspectives, 38</em>(2),
189–204.
<a href="https://doi.org/10.1108/DLP-03-2021-0022">https://doi.org/10.1108/DLP-03-2021-0022</a></p>
<p>Ratledge, D., &amp; Sproles, C. (2017). An analysis of the
changing role of systems librarians. Library Hi Tech, 35(2),
303–311.
<a href="https://doi.org/10.1108/LHT-08-2016-0092">https://doi.org/10.1108/LHT-08-2016-0092</a></p>
<p>Wilson, T. C. (1998). Systems librarian: Desinging roles,
defining skills. American Library Association.
<a href="https://www.worldcat.org/title/1038159656">https://www.worldcat.org/title/1038159656</a></p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="project-management"><a class="header" href="#project-management">Project Management</a></h1>
<p>This course involves working
towards a final project
that will lead us
to install two content management systems
and an integrated library system.</p>
<p>To accomplish this,
we will need
to set up Linux servers.
We will use Google Cloud for this purpose.
With Google Cloud,
we can create what are
called virtual machines
that run full-fledged operating systems.
We will work with Linux,
and in particular,
the Ubuntu distribution of Linux,
to complete our project.</p>
<p>We will also want
to document our work.
To do that,
we will use <a href="https://en.wikipedia.org/wiki/Git">git</a>,
which is a version control system,
and <a href="https://github.com">GitHub</a>,
an online platform
for hosting <code>git</code> repositories.
Using <code>git</code>,
we can collaborate,
share documentation and code,
and more.</p>
<h2 id="using-google-cloud-gcloud"><a class="header" href="#using-google-cloud-gcloud">Using Google Cloud (gcloud)</a></h2>
<p>The first section
in this chapter
introduces us to
<a href="https://cloud.google.com">Google Cloud</a>,
which I'll often refer to as <strong>gcloud</strong>.
We will use this platform
to create virtual instances
of the Ubuntu Server Linux operating system.
Once we create our own
Ubuntu virtual machines,
we will connect to them
via the command line.
I have written some
helpful software to help
you learn the command line language,
specifically,
the <a href="https://en.wikipedia.org/wiki/Bash_(Unix_shell)">Bash shell</a>.
Just about everything
we'll do this semester
will happen via the Bash shell.</p>
<h2 id="git-and-github"><a class="header" href="#git-and-github">Git and GitHub</a></h2>
<p>The second section
in this chapter
introduces us to <code>git</code> and GitHub.
<code>git</code> and GitHub are
primarily used for software management.
Every major software project
requires managing the codebase,
collaborations,
documentation, and more.
Many people may be involved
in these projects,
and it takes coordination
for them to write
the many thousands of
lines of software code,
which also requires management.</p>
<p>Although <code>git</code> and GitHub
are primarily used
for this purpose,
our goal is to use them
to document our work,
much like this book,
which has its own
<a href="https://github.com/cseanburns/systems_librarianship">GitHub repository or repo</a>.
This documentation covers
the processes involved
in learning Google Cloud,
<code>git</code> and GitHub, Linux, and more.
Therefore,
in the next section,
we'll learn how
to create a new repo on GitHub,
use the web interface to add notes,
and write our notes using Markdown,
an easy-to-understand and
use <em>markup</em> language to format our text.</p>
<p>Providing good documentation
is key to being able
to build on prior work,
make adjustments to our workflows,
recall the details of some process, and,
for students,
it can help in
retention and reflection.
In the remainder of the semester,
we will begin
to install and configure
some complicated pieces of software.
In order to better understand
what we will be doing,
it will be helpful
to document our processes.</p>
<h2 id="attending-to-detail"><a class="header" href="#attending-to-detail">Attending to Detail</a></h2>
<p>As we begin to work on
the more technical aspects
of this book and course,
it will be important to
remain <strong>attentive to details</strong>.
Many people who are new
to this kind of work often
stumble over the details,
like a missing period,
incorrect capitalization,
and more.
To learn how to pay
<strong>attention to the details</strong>,
work slowly and
read any messages,
including error messages,
the screen prints out
in response to your commands.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="using-gcloud-for-virtual-machines"><a class="header" href="#using-gcloud-for-virtual-machines">Using gcloud for Virtual Machines</a></h1>
<h2 id="virtual-machines"><a class="header" href="#virtual-machines">Virtual Machines</a></h2>
<p>Our goal in this section 
is to create a <strong>virtual machine (VM)</strong> <em>instance</em>.
A VM is basically a virtualized operating system
that runs on a host operating system.
That host operating system may also be Linux,
but it could be Windows or macOS.
In short,
when we use virtual machines,
it means instead of installing an operating system
(like Linux, macOS, Windows, etc) on a physical machine,
we use virtual machine software to mimic the process.
The virtual machine, thus, runs on top of our main OS.
It's like an app, where the app is a fully functioning
operating system.</p>
<p>In this course,
we're going to use gcloud (via Google)
to provide us with virtual machines.
There are other cloud service providers
available that you 
can explore on your own.
You can also play with
<a href="https://www.virtualbox.org/">VirtualBox</a>
(on your own),
which I've used in prior classes,
to install virtual machines
on your own computers.</p>
<h2 id="google-cloud--gcloud"><a class="header" href="#google-cloud--gcloud">Google Cloud / gcloud</a></h2>
<h3 id="google-account"><a class="header" href="#google-account">Google Account</a></h3>
<p>We need to have a personal Google
account to get started with gcloud.
I imagine most of you already have a Google account,
but if not, go ahead and create one at
<a href="https://www.google.com">https://www.google.com</a>.</p>
<h3 id="google-cloud-gcloud-project"><a class="header" href="#google-cloud-gcloud-project">Google Cloud (gcloud) Project</a></h3>
<p>Next we will need
to create a project on the
<a href="https://cloud.google.com/?hl=en">Google Cloud website</a>.</p>
<p>Follow <strong>Step 1</strong> at the top of the 
<strong><a href="https://cloud.google.com/sdk/docs/install-sdk">Install the gcloud CLI</a></strong> page
to create a new project.
Also, review the page on
<a href="https://cloud.google.com/resource-manager/docs/creating-managing-projects#gcloud">creating and managing projects</a>.</p>
<p>When you create your project,
you can name it anything,
but try to name it something to do with this course.
E.g., I am using the name <strong>syslib-YEAR</strong>
(replace <strong>YEAR</strong> with the actual year).
Avoid using spaces when naming your project.</p>
<p>Then click on the <strong>Create</strong> button,
and leave the organization field
set to <strong>No Organization</strong>.</p>
<h3 id="google-billing"><a class="header" href="#google-billing">Google Billing</a></h3>
<p>The second thing to do is to set up
a billing account for your gcloud project.
This does mean there is a cost associated
with this product, but
the good news is that our bills by the end of the semester should
only amount to $5 to 10 dollars, at most.
<strong><a href="https://cloud.google.com/sdk/docs/install-sdk">Follow Step 2</a></strong> to enable
billing for your new project.
See also the page on how to
<strong><a href="https://cloud.google.com/billing/docs/how-to/manage-billing-account">create, modify, or close your self-serve Cloud Billing account</a></strong>.</p>
<p>At the end of the semester,
I'll remind you that you may
want to delete your virtual machines.
If you don't do this,
you will continue
to be billed for them.</p>
<h3 id="install-the-latest-gcloud-cli-version"><a class="header" href="#install-the-latest-gcloud-cli-version">Install the latest gcloud CLI version</a></h3>
<p>After you have set up billing,
the next step is to install gcloud on your local machines. 
The <strong><a href="https://cloud.google.com/sdk/docs/install-sdk">Install the gcloud CLI</a></strong> page
provides instructions for different operating systems.</p>
<p>There are installation instructions
for macOS, Windows, Chromebooks, and various Linux distributions.
Follow these instructions closely for the operating system
that you're using.
Note that for macOS,
you have to choose among three different CPU/chip
architectures.
If you have an older macOS machine (before November 2020 or so),
it's likely that you'll select <strong>macOS 64-bit (x86_64)</strong>.
If you have a newer macOS machine,
then it's likely you'll have to select <strong>macOS 64-bit (arm64, Apple M1
silicon).</strong>
It's unlikely that any of you are using a 32-bit macOS operating system.
If you're not sure which macOS system you have,
then let me know and I can help you determine the appropriate platform.
Alternatively, follow these instructions to find your processor information:</p>
<ul>
<li>click on the Apple menu</li>
<li>choose <strong>About This Mac</strong></li>
<li>locate the <strong>Processor</strong> or <strong>Chip</strong> information</li>
</ul>
<p>After you have downloaded the gcloud CLI
for your particular OS and CPU architecture,
you will need to open a command prompt/terminal
on your machines to complete the instructions
that describe how to install the gcloud CLI.
macOS uses the Terminal app,
which can located using Spotlight.
Windows user can use Command.exe,
which can be located by search also.</p>
<p>Windows users will download a regular <strong>.exe</strong> file,
but macOS users will download a <strong>.tar.gz</strong> file.
Since macOS is Unix, you can use the <code>mv</code> command to 
move that file to your <code>$HOME</code> directory.
Then you extract it there using the <code>tar</code> command,
and once extracted
you can change to the directory that it
creates with the <code>cd</code> command.
For example, if you are downloading the X86_64 version
of the gcloud CLI, then you would run the following commands:</p>
<p>For macOS users, this assumes the <strong>.tar.gz</strong> file
was downloaded to your default Downloads folder:</p>
<pre><code>cd ~/Downloads/
mv google-cloud-cli-392.0.0-darwin-x86_64.tar.gz ~/
cd ~/
tar -xzf google-cloud-cli-392.0.0-darwin-x86_64.tar.gz
cd google-cloud-sdk
</code></pre>
<p>Modify the above commands, as appropriate,
if you're using the M1 or the M2 version
of the gcloud CLI.</p>
<h3 id="initializing-the-gcloud-cli"><a class="header" href="#initializing-the-gcloud-cli">Initializing the gcloud CLI</a></h3>
<p><strong>As above,
please follow the instructions
from the Google Cloud documentation
for your operating system.</strong></p>
<p>Once you have downloaded and installed
the gcloud CLI program,
you need to initialize it on your local machine.
Scroll down on the <a href="https://cloud.google.com/sdk/docs/install-sdk">install page</a>
to the section titled
<strong>Initializing the gcloud CLI</strong>.
In your terminal/command prompt,
run the initialization command,
per the instructions at the above page:</p>
<pre><code>gcloud init
</code></pre>
<p>And continue to follow the instructions
from the prompt and from the
Google Cloud documentation page above.</p>
<h2 id="gcloud-vm-instance"><a class="header" href="#gcloud-vm-instance">gcloud VM Instance</a></h2>
<p>Once you've initialized gcloud,
log into <a href="https://console.cloud.google.com/">Google Cloud Console</a>,
which should take you to the Dashboard page.</p>
<p>Our first goal is to create a <strong>virtual machine (VM)</strong> <em>instance</em>.
As a reminder,
a VM is basically a virtualized operating system.
That means instead of installing an operating system
(like Linux, macOS, Windows, etc) on a physical machine,
software is used to mimic the process. </p>
<p>gcloud offers a number of Linux-based operating systems
to create VMs.
We're going to use the Ubuntu operating system
and specifically the Ubuntu 20.04 LTS version.</p>
<blockquote>
<p>Ubuntu is a Linux distribution.
There are many, many distributions of Linux, and
most are probably listed on the <a href="https://distrowatch.com/">DistroWatch</a> site.
A new version of Ubuntu is released every six months.
The 20.04 signifies that this is the April 2020 version.
LTS signifies <strong>Long Term Support</strong>.
LTS versions are released every two years,
and Canonical LTD,
the owners of Ubuntu,
provide standard support for LTS versions for five years.</p>
<p>LTS versions of Ubuntu are stable.
Non-LTS versions of Ubuntu receive nine months of standard support,
and generally apply cutting edge technology,
which is not always desirable for server operating systems.
Each version of Ubuntu has a code name.
20.04 has the code name <strong>Focal Fossa</strong>.
You can see a list of versions, code names, release dates,
and more on Ubuntu's <a href="https://wiki.ubuntu.com/Releases">Releases</a> page.</p>
</blockquote>
<p>We will create our VM using the gcloud console.
To do so, follow these steps from the Project page:</p>
<ul>
<li>Click on the hamburger icon (three vertical bars) in the
top left corner.</li>
<li>Click on <strong>Compute Engine</strong> and then <strong>VM instances</strong></li>
<li>Make sure your project is listed.</li>
<li>Next, click on <strong>Create Instance</strong>.</li>
<li>Provide a name for your <strong>instance</strong>.
<ul>
<li>E.g., I chose <strong>main-ubuntu</strong> (no spaces) </li>
</ul>
</li>
<li>In the <strong>Machine configuration</strong> section, make sure <strong>E2</strong> is selected.</li>
<li>In the <strong>Machine type</strong> section, select <strong>e2-micro (2 vCPU, 1 core, 1 GB memory)</strong>
<ul>
<li>This is the lowest cost virtual machine and perfect for our needs.</li>
</ul>
</li>
<li>Under <strong>Boot disk</strong>, click on the <strong>Change</strong> button.</li>
<li>In the window, select <strong>Ubuntu</strong> from the <strong>Operating system</strong> drop down box.</li>
<li>Select <strong>Ubuntu 20.04 LTS x86/64</strong></li>
<li>Leave <strong>Boot disk type</strong> be set to <strong>Balanced persistent disk</strong></li>
<li>Disk size should be set to <strong>10 GB</strong>.</li>
<li>Click on the <strong>Select</strong> button.</li>
<li>Check the <strong>Allow HTTP Traffic</strong> button</li>
<li>Finally, click on the <strong>Create</strong> button to create your VM instance.</li>
</ul>
<blockquote>
<p>Later in the semester when we install Koha, we will need
to create a virtual machine with more CPUs and memory.
We will be charged more for those machines.
Since we do not yet need the extra resources,
we will start off with fairly low powered
machines.</p>
</blockquote>
<h2 id="connect-to-our-vm"><a class="header" href="#connect-to-our-vm">Connect to our VM</a></h2>
<p>After the new VM machine has been created,
we need to connect to it via the command line.
macOS users will connect to it via their Terminal.app.
Windows users can connect to it via their command prompt.</p>
<p>We use a <code>ssh</code> command
to connect to our VMs.
The syntax follows this pattern:</p>
<pre><code>gcloud compute ssh --zone &quot;zone-info&quot; &quot;name-info&quot; --project &quot;project-id&quot;
</code></pre>
<p>The values in the double quotes in the above command
can be located in your Google Cloud console and
in your VM instances section.
See the course video for details.</p>
<h2 id="update-our-ubuntu-vm"><a class="header" href="#update-our-ubuntu-vm">Update our Ubuntu VM</a></h2>
<p>The VM will include a recently updated version of Ubuntu 20.04,
but it may not be completely updated.
Thus the first thing we need to do is update our machines.
On Ubuntu, we'll use the following two commands,
which you should run also:</p>
<pre><code>sudo apt update
sudo apt -y upgrade
</code></pre>
<p>Then type <code>exit</code> to logout and quit the connection to the remote server.</p>
<pre><code>exit
</code></pre>
<blockquote>
<p>When you log into your machines, you'll note a command
prompt that ends with a dollar sign <code>$</code>. This is where
we type our commands. The command prompt also displays our
location in the file system. The tilde <code>~</code> is a
shorthand symbol for our home directory. By default, we
are placed in our home directory whenever we login to our
machines.</p>
</blockquote>
<h2 id="snapshots"><a class="header" href="#snapshots">Snapshots</a></h2>
<p>Lastly, we have installed a pristine version of Ubuntu,
but it's likely that we will mess something up 
as we work on our systems.
Or it could be that our systems may become compromised
at some point.
Therefore, we want to create a snapshot of our newly
installed Ubuntu server.
This will allow us to restore our server if something
goes wrong later.</p>
<p>To get started:</p>
<ol>
<li>
<p>In the left hand navigation panel, click on <strong>Snapshots</strong>.</p>
</li>
<li>
<p>At the top of the page, click on <strong>Create Snapshot</strong>.</p>
</li>
<li>
<p>Provide a name for your snapshot: e.g., <strong>ubuntu-1</strong>.</p>
</li>
<li>
<p>Provide a description of your snapshot: e.g.,</p>
<p>This is a new install of Ubuntu 20.04.</p>
</li>
<li>
<p>Choose your <strong>Source disk</strong>.</p>
</li>
<li>
<p>Choose a <strong>Location</strong> to store your snapshot.</p>
<ul>
<li>To avoid extra charges, choose <strong>Regional</strong>.</li>
<li>From the drop down box, select the same location (zone-info) your VM has</li>
</ul>
</li>
<li>
<p>Click on <strong>Create</strong></p>
</li>
</ol>
<p><strong><p style="color:red">Please monitor your billing for this to avoid costs
that you do not want to incur.</p></strong></p>
<h2 id="conclusion-2"><a class="header" href="#conclusion-2">Conclusion</a></h2>
<p>Congratulations!
You have just completed your first installation of a Linux server.</p>
<p>To summarize,
in this section,
you learned about and created a VM with gcloud.
This is a lot! 
After this course is completed,
you will be able to fire up a virtual machine
on short notice and deploy websites and more.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="learn-git-and-github"><a class="header" href="#learn-git-and-github">Learn Git and GitHub</a></h1>
<h2 id="introduction-3"><a class="header" href="#introduction-3">Introduction</a></h2>
<p><a href="https://git-scm.com/">Git</a> and <a href="https://github.com">GitHub</a>
are some of the most popular tools
developers and others use to manage
source code and documentation.</p>
<p>For the remainder of this course,
we will use Git and GitHub to
document what we learn as we
proceed to install the following
technologies:</p>
<ul>
<li>the Apache2 web server</li>
<li>the PHP scripting language</li>
<li>the MySQL relational database</li>
<li>the WordPress content management system</li>
<li>the Omeka content management system</li>
<li>the Koha integrated library system</li>
</ul>
<h2 id="git"><a class="header" href="#git">Git</a></h2>
<p><code>git</code> is a &quot;free and open source
distributed version control system.&quot;
While it is primarily used by
software developers, researchers, and
others to manage software code and
documentation,
it is also quite useful for other
projects that are text-based.
For example, this entire handbook
is written in a text-editor,
marked up in <a href="https://www.markdownguide.org/">Markdown</a>,
managed using <code>git</code>, and
publicly stored on a
<a href="https://github.com/cseanburns/systems-librarianship">GitHub repository</a>.</p>
<h2 id="github"><a class="header" href="#github">GitHub</a></h2>
<p>GitHub is a hosting site for projects
and repositories managed using <code>git</code>.
Other <code>git</code>-based hosting sites exist,
such as <a href="https://about.gitlab.com/">GitLab</a>, and
it is also possible to create self-hosted
repositories.
GitHub and GitLab provide social
features to enhance collaboration
on projects.
Each service has its own strengths,
and these differences largely come into play
with more advanced usage of <code>git</code>.
The basics among them are the same, though.</p>
<h2 id="markdown"><a class="header" href="#markdown">Markdown</a></h2>
<p>Markdown is a simplified and
highly versatile <em>markup</em> language.
Text marked up with Markdown can be
converted to other formats,
including HTML, PDF, DOCX, ODT, EPUB,
and more.
The basic formatting options offered
by Markdown include:</p>
<ul>
<li>headings</li>
<li>bold</li>
<li>italic</li>
<li>blockquote</li>
<li>ordered lists</li>
<li>unordered lists</li>
<li>code</li>
<li>links</li>
<li>images</li>
<li>horizontal rule</li>
</ul>
<p>More formatting options exist and
are listed in a helpful
<a href="https://www.markdownguide.org/cheat-sheet/">cheatsheet</a>.</p>
<p>When you write your documentation,
you will mark it up with Markdown.
It doesn't require a lot.
The majority of the time,
I only use the above elements
(rarely do I use the images
or the horizontal rule elements).
Here is an example of a file
marked up with Markdown:</p>
<pre><code># Title

## Subtitle

This is a paragraph. Just add an empty line between
paragraphs to create new paragraphs.

For example, this is the second paragraph. I'm following
this paragraph with an unordered list:

- I can write in **bold** or use *italics*.
- I can add a [link to someplace](https://example.com).
- I can add `code` in a sentence with backticks.
- Next I use a blockquote to **not** quote Benjamin
  Franklin, who it is often attributed to, but to probably
  quote Xun Kuang, a [fourth century Confucian
  philosopher](https://www.fi.edu/benjamin-franklin/7-things-benjamin-franklin-never-said):

&gt; Tell me and I forget. Teach me and I remember. Involve me
&gt; and I learn. --Not Benjamin Franklin and probably Xun
&gt; Kuang

And finally, a code block starts with three backticks on
their own line, followed by the code (or any kind of
pre-formatted text), followed by three closing backticks on
a their own line.
</code></pre>
<p>When you sync your documentation
to your GitHub,
your Markdown files will automatically
be rendered into HTML.
To facilitate it,
name your files in a systematic way and
use the <strong>.md</strong> file extension.
For example, when we install the Apache2
web server,
you can name it <strong>apache2-documentation.md</strong>.</p>
<h2 id="motivation"><a class="header" href="#motivation">Motivation</a></h2>
<p>We will be using these technologies
for four primary reasons.
First, these technologies see
widespread usage in the technology sector,
and this is true for library specific projects.
For example, the software code for the
Koha integrated library system is managed
with git and <a href="https://github.com/Koha-Community/Koha">stored on GitHub</a>.
So is <a href="https://github.com/omeka/Omeka">Omeka</a>.
WordPress also has a presence
on <a href="https://github.com/WordPress/WordPress">GitHub</a>.
Therefore I think it's important to
acquire some hands-on experience with
<code>git</code> and GitHub because it helps one
become part of those communities,
even if we have no intention to
contribute code to these projects.</p>
<p>Second, we will soon install and
configure these projects on our servers,
and doing so involves complicated processes.
Documenting how we install
and configure them will help us reproduce
the steps at later times.
For example, I used to install, configure,
and setup Omeka for one of our LIS courses,
but I only had to do so once a year.
There was no way that I would remember
the installation process each year, but
by keeping detailed notes,
I was easily able to reproduce my steps
from the prior year.
This saved me tons of time.</p>
<p>Documentation can also serve to enhance
our workflows.
I was able to use my Omeka
notes to create scripts
to automate parts of the
configuration process.
For example, you can read
through my scripts for setting up
<a href="https://github.com/cseanburns/omeka_admin">Omeka for LIS 602</a>
on GitHub.
Even if you don't code,
documentation can still improve
your workflows.</p>
<p>Third, the process of documenting
a complex series of steps
augments learning.
It's a way to reflect on our tasks and
to develop an eye for detail.</p>
<p>Lastly, I would know so much less
than I do about Linux and about
all these technologies if I hadn't
had access to the documentation efforts
that other people have contributed and
added to the web.
By sharing our notes on GitHub,
we contribute back to that ecosystem.</p>
<h2 id="how-to-document"><a class="header" href="#how-to-document">How to Document</a></h2>
<p>Because you will be
documenting technical information,
it will be important
to take notes of the commands
that you will be learning
and using in this course
and document those notes
in GitHub.</p>
<p>However,
as importantly,
you will want to describe
the processes you use
in learning Linux,
git, and more.
Therefore,
you should not just
record your commands.
You should also describe
what the commands do and
why you run various commands.
Use this book as an example,
which itself arose out of 
documenting the steps
needed to accomplish the goals
for this course.</p>
<h2 id="setup-git-and-github"><a class="header" href="#setup-git-and-github">Setup Git and GitHub</a></h2>
<p>The steps we'll take to begin
using Git and GitHub will be:</p>
<ol>
<li>Create an account on GitHub
<ul>
<li>be sure to setup two factor authentication</li>
</ul>
</li>
<li>Create a repository for your documentation</li>
<li>Create a markdown file to begin documenting</li>
<li>Begin documenting your process</li>
<li>Once you have documented your process, you can commit your file to your repository</li>
</ol>
<p>You can edit and commit files
directly on GitHub.
Later I will show you how to
manage your GitHub documentation
from the command line
on your Linux virtual machines.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="learning-the-command-line"><a class="header" href="#learning-the-command-line">Learning the Command Line</a></h1>
<p>It's obviously more common for people today
to learn how to use a computer via a 
graphical user interface (GUI), but
there are benefits to learning a
command line interface (CLI).
In this section,
we learn some of the basics
of using the <a href="https://en.wikipedia.org/wiki/Bash_(Unix_shell)">Bash shell</a> as our CLI.
Our primary goal is to learn how
to use the CLI as a file manager and
to perform some text editing.
However, if you find this interface appealing,
know that Bash is a
<a href="https://www.redhat.com/sysadmin/learn-bash-scripting">full-fledged programming language</a>, and
I encourage you to explore it as a scripting language.</p>
<p>There are three reasons,
from a systems administration/librarianship
point of view,
to prefer the CLI over the GUI.</p>
<ul>
<li>First, the GUI entails extra software, and the more software we have on a
server, the more resources (memory, CPU, storage, etc) that software
consumes. We would much rather have our machine's resources being used to
provide the services we build them to do than to run irrelevant software.</li>
<li>Second, the extra software a GUI requires means that we expose our systems to
additional security risks. That is, every time we install more software on
our servers, the server becomes more vulnerable because all software is buggy.
This means that we want to be conservative, careful, and protective of our
systems. This is especially true for production systems.</li>
<li>Third, graphical user interfaces do not provide a good platform for
automation, at least not remotely as well as command line interfaces do.
Working on the command line, because it is a text-based environment, in what is
known as a <a href="https://en.wikipedia.org/wiki/Unix_shell">shell</a>, is a reproducible process. That is not as easily
true in a GUI.</li>
</ul>
<p>Fortunately, Linux, and
many other Unix-like operating systems,
have the ability to operate without graphical user interfaces.
This is partly the reason why these operating systems
have done so well in the server market.</p>
<p>In this section,
our focus is learning the command line environment.
We will do this using the Bash shell.
We will learn how to use the shell,
how to navigate around the filesystem,
how to perform basic tasks, and
explore other functions and utilities
the shell has to offer.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="learn-the-command-line-interface-cli"><a class="header" href="#learn-the-command-line-interface-cli">Learn the Command Line Interface (CLI)</a></h1>
<h2 id="introduction-4"><a class="header" href="#introduction-4">Introduction</a></h2>
<p>There are two major interfaces
that we use to interact with our computers.
The most common interface is the 
graphical user interface, or GUI.
This interface largely emphasizes
non-textual interaction,
such as the mouse, fingers (touch screens),
remote controls (e.g., smart TVs),
and more recently,
wearable tech such as
VR headsets and like.
All of the above mechanisms for interacting
with our computer systems are worthwhile, but
more importantly, they are all suited to
specific ranges of engagement with our computers.
That is,
<a href="https://doi.org/10.7551/mitpress/7221.001.0001">they <em>afford</em> certain kinds of actions</a>
(Dourish, 2001).</p>
<p>The other major way of interfacing with
our computers is via the
command line interface, or CLI.
The CLI is also suited to
specific ranges of engagement, and
it's the kind of engagement that 
allows greater control over
the fundamental uses of our systems.</p>
<p>One reason the CLI provides greater
control over our systems is because
the interaction is text-based.
Text-based interaction requires more
specificity than graphical-based interaction.
By that I mean, it requires us to provide
written instructions to a computer and
to know what instructions to give it
when we want the computer to perform
some specific action.
This means that we have to memorize
some common instructions in order to
use our systems.
This is not necessarily difficult because
many of the most common instructions,
or <em>commands</em>,
are mnemonic, but
it does take some getting used to.</p>
<p>A second reason the CLI provides greater
control over the system is that because
it's text-based,
it can be automated.
We will not cover programming
in this work or course,
but know that all the commands
that we will learn can be put
in a text file,
made into an executable file,
and run like a program.
This makes text-based interaction
rather powerful.</p>
<p>The big gotcha with a text-based
interface with the computer
is that it requires specificity.
We have to be fairly exact
in our commands.
This exactitude requires
an <strong>attention to detail</strong>.
Little things like misplaced punctuation,
missing punctuation,
incorrect capitalization or indentation,
and misspelled words
can cause errors or
prevent the execution of our programs.
It's important to proceed slowly
on the command line and
to <strong>pay attention to the messages</strong>
the screen displays
when we run commands.</p>
<h2 id="basic-commands"><a class="header" href="#basic-commands">Basic Commands</a></h2>
<p>In light of that,
I have developed two programs that
will help you learn and remember
basic Linux shell commands.
The commands that I'll ask you to
learn encompass less than 0.3%
of the commands that are available
on a Linux system, but
they are the most commonly used commands.
Many of the other commands that are
available are for very specific purposes.
I'd estimate
that despite having used the Linux
command line for over 20 years,
I've barely used 20% of them, and
I might be stretching my estimate.</p>
<p>The first set of commands that
I'll ask you to learn and
practice include the following:</p>
<pre><code>list files and directories.................. ls
print name of current/working directory..... pwd
create a new directory...................... mkdir
remove or delete an empty directory......... rmdir
change directory............................ cd
create an empty file........................ touch
print characters to output.................. echo
display contents of a text file............. cat
copy a file or directory.................... cp
move or rename a file or directory.......... mv
remove or delete a file or directory........ rm
</code></pre>
<p>You will practice these commands using
the program that I wrote
called <a href="https://github.com/cseanburns/learn-the-commandline/blob/main/learn-the-cli">learn-the-cli</a>
(I will show you how to install
this and the other programs shortly).</p>
<p>I also developed a <a href="https://github.com/cseanburns/learn-the-commandline/blob/main/flashcards">flashcards</a>
program that will help you learn,
or at least become familiar,
with an additional 45 commands.
(This program is based on one created
by someone else for a different purpose;
see source code link above for credit).
I'll explain these additional commands
as we proceed through the semester.
In the meantime,
I'll ask that you periodically run
the <code>flashcards</code> program to
familiarize yourself with these commands,
which includes the ones in the list above
but also a few additional ones.</p>
<h2 id="the-filesystem"><a class="header" href="#the-filesystem">The Filesystem</a></h2>
<p>In addition to the various commands
that I'll ask you to learn,
you will also have to learn the
structure of the Linux filesystem.
A filesystem has several meanings, but
in this context,
I refer to where the directories
on the Linux system are placed.
I find this to be the most difficult
thing that new Linux users have to learn
for a couple of reasons.
First, modern operating systems tend
to hide (abstract away)
the filesystem from their users.
So even though, for example,
macOS is Unix,
many macOS users that I have taught
are completely unfamiliar with the
layout of directories on their system.
This is because,
per my observations,
macOS Finder does not show
the filesytem by default these days.
Instead it shows its users some common
locations for <strong>folders</strong>.
This might make macOS more usable to
most users, but
it makes learning the system more difficult.</p>
<p>What's common for both macOS and Linux
operating systems is a filesytem based on a
tree-like structure.
These filesystems begin at what's called a
<strong>root</strong> location.
The <strong>root</strong> location is referenced by
a forward slash: <code>/</code>.
All directories <strong>branch</strong> off from root.
The location to any directory is called
a <strong>PATH</strong>.
For example, our home directories on
Linux are located at the following PATH:</p>
<pre><code>/home/USER
</code></pre>
<p>That PATH begins at the root directory <code>/</code>,
proceeds to the directory named <code>home</code>, and
then ends in our <strong>USER</strong> directory,
which will share the same name as our usernames.
As an example,
if my username on a Linux system is <strong>sb</strong>,
then my home directory will be located at:</p>
<pre><code>/home/sb
</code></pre>
<p>It is a little different for Windows users.
Since Windows is not Unix-like,
it uses a different filesystem hierarchy.
Many Windows users might be familiar with
the basics, such as the <strong>C:</strong> drive for the
main storage device or the <strong>D:</strong> drive for
an added USB stick.
As such, the Windows operating system
uses multiple root directories (C:, D:, E:, etc.).
I encourage you to read the following article on
<a href="https://www.redhat.com/sysadmin/linux-filesystem-windows">A quick introduction to the Linux filesystem for Windows users</a>.
The article is published by <em>Red Hat</em>,
which makes its own Linux distribution.</p>
<p>In short, learning the Linux filesystem
requires adopting a new mental model
about how the operating system organizes
its directories and files.
Like learning the basic commands,
it's not too hard,
but it may take time and practice
before it sticks.
To help learn it,
I wrote an additional program that
will let you practice navigating around
the Linux filesystem and making some
changes to it.
The program is called
<a href="https://github.com/cseanburns/learn-the-commandline/blob/main/learn-the-filesystem">learn-the-filesystem</a>.
Before you use this program,
I would like to encourage you to read
another <em>Red Hat</em> article on
<a href="https://www.redhat.com/sysadmin/navigating-filesystem-linux-terminal">Navigating your filesystem in the Linux terminal</a>.
It includes sections that my program will cover
that include:</p>
<ul>
<li>viewing file lists</li>
<li>opening a folder (aka, a directory)</li>
<li>closing a folder</li>
<li>navigating directories</li>
<li>absolute paths</li>
</ul>
<h2 id="bash-the-bourne-again-shell"><a class="header" href="#bash-the-bourne-again-shell">Bash: The Bourne Again Shell</a></h2>
<p>I should point out that the
command line interface that we
are using on our Linux servers
is provided by a <a href="https://en.wikipedia.org/wiki/Unix_shell">shell</a>.
A shell is &quot;both an interactive
command language and a scripting
language&quot; (see link above).
We will use the shell strictly
as a <a href="https://en.wikipedia.org/wiki/Command_language">command language</a>,
but if you're interested someday,
I'd encourage you to explore Bash
as a <a href="https://en.wikipedia.org/wiki/Scripting_language">scripting language</a>
(I personally script in Bash quite a lot, and the
learn-the-cli and flashcard programs
were written in <code>bash</code>).
There are a variety of shells
available for Linux and other Unix-like
operating systems, but
the most popular one and
the one we will be using is called
<a href="https://en.wikipedia.org/wiki/Bash_(Unix_shell)">Bash</a>.</p>
<p>Bash is an acronym for the
<em>Bourne Again Shell</em> because it's
based on the original Unix shell
called the Bourne shell,
written by
<a href="https://en.wikipedia.org/wiki/Stephen_R._Bourne">Stephen Bourne</a>.
Bash itself was written by
<a href="https://en.wikipedia.org/wiki/Brian_Fox_(computer_programmer)">Brian Fox</a>.</p>
<p>I think it's important to know
the history of the technologies
that we use, and
Bash has a super interesting
history that pre-exists Linux.
Therefore, I highly encourage you
listen to the
<a href="https://www.redhat.com/en/command-line-heroes">Command Line Heroes</a> episode titled
<a href="https://www.redhat.com/en/command-line-heroes/season-3/heroes-in-a-bash-shell">Heroes in a Bash Shell</a>,
narrated by
<a href="https://saron.io/">Saron Yitbarek</a>.
The episode recounts Brian Fox's
history with the Bash shell
while he worked for the
<a href="https://en.wikipedia.org/wiki/Free_Software_Foundation">Free Software Foundation</a>
in the 1980s.</p>
<h2 id="conclusion-3"><a class="header" href="#conclusion-3">Conclusion</a></h2>
<p>We will spend the next few weeks
practicing these commands and
learning the filesystem.
We'll do this because knowing
these things is integral to
accomplishing everything else in this work,
including installing and setting up
our content management systems and
the integrated library system.</p>
<p>In the video for this week,
I'll show you how to install the three
programs that I wrote or modified.
We will use <code>git</code> to download them.
The we will move the programs to a
specific directory in our
executable PATH.
This will allow us to run them
simply by typing their names.</p>
<h2 id="installation"><a class="header" href="#installation">Installation</a></h2>
<p>To install my practice programs,
login to your Linux virtual instances, and
run the following commands.
You will learn more about these commands shortly.</p>
<p>First, let's take a look at the contents
of your home directory
(the default directory you're in when
you connect to your virtual machine):</p>
<pre><code>ls
</code></pre>
<p>Most likely,
nothing will be listed.</p>
<p>Now let's retrieve the programs
using the <code>git</code> command:</p>
<pre><code>git clone https://github.com/cseanburns/learn-the-commandline.git
</code></pre>
<p>Run the <code>ls</code> command again, and
you'll see a new directory called
<code>learn-the-commandline</code>:</p>
<p><code>ls</code></p>
<p>Next, copy the programs to an executable path:</p>
<pre><code>sudo cp learn-the-commandline/* /usr/local/bin
</code></pre>
<p>Run the first program and
work through it in order to learn
some of the basic commands:</p>
<pre><code>learn-the-cli
</code></pre>
<p>When ready,
run the second program in order
to learn about the Linux filesystem:</p>
<pre><code>learn-the-filesystem
</code></pre>
<p>Finally, periodically run the
<code>flashcards</code> program to refresh your
memory of the basic commands, plus
some other commands that you'll learn
about soon:</p>
<pre><code>flashcards
</code></pre>
<p>After working through the
<code>learn-the-cli</code> program a few times,
you can continue
to practice with the
<code>learn-the-cli-module</code> program.
This is a modified version that
allows you to focus specific
learning modules.</p>
<h3 id="resources"><a class="header" href="#resources">Resources</a></h3>
<p>Here are some additional resources
for learning Bash and Linux shell commands:</p>
<ul>
<li><a href="https://explainshell.com">explainshell.com</a> : helps explain the parts of a shell command</li>
<li><a href="https://www.shellcheck.net/">shellcheck.net</a> : helps debut a shell script</li>
<li><a href="https://github.com/jlevy/the-art-of-command-line">The Art of the Command Line</a> : describes the fundamentals of Bash and the command line</li>
</ul>
<h2 id="references-1"><a class="header" href="#references-1">References</a></h2>
<p>Dourish, P. (2001). <em>Where the Action Is: The Foundations of
Embodied Interaction</em>. MIT Press.
<a href="https://doi.org/10.7551/mitpress/7221.001.0001">https://doi.org/10.7551/mitpress/7221.001.0001</a></p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="text-editors"><a class="header" href="#text-editors">Text editors</a></h1>
<p>As we learn more about
how to work on the command line,
we will acquire the need to write
in plain text or edit
configuration files.
Most configuration files for Linux
applications exist
in the <code>/etc</code> directory,
and are regular text files.
For example,
later in the semester
we will install the
<a href="https://httpd.apache.org/">Apache Web Server</a>, and
we will need to edit
Apache's configuration
files in the process.</p>
<p>In order to edit and save text files, 
we need a text editor.
Programmers use text editors
to write programs,
but because programmers 
often work in
graphical user environments,
they may often use 
graphical text editors or graphical
<a href="https://en.wikipedia.org/wiki/Integrated_development_environment">Integrated Development Environments (IDEs)</a>. 
It might be that if you work
in systems librarianship,
that you will often use
a graphical text editor,
but knowing something about
how to use command line-based
editors can be helpful.</p>
<h2 id="what-is-a-plain-text"><a class="header" href="#what-is-a-plain-text">What is a Plain Text?</a></h2>
<p>Plain text is the most basic
way to store human-readable textual information.
Whenever we use a word processor program,
like Microsoft Office,
we are creating a complex series
of files that instruct the Office application
how to display the contents of the file as
well as how the contents are formatted
and arranged.
This can easily be illustrated by
using an archive manager to extract
the contents of a <strong>.docx</strong> file.
Upon examination,
most of the files in a single <strong>.docx</strong>
file are plain text that are
marked up in XML.
The files are packaged as a <strong>.docx</strong>
file and then rendered by an application,
commonly Microsoft Word,
but any application
that can read <strong>.docx</strong> files will do.</p>
<p>A plain text file only contains
<a href="https://www.rapidtables.com/code/text/ascii-table.html">plain text</a>.
Its only arrangement is from top
to bottom.
It does not allow for any kind of
additional formatting,
and it does not include media.
It is the closest thing the digital
has to output produced by a typewriter, but
a <a href="https://www.youtube.com/watch?v=jxkygWI-Wfs">typewriter that's connected to the internet</a>.</p>
<p>A lot of content is written in plain text.
For example, HTML is written in plain text
and the web browser uses the HTML markup to
render how a page will look.</p>
<pre><code>&lt;p&gt;This is using a HTML paragraph tag.
The web browser would normally render this like
the other paragraphs on this page.
However, it's written in a code block,
which allows us to display the HTML tags
and appear as if it's real source code.&lt;/p&gt;
</code></pre>
<p>The rendered result is not plain text but HTML,
just like the rendered result of all those
XML files in a <strong>.docx</strong> file are not
plain text but a <strong>.docx</strong> file.
Softare is written in plain text files
because programming languages cannot
evaluate content that is not just text.
Those of you who have learned how to
use the R programming language wrote
your R code in plain text likely using
the RStudio IDE.
For our purposes,
we need plain text files to
modify configuration files for
the various programs that we will
install later.</p>
<h2 id="why-edit-in-plain-text"><a class="header" href="#why-edit-in-plain-text">Why Edit in Plain Text</a></h2>
<p>Most of the time when we configure software,
we might do it, for example,
by using our mouse to find the settings
menu in some application that we are using.
All that does, for the most part,
is make changes to some text file somewhere.
We will have to be more direct since
we are working on the command line only.
That is, the kind of settings configurations we
will do will require editing a variety
of plain text files that the programs
will use to modify how they work.
Often the settings for programs can only
be modified by editing their plain text
configuration files.</p>
<h2 id="nano"><a class="header" href="#nano"><code>nano</code></a></h2>
<p>The <a href="https://www.nano-editor.org/"><code>nano</code></a> text editor
is a fairly user-friendly
command line text editor, but
it requires some learning
as a new command line user.
The friendliest thing about
<code>nano</code> is that it is modeless,
which is what you're
already accustomed to using.
This means <code>nano</code> can be used
to enter and manipulate text
without changing to
insert or command mode.
It is also friendly because,
like many graphical text editors
and software,
it uses control keys
to perform its operations.</p>
<blockquote>
<p>A modal text editor has modes such as insert mode or
command mode. In insert mode, the user types text as
anyone would in any kind of editor or word processor. The
user switches to command mode to perform operations on the
text, such as find and replace, saving, cutting and
pasting but cannot insert text as they would in insert
mode. Switching between modes usually involves pressing
some specific keys. In Vim and ed(1), my text editors of
choice, the user starts in command mode and switches to
insert mode by pressing the letter <strong>i</strong> or the letter
<strong>a</strong>. The user may switch back to command mode by
pressing the <strong>Esc</strong> key in Vim or by pressing the period
in a new line in ed(1).</p>
</blockquote>
<p>The tricky part to learning <code>nano</code> is that
the control keys are assigned
to different keystroke combinations
than what
many graphical editors
(or word processors) use
by convention today.
For example,
instead of Ctrl-c or Cmd-c to copy text,
in <code>nano</code> you press the <code>M-6</code> key
(press <code>Alt, Cmd, or Esc key</code>
and <code>6</code>) to copy.
Then to paste,
you press <code>Ctrl-u</code> instead
of the more common <code>Ctrl-v</code>.
Fortunately, <code>nano</code> lists
the shortcuts at the bottom
of the screen.</p>
<blockquote>
<p><code>nano</code> is a text-editor with old origins. Specifically, it's a fork of the
Unix <code>pico</code> editor. The keyboard shortcuts used by <code>nano</code> were carried over
from the <code>pico</code> editor. These keyboard shortcuts were designed before the
<a href="cua">Common User Access</a> guidelines helped standardize the common keyboard
shortcuts we use today for opening, saving, closing, etc files.</p>
</blockquote>
<p>The shortcuts listed
need some explanation, though.
The carat mark is shorthand
for the keyboard's <strong>Control (Ctrl)</strong> key.
Therefore to <strong>Save As</strong> a file,
we <strong>write</strong> out the file
by pressing <code>Ctrl-o</code>
(although <code>Ctrl-s</code> will work, too).
The <strong>M-</strong> key is also important,
and depending on your keyboard
configuration,
it may correspond to your
<code>Alt, Cmd, or Esc</code> keys.
To search for text,
you press <code>^W</code>,
If your goal is to copy,
then press <strong>M-6</strong>
to copy a line.
Move to where you want
to paste the text,
and press <strong>Ctrl-u</strong>
to paste.</p>
<p>We can start <code>nano</code> simply
by typing <code>nano</code> on the command line.
This will open a new, unsaved file
with no content.
Alternatively, we can start <code>nano</code>
by specifying a file name after typing <code>nano</code>.
For example, if I want to open a file
called <strong>example.txt</strong>,
then I type the following command:</p>
<pre><code>nano example.txt
</code></pre>
<p>If the file doesn't exist,
this will create it.
If it does exit, then
the above command will open it.</p>
<p>One of the other tricky things about <code>nano</code>
is that the <em>menu bar</em>
(really just a crib sheet, so to speak)
is at the bottom of
the screen instead of at the top,
which is where we are mostly accustomed to
finding it these days.
Also, the <code>nano</code> program does not provide
pop up dialog boxes.
Instead, all messages from <code>nano</code>,
like what to name a file when we save it,
appear at the bottom of the screen.</p>
<p>Lastly, <code>nano</code> also uses distinct terminology
for some of its functions.
The most important function to remember
is the <strong>Write Out</strong> function,
which means to save.</p>
<p>For the purposes of this class,
that's all you really
need to know about <code>nano</code>.
Use it and get comfortable writing in it.
Some quick tips:</p>
<ol>
<li><code>nano file.txt</code> will open and display the file named <strong>file.txt</strong>.</li>
<li><code>nano</code> by itself will open to an empty page.</li>
<li>Save a file by pressing <code>Ctrl-o</code>.</li>
<li>Quit and save by pressing <code>Ctrl-x</code>.</li>
<li>Be sure to follow the prompts at the bottom of the screen.</li>
</ol>
<h2 id="other-editors"><a class="header" href="#other-editors">Other Editors</a></h2>
<p>It's important to be familiar with
<code>nano</code> because it's generally the default
text editor on Linux operating systems nowadays.
However, if you are interested in using a
command line text editor with familiar keyboard shortcuts,
then there are others you may want to try.
In the meantime,
here are a couple of more friendly editors
to test out.</p>
<h3 id="tilde"><a class="header" href="#tilde">tilde</a></h3>
<p>The <a href="tilde"><code>tilde</code></a> text editor is a user friendly
text editor that uses conventional keybindings
(like ctrl-s for saving, etc).</p>
<p>You can install it via the <code>apt</code> command:</p>
<pre><code>sudo apt install tilde
</code></pre>
<h3 id="micro"><a class="header" href="#micro">micro</a></h3>
<p>The <a href="micro"><code>micro</code></a> text editor is also user friendly,
and, like <code>tilde</code>, uses conventional key bindings.
Press <strong>ctrl-g</strong> to enter its help menu.
Use your arrow keys to read through it and
learn more about its capabilities and its functions.
Press <strong>ctrl-q</strong> to exit the help menu.</p>
<p>You can install it via the <code>apt</code> command:</p>
<pre><code>sudo apt install micro
</code></pre>
<h2 id="ed1-vivim-emacs"><a class="header" href="#ed1-vivim-emacs">ed(1), Vi/Vim, Emacs</a></h2>
<p>ed(1), Vi/Vim, and Emacs are
the traditional Unix and Linux text editors.
I first started using Linux
because I found <code>emacs</code>,
but sometime during my early
Linux years,
I switched to <code>vim</code>,
which is a descendent of the
<code>vi</code> text editor,
which itself is a descendent
of the <code>ed</code> editor.
None of these editors are
user-friendly, but
they are extremely powerful
once you learn them, and
they are still quite popular
(well, <code>ed</code> probably isn't
all that popular).
There are plenty of online
resources that provide
tutorials on getting started with
these text editors.
I won't teach how to use them
because it will take too much time,
but they are worth knowing about
because all three are important
parts of Unix and Linux history.</p>
<h2 id="conclusion-4"><a class="header" href="#conclusion-4">Conclusion</a></h2>
<p>In the prior lesson,
we learned how to use the
Bash interactive shell.
We will continue to do that,
but in the meantime,
in this lesson,
we begin to learn how to use
a command line text editor, <code>nano</code>.
I also introduce you to friendlier
editors (<code>tilde</code> and <code>micro</code>)
that you might prefer over <code>nano</code>.
We will use a text editor to edit
configuration files and publish
text to GitHub.
It's your choice what
you want to use.</p>
<h2 id="my-nanorc"><a class="header" href="#my-nanorc">My .nanorc</a></h2>
<p>You can configure <code>nano</code>
to look and behave in certain ways.
If you want to mimic
the setup I have,
then create a file called
<strong>.nanorc</strong> in your home directory,
and add the following to it:</p>
<pre><code># set element fgcolor,bgcolor
set titlecolor brightwhite,blue
set statuscolor brightwhite,green
# set errorcolor brightwhite,red
set selectedcolor brightwhite,magenta
# set stripecolor ,yellow
set numbercolor cyan
set keycolor cyan
set functioncolor green

set speller &quot;aspell -x -c&quot;

## When soft line wrapping is enabled, make it wrap lines at blanks
## (tabs and spaces) instead of always at the edge of the screen.
set atblanks

## Use auto-indentation.
set autoindent

## Back up files to the current filename plus a tilde.
# set backup

## The directory to put unique backup files in.
# set backupdir &quot;~/.backup&quot;

## Use bold text instead of reverse video text.
set boldtext

## Remember the used search/replace strings for the next session.
set historylog

## Display line numbers to the left of the text.
set linenumbers

## Enable vim-style lock-files.  This is just to let a vim user know you
## are editing a file [s]he is trying to edit and vice versa.  There are
## no plans to implement vim-style undo state in these files.
set locking

## Remember the cursor position in each file for the next editing session.
set positionlog

## Do extended regular expression searches by default.
set regexp

## Allow nano to be suspended.
set suspend

## Use this tab size instead of the default; it must be greater than 0.
set tabsize 8

## Convert typed tabs to spaces.
set tabstospaces
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="searching-with-grep"><a class="header" href="#searching-with-grep">Searching with grep</a></h1>
<p>We have available some powerful utilities and programs
to process, manipulate, and analyze text files.
In this section, we will focus on the <code>grep</code> utility,
which offers some advanced methods for searching
the contents of text files.</p>
<h2 id="grep"><a class="header" href="#grep">Grep</a></h2>
<p>The <code>grep</code> command is one of my most often used commands.
The purpose of <code>grep</code> is to &quot;print lines that match patterns&quot;
(see <code>man grep</code>).
In other words, it searches text, and
it's super powerful.</p>
<p><code>grep</code> works line by line.
So when we use it to search a file for a <strong>string</strong> of text,
it will return the whole line that matches the string.
This <strong>line by line</strong> idea is part of the history of
Unix-like operating systems,
and it's important to remember that most utilities
and programs that we use on the commandline
are line oriented.</p>
<blockquote>
<p>&quot;A string is any series of characters that are interpreted
literally by a script. For example, 'hello world' and 'LKJH019283'
are both examples of strings.&quot; -- <a href="https://www.computerhope.com/jargon/s/string.htm">Computer Hope</a>.
More generally, it's a type of data structure. </p>
</blockquote>
<p>To visualize how <code>grep</code> works,
let's consider a file called
<strong>operating-systems.csv</strong> with content
as seen below:</p>
<pre><code>OS, License, Year
Chrome OS, Proprietary, 2009
FreeBSD, BSD, 1993
Linux, GPL, 1991
macOS, Proprietary, 2001
Windows NT, Proprietary, 1993
Android, Apache, 2008
</code></pre>
<p>We can use <code>grep</code> to search
for anything in that file.
Let's start with a search for the string <strong>Chrome</strong>.
Notice that even though the string <strong>Chrome</strong> only appears once,
and in one part of a line,
<code>grep</code> returns the entire line.</p>
<p><strong>Command:</strong></p>
<pre><code>grep &quot;Chrome&quot; operating-systems.csv
</code></pre>
<p><strong>Output:</strong></p>
<pre><code>Chrome OS, Proprietary, 2009
</code></pre>
<h3 id="case-matching"><a class="header" href="#case-matching">Case Matching</a></h3>
<p>Be aware that, <em>by default</em>, <code>grep</code> is case-sensitive,
which means a search for the string <strong>chrome</strong>,
with a lower case <strong>c</strong>,
would return no results.
However, many Linux command line utilities
can have their functionality extended
through command line options.
<code>grep</code> has an <code>-i</code> option
that can be used to
to ignore the case of the search string.
In the following examples,
<code>grep</code> returns nothing in the first search
since we do not capitalize the string <strong>chrome</strong>.
However, adding the <code>-i</code> option results in success
since <code>grep</code> is instructed to ignore case:</p>
<p><strong>Command:</strong></p>
<pre><code>grep &quot;chrome&quot; operating-systems.csv
</code></pre>
<p><strong>Output:</strong></p>
<p>None.</p>
<p><strong>Command:</strong></p>
<pre><code>grep -i &quot;chrome&quot; operating-systems.csv
</code></pre>
<p><strong>Output:</strong></p>
<pre><code>Chrome OS, Proprietary, 2009
</code></pre>
<h3 id="invert-matching"><a class="header" href="#invert-matching">Invert Matching</a></h3>
<p><code>grep</code> can do inverse searching.
That is, we can search for lines
that <strong>do not</strong> match our string 
using the <code>-v</code> option.
Options can often be combined
for additional functionality.
We can combine <code>-v</code> to inverse search
with <code>-i</code> to ignore the case.
In the following example,
we search for
all lines that
do not contain the
string <strong>chrome</strong>:</p>
<p><strong>Command:</strong></p>
<pre><code>grep -vi &quot;chrome&quot; operating-systems.csv
</code></pre>
<p><strong>Output:</strong></p>
<pre><code>FreeBSD, BSD, 1993
Linux, GPL, 1991
iOS, Proprietary, 2007
macOS, Proprietary, 2001
Windows NT, Proprietary, 1993
Android, Apache, 2008
</code></pre>
<h3 id="regular-expressions"><a class="header" href="#regular-expressions">Regular Expressions</a></h3>
<p>Sometimes data files,
like spreadsheets,
contain header columns in the
first row.
We can use <code>grep</code> to remove
the first line of a file by
inverting our search and
selecting all lines not matching
&quot;OS&quot; at the start of a line.
Here the carat key <code>^</code> is
a <strong>regex</strong> indicating the
start of a line.
Again, this <code>grep</code> command returns
all lines that do not match the
string <strong>os</strong> at the start of a line,
ignoring case:</p>
<p><strong>Command:</strong></p>
<pre><code>grep -vi &quot;^os&quot; operating-systems.csv
</code></pre>
<p><strong>Output</strong>:</p>
<pre><code>Chrome OS, Proprietary, 2009
FreeBSD, BSD, 1993
Linux, GPL, 1991
iOS, Proprietary, 2007
macOS, Proprietary, 2001
Windows NT, Proprietary, 1993
Android, Apache, 2008
</code></pre>
<p>Alternatively, since we know that
the string <strong>Year</strong> comes
at the end of the first line,
we can use <code>grep</code> to invert search for that.
Here the dollar sign key <code>$</code>
is a <strong>regex</strong> indicating the
end of a line.
Like the above,
this <code>grep</code> command returns all lines that
do not match the string <strong>year</strong>
at the end of a line,
ignoring case.
The result,
in this specific instance,
is exactly the same as the last command:</p>
<p><strong>Command</strong>:</p>
<pre><code>grep -vi &quot;year$&quot; operating-systems.csv
</code></pre>
<p><strong>Output</strong>:</p>
<pre><code>Chrome OS, Proprietary, 2009
FreeBSD, BSD, 1993
Linux, GPL, 1991
iOS, Proprietary, 2007
macOS, Proprietary, 2001
Windows NT, Proprietary, 1993
Android, Apache, 2008
</code></pre>
<p>The <code>man grep</code> page lists other options,
but a couple of other good ones include:</p>
<h3 id="count-matches"><a class="header" href="#count-matches">Count Matches</a></h3>
<p>Get a count of the matching lines
with the <code>-c</code> option.
For example,
let's get a total count of rows
in our file excluding the header
by adding the <code>-c</code> option:</p>
<pre><code>grep -vic &quot;year$&quot; operating-systems.csv
</code></pre>
<h3 id="alternate-matching"><a class="header" href="#alternate-matching">Alternate Matching</a></h3>
<p>We separate the strings with a vertical bar <code>|</code>
(the <strong>infix operator</strong>)
to match any string on either side.
This is similar to a Boolean OR search.
Since there's at least one match in the following string,
there is at least one result.</p>
<p>Here is an example where only one string
returns a true value since
the file contains <strong>bsd</strong> but not <strong>atari</strong>:</p>
<p><strong>Command:</strong></p>
<pre><code>grep -Ei &quot;(bsd|atari)&quot; operating-systems.csv
</code></pre>
<p><strong>Output:</strong></p>
<pre><code>FreeBSD, BSD, 1993
</code></pre>
<p>Here's an example where both strings evaluate to true:</p>
<p><strong>Command:</strong></p>
<pre><code>grep -Ei &quot;(bsd|gpl)&quot; operating-systems.csv
</code></pre>
<p><strong>Output:</strong></p>
<pre><code>FreeBSD, BSD, 1993
Linux, GPL, 1991
</code></pre>
<h3 id="whole-word-matching"><a class="header" href="#whole-word-matching">Whole Word Matching</a></h3>
<p>By default, <code>grep</code> will return results where the
string appears within a larger word,
like <strong>OS</strong> in <strong>macOS</strong>.</p>
<p><strong>Command:</strong></p>
<pre><code>grep -i &quot;os&quot; operating-systems.csv
</code></pre>
<p><strong>Output:</strong></p>
<pre><code>OS, License, Year
Chrome OS, Proprietary, 2009
iOS, Proprietary, 2007
macOS, Proprietary, 2001
</code></pre>
<p>However, we might want to limit results so that
we only return results where <strong>OS</strong> is a complete word.
To do that, we can surround the string with
special characters:</p>
<p><strong>Command:</strong></p>
<pre><code>grep -i &quot;\&lt;os\&gt;&quot; operating-systems.csv
</code></pre>
<p><strong>Output:</strong></p>
<pre><code>OS, License, Year
Chrome OS, Proprietary, 2009
</code></pre>
<p>Sometimes I find it hard to remember
the backslash and angle bracket combinations
because they're too much alike HTML syntax but
not exactly like HTML syntax.
Fortunately, <code>grep</code> has a <code>-w</code> option
to match whole words:</p>
<p><strong>Command:</strong></p>
<pre><code>grep -wi &quot;os&quot; operating-systems.csv
</code></pre>
<p><strong>Output:</strong></p>
<pre><code>OS, License, Year
Chrome OS, Proprietary, 2009
</code></pre>
<h3 id="context-matches"><a class="header" href="#context-matches">Context Matches</a></h3>
<p>Sometimes we want the context for a result;
that is,
we might want to print lines
that surround our matches.
For example,
to print the matching line plus the two lines
after the matching line using the <code>-A NUM</code> option,
where <strong>NUM</strong> equals the number of lines
to return after the matching line:</p>
<p><strong>Command:</strong></p>
<pre><code>grep -i &quot;linux&quot; -A2 operating-systems.csv
</code></pre>
<p><strong>Output:</strong></p>
<pre><code>Linux, GPL, 1991
macOS, Proprietary, 2001
Windows NT, Proprietary, 1993
</code></pre>
<p>Or, print the matching line plus the two lines
before the matching line using the <code>-B NUM</code> option:</p>
<p><strong>Command</strong></p>
<pre><code>grep -i &quot;linux&quot; -B2 operating-systems.csv
</code></pre>
<p><strong>Output:</strong></p>
<pre><code>Chrome OS, Proprietary, 2009
FreeBSD, BSD, 1993
Linux, GPL, 1991
</code></pre>
<p>We can combine many of the variations.
Here I search for the whole word <strong>BSD</strong>,
case insensitive, and
print the line before and the line after
the match:</p>
<p><strong>Command:</strong></p>
<pre><code>grep -iw -C1 &quot;bsd&quot; operating-systems.csv
</code></pre>
<p><strong>Output:</strong></p>
<pre><code>Chrome OS, Proprietary, 2009
FreeBSD, BSD, 1993
Linux, GPL, 1991
</code></pre>
<h3 id="halt-matching"><a class="header" href="#halt-matching">Halt Matching</a></h3>
<p>We can use another option to
stop returning results after some
number of hits.
Here I use <code>grep</code> to return
a search for the string &quot;proprietary&quot;
and stop after the first hit:</p>
<p><strong>Command:</strong></p>
<pre><code>grep -i -m1 &quot;proprietary&quot; operating-systems.csv
</code></pre>
<p><strong>Output:</strong></p>
<pre><code>Chrome OS, Proprietary, 2009
</code></pre>
<h3 id="returning-line-numbers"><a class="header" href="#returning-line-numbers">Returning Line Numbers</a></h3>
<p>We can add the <code>-n</code> option to
instruct <code>grep</code> to tell us the
line number for each hit.
Below we see that the string
&quot;proprietary&quot; is found on lines
2, 5, and 6.</p>
<p><strong>Command:</strong></p>
<pre><code>grep -in &quot;proprietary&quot; operating-systems.csv
</code></pre>
<p><strong>Output:</strong></p>
<pre><code>2:Chrome OS, Proprietary, 2009
5:macOS, Proprietary, 2001
6:Windows NT, Proprietary, 1993
</code></pre>
<h3 id="character-class-matching"><a class="header" href="#character-class-matching">Character Class Matching</a></h3>
<p>We can use <code>grep</code> to search for
patterns in strings instead of literal words.
Here we use what's called <strong>character classes</strong>
and <strong>repetition</strong> to search for five letter words
that contain any English character <strong>a through z</strong>:</p>
<p><strong>Command:</strong></p>
<pre><code>grep -Eiw &quot;[a-z]{5}&quot; operating-systems.csv
</code></pre>
<p><strong>Output:</strong></p>
<pre><code>Linux, GPL, 1991
macOS, Proprietary, 2001
</code></pre>
<p>Or four letter numbers,
which highlights the years:</p>
<p><strong>Command:</strong></p>
<pre><code>grep -Eiw &quot;[0-9]{4}&quot; operating-systems.csv
</code></pre>
<p><strong>Output:</strong></p>
<pre><code>Chrome OS, Proprietary, 2009
FreeBSD, BSD, 1993
Linux, GPL, 1991
macOS, Proprietary, 2001
Windows NT, Proprietary, 1993
Android, Apache, 2008
</code></pre>
<p><code>grep</code> can also search for words that
begin with some letter and end with some letter
and with a specified number of letters between.
Here we search for words that start with <strong>m</strong>,
end with <strong>s</strong>, and have three letters in the middle:</p>
<p><strong>Command:</strong></p>
<pre><code>grep -Eiw &quot;m.{3}s&quot; operating-systems.csv
</code></pre>
<p><strong>Output:</strong></p>
<pre><code>macOS, Proprietary, 2001
</code></pre>
<h2 id="practice"><a class="header" href="#practice">Practice</a></h2>
<p>Let's use the <code>grep</code> command
to investigate bibliographic data.
Our task is to:</p>
<ol>
<li>Search <em>Scopus</em>.</li>
<li>Download a <a href="https://www.bibtex.org/Format/"><em>BibTeX</em></a> file from <em>Scopus</em> as a .bib file.</li>
<li>Use the <code>grep</code> command to search the downloaded <em>BibTeX</em> file, which should be named <strong>scopus.bib</strong>.</li>
</ol>
<h3 id="download-data"><a class="header" href="#download-data">Download Data</a></h3>
<p>I'm using Scopus data
in this example, but
other bibliographic data can
be downloaded from other databases.</p>
<ol>
<li>From your university's website, find Scopus.</li>
<li>In Scopus, perform a search.</li>
<li>Select the documents you want to download.</li>
<li>Click on the <strong>Export</strong> button.</li>
<li>Click on <em>BibTeX</em> under the listed file types.</li>
<li>Select all <strong>Citation Information</strong> and <strong>Bibliographic Information</strong>. Select more in interested.</li>
<li>Click on <strong>Export</strong>.</li>
</ol>
<p>The file should be saved
to your Downloads folder
and titled <strong>scopus.bib</strong>.</p>
<h3 id="upload-to-gcloud"><a class="header" href="#upload-to-gcloud">Upload to gcloud</a></h3>
<p>To upload to <code>gcloud</code>,
you use a similar command
as the <code>gcloud compute ssh</code>
command that you use
to connect to your servers.</p>
<p>However, there are some differences.
The <code>gcloud</code> copy command uses
<code>scp</code> instead of <code>ssh</code> and
then specifies the local file to transfer
and the remote location.
The following command
copies the local file
titled <strong>file_name</strong>
to the remote server.
Simply replace the file name,
server, zone, and project names
with those specific
to your virtual instances.</p>
<pre><code>gcloud compute scp file_name &quot;server_name&quot;:~/ --zone &quot;zone_name&quot; --project &quot;project_name&quot;
</code></pre>
<p>There are other ways
to transfer files to the
virtual instance from your
local computer, but
they raise some complications.
If interested, see
<a href="https://cloud.google.com/compute/docs/instances/transfer-files">Transfer files to Linux VMs</a>.</p>
<h3 id="investigate"><a class="header" href="#investigate">Investigate</a></h3>
<p>Now that the file
is uploaded,
the first task is to
to get an understanding of
the structure of the data.
<em>BibTeX</em> (.bib) files are structured
files that contain bibliographic data.
It's important to understand
how files are structured
if we want to search them efficiently.</p>
<p>The <strong>scopus.bib</strong> file begins with
information about the source
(<em>Scopus</em>) of the records
and the date the records
were exported.
These two lines and the
empty line after them can
be safely deleted or ignored.</p>
<p>Each bibliographic record
in the file begins with
an <strong>entry type</strong> (or document type) preceded
by an at <strong>@</strong> sign.
Example entry types include:
<a href="https://www.bibtex.com/e/entry-types/">article, book, booklet, conference, and more</a>.
There is a opening curly brace
after the entry or document type.
These curly braces mark
the beginning and ending of each record.</p>
<p>The cite key follows
the opening curly brace.
The cite key is an identifier that
often refers to the author's name and
includes publication date information.
For example, a cite key might look
as follows and
would stand for the author <strong>Budd</strong>
and the date <strong>2020-11-23</strong>.</p>
<pre><code>Budd20201123
</code></pre>
<p>The rows below the entry type
contain the metadata for the record.
Each row begins with a tag or field name
followed by an equal sign,
which is then followed by
the values or content for that tag.
For example,
there's an author tag,
an equal sign, and
then a list of authors.
There is a standard list
of <em>BibTeX</em> fields.
Example fields include:
<a href="https://bibtex.eu/fields/">author, doi, publisher, title, journal, year, and more</a>.
The fields are standardized because
some programs use <em>BibTeX</em> records
to manage and generate
bibliographies, in-text citations, footnotes, etc..</p>
<p>The content of each field
is enclosed in
additional curly braces.
Each line ends with a comma,
except for the last line.
The record ends
with a closing curly brace.</p>
<h4 id="document-types"><a class="header" href="#document-types">Document Types</a></h4>
<p>We can use <code>grep</code> to
examine the types of documents
the records point to.
In the following command,
I use the carat key <strong>^</strong>,
which is a regular expression
to signify the start of a line,
to search for lines beginning
with the at <strong>@</strong> symbol.
The following <code>grep</code> command
therefore means:
return all lines that begin
with the at <strong>@</strong> symbol:</p>
<pre><code>grep &quot;^@&quot; scopus.bib
</code></pre>
<p>The results show,
for this particular data,
that I have BOOK and ARTICLE entry types.
The data I'm using does not contain
many records, but
if it contained thousands or more,
then it would be helpful to
filter these results.</p>
<p>Thus, below I use the <strong>-E</strong> option
to extend <code>grep</code>'s regular expression engine.
I use the <strong>(A|B)</strong> to tell <code>grep</code> to search
for letters after the at sign <strong>@</strong>
that start with either A or B,
for ARTICLE or BOOK.
Then I use regular expression
character class matching
with <strong>[A-Z]*</strong> to match any letters
after the initial A or B characters.
The <strong>-i</strong> option turns off case sensitivity,
and the <strong>-o</strong> option returns
only matching results from the lines.
I pipe the output of the <code>grep</code> command
to the <code>sort</code> command to sort the
results alphabetically:</p>
<pre><code>grep -Eio &quot;^@(A|B)[A-Z]*&quot; scopus.bib | sort
</code></pre>
<blockquote>
<p>Tip: Without using the <code>sort</code> command, the <code>grep</code> command returns the results
in the order it finds them. To see this, run the above command with and
without piping to the <code>sort</code> command to examine how the output changes.</p>
</blockquote>
<p>Now let's get a frequency of the document types.
Here I <strong>pipe</strong> <code>|</code> the output from the <code>grep</code>
command to the <code>sort</code> command,
in order to sort the output alphabetically.
Then I <strong>pipe</strong> the output from the <code>sort</code>
command to the <code>uniq</code> command.
The <code>uniq</code> command will deduplicate
the results, and
the <strong>-c</strong> option will count the
number of duplicates.
As a result,
it will provide an overall
count of the document or entry types
we searched.</p>
<pre><code>grep -Eio &quot;^@(A|B)[A-Z]*&quot; scopus.bib | sort | uniq -c
</code></pre>
<h4 id="journal-titles"><a class="header" href="#journal-titles">Journal Titles</a></h4>
<p>We can parse the data for other information.
For example,
we can get a list of journal titles by
querying for the <strong>journal</strong> tag:</p>
<pre><code>grep &quot;journal&quot; scopus.bib
</code></pre>
<p>Even though that works,
the data contains
the word <strong>Journal</strong>
in the name of some journals.
If we were searching thousands
or more records,
we might want to construct a more
unique <code>grep</code> search.</p>
<p>To rectify this,
we can modify our <code>grep</code> search
in two ways.
First, the rows of data fields
begin with a tab character.
The regular expression
for the tab character is <strong>\t</strong>.
Therefore, we can search
the file using this expression
with the <strong>-P</strong> option:</p>
<pre><code>grep -P &quot;\tjournal&quot; scopus.bib
</code></pre>
<p>Second, we can simply add more
unique terms to our <code>grep</code> search.
Since each tag includes a space,
an equal sign,
followed by another space, 
we can use that in our <code>grep</code> query:</p>
<pre><code>grep &quot;journal =&quot; scopus.bib
</code></pre>
<p>Using either method above,
we can extract the journal title information.
Here I use two new commands,
<code>cut</code> and <code>sed</code>.
The <code>cut</code> command takes
the results of the <code>grep</code> command,
removes the first column based on
the comma as the column delimiter.
In the first <code>sed</code> command,
I remove the space and opening
curly brace and replace it with nothing.
In the second <code>sed</code> command,
I remove the closing curly brace and
the comma and replace it with nothing.
The result is list of only the journal titles
without any extraneous characters.
I then pipe the output to the <code>sort</code> command,
which sorts the list alphabetically,
to the <code>uniq -c</code> command,
which deduplicates and counts the results,
and again to the <code>sort</code> command,
which sorts numerically,
since the first character is a number:</p>
<pre><code>grep &quot;journal =&quot; scopus.bib | cut -d&quot;=&quot; -f2 | \
    sed 's/ {//' | sed 's/},//' | \
    sort | uniq -c | sort
</code></pre>
<h4 id="total-citations"><a class="header" href="#total-citations">Total Citations</a></h4>
<p>There are other things we can
do if we want to learn more powerful technologies.
While I will not cover <code>awk</code>,
I do want to introduce it to you.
With the <code>awk</code> command,
based on the <em>BibTeX</em> tag that
includes citation counts
at the time of the download
(e.g., <strong>note = {Cited by: 2}</strong>),
we can extract the number from
that field for each record and
sum the total citations for
the records in the file:</p>
<pre><code> grep -o &quot;Cited by: [0-9]*&quot; scopus.bib | \
    awk -F&quot;:&quot; \
    'BEGIN { printf &quot;Total Citations: &quot;} \
    { sum += $2; } \
    END { print sum }'
</code></pre>
<p>In the above command,
we use the pipe operator
to connect a series of commands
to each other:</p>
<ol>
<li>use <code>grep</code> to search for the string &quot;Cited by: &quot; and to include any number of digits</li>
<li>use <code>awk</code> to use the colon as the column or field delimiter</li>
<li>use the <code>awk</code> BEGIN statement to print the words &quot;Total Citations: &quot;</li>
<li>instruct <code>awk</code> to sum the second column, which is the citation numbers</li>
<li>use the <code>awk</code> END statement to print the sum.</li>
</ol>
<blockquote>
<p>If you want to learn more about <code>sed</code> and <code>awk</code>, please see my <a href="https://cseanburns.github.io/linux_sysadmin/10-text-processing-part-2.html">text
processing chapter for my Linux Systems Administration</a>.
There are also many tutorials on the web.</p>
</blockquote>
<h2 id="conclusion-5"><a class="header" href="#conclusion-5">Conclusion</a></h2>
<p><code>grep</code> is very powerful, and
there are more options listed in its <code>man</code> page.</p>
<p>The Linux (and other Unix-like OSes) command line
offers a lot of utilities to examine data.
It's fun to learn and practice these.
Despite this, you do not have to become
an advanced <code>grep</code> user.
For most cases,
simple <code>grep</code> searches work well.</p>
<p>There are many <code>grep</code> tutorials on the web
if you want to see other examples.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="managing-software"><a class="header" href="#managing-software">Managing Software</a></h1>
<h2 id="introduction-5"><a class="header" href="#introduction-5">Introduction</a></h2>
<p>Most Linux distributions use
what's called a <strong>package manager</strong> to
handle the installation, upgrades, and
uninstalls of the software on a system.
The Ubuntu distribution uses a
package manager called <code>dpkg</code> and
a front-end called <code>apt</code>
(advanced package tool).
We will use <code>apt</code> to install,
update, and remove software
from our servers.</p>
<h2 id="sudo"><a class="header" href="#sudo"><code>sudo</code></a></h2>
<p>In order to use the package manager,
we will need 
the <code>sudo</code> command.
The <code>sudo</code> command allows us to
&quot;execute a command as another user&quot;
(see <code>man sudo</code>).
By default,
the <code>sudo</code> command
&quot;executes a command as the superuser&quot;
(see <code>man 8 sudo</code>).</p>
<p>The name of the <strong>superuser</strong> account
is <strong>root</strong>.
This user can perform administrative tasks
that regular users cannot.
For security purposes,
regular accounts may not add, remove, or
update software on a system, nor
may they modify most files or directories
outside their home directories.
Using <code>sudo</code> allows regular users to
perform maintenance tasks on our systems
by executing commands as the root user.
Some consider this safer than logging
in as the root user.</p>
<p>Not all regular users can use
the <code>sudo</code> command.
On regular Ubuntu distributions,
users must belong to the <strong>sudo</strong> group
in order to run the <code>sudo</code> command.
The <code>groups</code> command will return
a list of groups that your account belongs to.
On the Ubuntu version used by the
Google Cloud Platform (GCP),
the group of interest is called <strong>google-sudoers</strong>.
The difference between the <strong>sudo</strong> group
on regular Ubuntu distributions and
the GCP version is that regular users in the
<strong>google-sudoers</strong> group are not prompted for
their password.</p>
<p>Down the line,
we will need to use the <code>sudo</code> command
to modify files, create directories, and
perform other maintenance tasks needed to
install and manage software.
In this lesson, we will use <code>sudo</code> along
with the <code>apt</code> commands to update our
systems and install software.</p>
<h3 id="sudo-syntax"><a class="header" href="#sudo-syntax"><code>sudo</code> syntax</a></h3>
<p>The <code>sudo</code> command is simple to use.
When necessary,
we use <code>sudo</code> by pre-pending it to
the regular commands that we have already
learned.
In our home directories, for example,
we don't need to use <code>sudo</code> to
create a new directory with the <code>mkdir</code>
command.
Instead we type
<code>mkdir data</code> to create a new
directory/folder called <strong>data</strong>.
But outside our home directory,
for example, in the directory
<strong>/usr/local/bin</strong>,
we need to use <code>sudo</code> to do such things.
(This is why I used the <code>sudo</code> command
when I showed you how to copy the
<strong>Learn the Commandline</strong> programs to
<strong>/usr/local/bin</strong>.)
If I want to create a <strong>data</strong> directory
in <strong>/usr/local/bin</strong>, then
I have to use sudo at the beginning of
my command:</p>
<pre><code>cd /usr/local/bin
sudo mkdir data
</code></pre>
<p>Or, without changing to that directory,
I can just specify the full path:</p>
<pre><code>sudo mkdir /usr/local/bin/data
</code></pre>
<p>Or if I want to create a file in
some other directory outside my
home directory, then
I have to use sudo there, too:</p>
<pre><code>cd /srv
sudo touch data.csv
</code></pre>
<p>Or, without changing to that directory,
I can specify the full path:</p>
<pre><code>sudo touch /srv/data.csv
</code></pre>
<h2 id="apt"><a class="header" href="#apt">apt</a></h2>
<p>We will use <code>sudo</code> in the above
ways soon enough, but for now,
we will use <code>sudo</code> to install,
update, and uninstall software on
our systems.</p>
<p>Next I'll demonstrate the <code>apt</code>
commands that we'll need.</p>
<h3 id="sudo-apt-update"><a class="header" href="#sudo-apt-update"><code>sudo apt update</code></a></h3>
<p>Your system keeps a record of
what software is installed on your
system and their version numbers.
The <code>sudo apt update</code> command
updates that list and compares
the update to what's installed.
That is, if you have a piece of
software called <strong>acme1.1</strong> on your system,
and <strong>acme1.2</strong> is available, then
running <code>sudo apt update</code> will
let you know that you can upgrade to
<strong>acme1.2</strong>.
It's good practice to run <code>sudo apt update</code>
before installing or upgrading your system
because this lets your system upgrade to
the most recent version of what you want
to install.</p>
<p>In short, the command to download
new package information is:</p>
<pre><code>sudo apt update
</code></pre>
<h3 id="sudo-apt-upgrade"><a class="header" href="#sudo-apt-upgrade"><code>sudo apt upgrade</code></a></h3>
<p>Once the list of packages have been updated,
you can <strong>upgrade</strong> with the <code>sudo apt upgrade</code>
command if there are any upgrades.
When you run this command, and if
there are any upgrades,
you will be prompted to proceed.
You can press <strong>Y</strong> to proceed, or
<strong>N</strong> to cancel.</p>
<p>This command is simply:</p>
<pre><code>sudo apt upgrade
</code></pre>
<h3 id="apt-search"><a class="header" href="#apt-search"><code>apt search</code></a></h3>
<p>If you want to install a piece
of software, then
you have to install it using its
package name.
Sometimes that means we have to
search for the name of the package.
This is one of the <code>apt</code> commands
that does not require the use of <code>sudo</code>.
<code>sudo</code> is not required because
<code>apt search</code> does not modify the system.
It simply helps you search for a package name.</p>
<p>For example, the <code>man</code> pages provide
helpful documentation about how to use
the commands on our systems, but
the <code>man</code> pages can also be dense and
not straightforward.</p>
<p>Fortunately, there's an application called
<code>tldr</code> that is a community-driven application
that provides simple help pages and examples
of how to use some of the most commonly used
commands.</p>
<p>To search for the <code>tldr</code> package,
we execute the following command:</p>
<pre><code>apt search tldr
</code></pre>
<p>This returns a list of results that
match the search query.
One of those results is the <code>tldr</code> package,
which is simply named <strong>tldr</strong>.
Not all packages are simply named,
which is why we need to search for the
specific name.</p>
<blockquote>
<p>Note that sometimes when we search for a package, the list
of results is quite long. In those cases, pipe the above
command through the <code>less</code> pager to page through the
results: <code>apt search &lt;packagename&gt; | less</code></p>
</blockquote>
<h2 id="apt-show"><a class="header" href="#apt-show"><code>apt show</code></a></h2>
<p>If we want more specific information
about the package,
we can use the <code>apt show</code> command
along with the package name.
Therefore, to get more information
about the <code>tldr</code> application,
we execute the following command:</p>
<pre><code>apt show tldr
</code></pre>
<p>This will return a fuller description
of the package (usually), as well
as the URL to the application's website,
plus other details.
We do not need to use <code>sudo</code> here
because we are not modifying the system.
We are only retrieving information.</p>
<h2 id="sudo-apt-install"><a class="header" href="#sudo-apt-install"><code>sudo apt install</code></a></h2>
<p>To install the <code>tldr</code> application,
we use the <code>sudo apt install</code> command
along with the package name.
We want to make sure that the name of the
package is exactly what was returned from
the <code>apt search</code> command.
In the <code>tldr</code> case,
it's pretty straightforward, and to install:</p>
<pre><code>sudo apt install tldr
</code></pre>
<h2 id="sudo-apt-remove"><a class="header" href="#sudo-apt-remove"><code>sudo apt remove</code></a></h2>
<p>In order to remove a package,
we use the <code>sudo apt remove</code>
command.
I like to add the <code>--purge</code> option
because this also removes system configuration
files that I probably do not need.
That is, some applications
install configuration files (configs)
in the <strong>/etc</strong> directory.
Adding <code>--purge</code> will remove those configs.</p>
<p>To remove a package and
its system configuration files (if any),
we run the above command with the package name.</p>
<pre><code>sudo apt --purge remove tldr
</code></pre>
<p>Some configs are stored in your home directory.
Generally only end user applications install
configs in our home directories.
The <code>--purge</code> option will not remove those configs;
instead, we have to remove them manually if we want.</p>
<h3 id="sudo-apt-autoremove"><a class="header" href="#sudo-apt-autoremove"><code>sudo apt autoremove</code></a></h3>
<p>One of the great things about <code>dpkg</code> and <code>apt</code>
is that it installs and handles software
<strong>dependencies</strong> really well.
Dependencies are other software that software
depends upon to run.
That is, few computer applications are self-contained, and
they often require other software to operate.
When we uninstall (or remove) applications,
the package manager does not auto uninstall those
dependencies that were installed with it.
We use the autoremove command to uninstall those,
which helps keep our systems clean:</p>
<pre><code>sudo apt autoremove
</code></pre>
<h3 id="sudo-apt-clean"><a class="header" href="#sudo-apt-clean"><code>sudo apt clean</code></a></h3>
<p>When we install packages,
some files are installed with them.
The <code>sudo apt clean</code> removes those
extra files and frees up disk space.
It's a simple command:</p>
<pre><code>sudo apt clean
</code></pre>
<h2 id="conclusion-6"><a class="header" href="#conclusion-6">Conclusion</a></h2>
<p>The <code>apt</code> command makes it quite easy
to manage software on our systems.
We will use this command to install more
complicated software later.
Here's a list of commands we covered:</p>
<ul>
<li><code>sudo apt update</code></li>
<li><code>sudo apt upgrade</code></li>
<li><code>apt search</code></li>
<li><code>apt show</code></li>
<li><code>sudo apt install</code></li>
<li><code>sudo apt --purge remove</code></li>
<li><code>sudo apt autoremove</code></li>
<li><code>sudo apt clean</code></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="library-search"><a class="header" href="#library-search">Library Search</a></h1>
<p>We're going to explore the <code>yaz-client</code>,
a tool that serves
as a gateway to
information retrieval
using the Z39.50 protocol.
For those unfamiliar,
Z39.50 is a standard protocol
in libraries for
sharing, querying, and retrieving bibliographic information
between library databases.
Development and usage
began in the 1970s,
which of course pre-dates the web,
and this is a testament to the evolution of
information retrieval systems since the 1970s.
The protocol is maintained by the
<a href="https://www.loc.gov/z3950/agency/"><em>Library of Congress</em></a>.</p>
<p>SRU (Search/Retrieve via URL) and
SRW (Search/Retrieve Web service)
are modern web-based successors to Z39.50.
They offer more flexibility
in accessing and sharing bibliographic records.
The <code>yaz-client</code> allows us to interact
with these protocols
directly from the command line,
which provides a hands-on experience
with the underlying mechanics of
digital library searches and data retrieval.</p>
<p>This exploration is not
only about learning a tool;
it's about understanding the
history and ongoing development
of information retrieval systems,
a crucial aspect in
library and information science.</p>
<blockquote>
<p>SRU uses URL query strings, which is similar to web searches.
SRW utilizes <a href="https://en.wikipedia.org/wiki/SOAP">SOAP</a>, which is more complex but allows for more data exchange.</p>
</blockquote>
<h2 id="installing-yaz"><a class="header" href="#installing-yaz">Installing <code>yaz</code></a></h2>
<p>Use the <code>apt</code> instructions
from the prior lesson
to install the <code>yaz</code> client.</p>
<p>First we need to search
for the name of the software:</p>
<pre><code>apt search yaz
</code></pre>
<p>The program that we are
interested in is called <code>yaz</code>.
To get information about the program,
we use the <code>apt show</code> command:</p>
<pre><code>apt show yaz
</code></pre>
<p>The details help confirm
that this is the program
we want to install.
Note that the output also
returns a URL to the program's
homepage on the web.
Visit that link to
read more about the software.</p>
<p>To install it,
we use the <code>sudo apt install</code> command:</p>
<pre><code>sudo apt install yaz
</code></pre>
<h2 id="documentation"><a class="header" href="#documentation">Documentation</a></h2>
<p>The documentation for the
<code>yaz-client</code> can be accessed
via its manual page or on the web.
See:</p>
<pre><code>man yaz-client
</code></pre>
<p>For attribute documentation:</p>
<pre><code>man bib1-attr
</code></pre>
<p>The Library of Congress also
provides an overview of the <strong>bib1-attr</strong>,
but it's less comprehensive:</p>
<p><a href="https://www.loc.gov/z3950/agency/defns/bib1.html">https://www.loc.gov/z3950/agency/defns/bib1.html</a></p>
<p>Complete documentation for the
<code>yaz-client</code> can be found on its
homepage:</p>
<p><a href="https://www.indexdata.com/resources/software/yaz/">https://www.indexdata.com/resources/software/yaz/</a></p>
<h2 id="using-yaz"><a class="header" href="#using-yaz">Using <code>yaz</code></a></h2>
<p>The command to start
the <code>yaz</code> program is
<code>yaz-client</code>.</p>
<p>Open yaz-client:</p>
<pre><code>yaz-client
</code></pre>
<p>This starts a separate command line
interface with a new prompt:</p>
<pre><code>Z&gt;
</code></pre>
<p>In this new interface,
we can connect to a library's
OPAC or discovery service.
To do so,
we use  the <code>open</code> command
followed by the server address:</p>
<pre><code>open saalck-uky.alma.exlibrisgroup.com:1921/01SAA_UKY
</code></pre>
<h2 id="queries"><a class="header" href="#queries">Queries</a></h2>
<p>Queries are constructed
using Prefix Query Notation (PQN).
In the context of PQN,
this is a way of structuring
queries where the operator
(e.g., AND, NOT, OR)
precedes the operands
(e.g., search terms, attributes, fields).</p>
<p>Each query begins with a <em>command</em>.
The list of commands are
described in <code>man yaz-client</code>
in the COMMANDS section.
The main command we'll use
is the <code>find</code> command,
which may be abbreviated
down to the <code>f</code> command.
Let's see some examples:</p>
<h3 id="example-1"><a class="header" href="#example-1">Example 1</a></h3>
<p>To find title with word
'information' and
the Library of Congress Subject Heading
'library science',
we use the following query:</p>
<pre><code>find @and @attr 1=4 &quot;information&quot; @attr 1=21 &quot;library science&quot;
</code></pre>
<p>In the above:</p>
<ul>
<li><code>find</code> is the command that sends a search request</li>
<li><code>@and</code> is the operator signifying a Boolean AND search of multiple attributes</li>
<li><code>@attr 1=4</code> instructs the query to search for the term in the Title</li>
<li><code>&quot;information&quot;</code> is the first search term for the Title search</li>
<li><code>@attr 1=21</code> instructs the query to search for the term in the Subject-heading</li>
<li><code>&quot;library science&quot;</code> is the second search term for the subject heading search</li>
</ul>
<p>The search does not reveal the results.
To peruse the results,
we use the <code>show</code> command.
To show the first record:</p>
<pre><code>show 1
</code></pre>
<h3 id="example-2"><a class="header" href="#example-2">Example 2</a></h3>
<p>Find with subject headings &quot;library science&quot; and &quot;philosophy&quot;</p>
<pre><code>f @and @attr 1=21 &quot;library science&quot; @attr 1=21 &quot;philosophy&quot;
</code></pre>
<h3 id="example-3"><a class="header" href="#example-3">Example 3</a></h3>
<p>Find where personal name is &quot;mcmurtry, larry&quot;</p>
<pre><code>f @attr 1=1 &quot;mcmurtry, larry&quot;
</code></pre>
<h3 id="example-4"><a class="header" href="#example-4">Example 4</a></h3>
<p>Find any for &quot;c programming language&quot;</p>
<pre><code>f @attr 1=1016 &quot;c programming language&quot;
</code></pre>
<h2 id="conclusion-7"><a class="header" href="#conclusion-7">Conclusion</a></h2>
<p>Z39.50 is often presented as an abstract
information retrieval concept
even though it has played a central
part of searching online catalogs and database
for nearly 50 years.
The protocol,
along with tools like <code>yaz</code>
can be used to build
search interfaces to bibliographic data.
For example,
see:</p>
<ul>
<li><a href="https://reintech.io/blog/guide-to-php-yaz-library-information-retrieval">A Guide to the PHP YAZ Library for Information Retrieval</a></li>
<li><a href="https://sites.nd.edu/emorgan/2013/11/fun/">Fun with bibliographic indexes, bibliographic data management software, and Z39.50</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="creating-a-lamp-server"><a class="header" href="#creating-a-lamp-server">Creating a LAMP Server</a></h1>
<p>In this section,
we learn how to set up a LAMP
(Linux, Apache, MySQL, PHP) stack.
This stack enables us to create a web server
that provides extra funtionality via PHP and MySQL,
both of which are required to run
content management systems and
integrated library systems.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="installing-the-apache-web-server"><a class="header" href="#installing-the-apache-web-server">Installing the Apache Web Server</a></h1>
<h2 id="introduction-6"><a class="header" href="#introduction-6">Introduction</a></h2>
<p><a href="https://httpd.apache.org/">Apache</a> is an HTTP server,
otherwise called web server software.
Other HTTP server software exists.
Another big one is <a href="https://nginx.org/en/">nginx</a>.
At its most basic,
an HTTP server essentially makes files
available to others who are able to establish a
connection to the computer and view the files
with a web browser.
Ergo, a web browser is,
at its most basic,
a file viewer.</p>
<p>It's important to understand
the basics of an HTTP server, and
therefore I ask you to read Apache's
<a href="https://httpd.apache.org/docs/2.4/getting-started.html">Getting Started</a> page before
proceeding with the rest of this section.
Each of the main sections on that page describe
the important elements that make up and serve a website,
including</p>
<ul>
<li>clients, servers, and URLs</li>
<li>hostnames and DNS</li>
<li>configuration files and directives</li>
<li>web site content</li>
<li>log files and troubleshooting</li>
</ul>
<h2 id="installation-1"><a class="header" href="#installation-1">Installation</a></h2>
<p>Before we install Apache,
we need to update our systems first.</p>
<pre><code>sudo apt update
sudo apt -y upgrade
</code></pre>
<p>Once the machine is updated,
we can install Apache2 using <code>apt</code>.
First we'll use <code>apt search</code> to identify
the specific package name.
I already know that a lot of results
will be returned,
so let's <strong>pipe</strong> the <code>apt search</code> command
through <code>head</code> to look at the initial results:</p>
<pre><code>sudo apt search apache2 | head
</code></pre>
<p>The package that we're interested in
happens to be named <strong>apache2</strong> on Ubuntu.
This package name is not a given.
On other distributions,
like Fedora,
the Apache package is called <strong>httpd</strong>.
To learn more about the <strong>apache2</strong> package,
let's examine it with the <code>apt show</code> command:</p>
<pre><code>apt show apache2
</code></pre>
<p>Once we've confirmed that <strong>apache2</strong> is the package
that we want,
we install it with the <code>apt install</code> command.
Press <strong>Y</strong> to agree to continue after running
the command below:</p>
<pre><code>sudo apt install apache2
</code></pre>
<h2 id="basic-checks"><a class="header" href="#basic-checks">Basic checks</a></h2>
<p>One thing that makes Apache2, and
some other web servers,
powerful is the library of modules that
extend Apache's functionality.
We'll come back to modules soon.
For now,
we're going to make sure the
server is up and running,
configure some basic things, and
then create a basic web site.</p>
<p>To start,
let's use <code>systemctl</code> to acquire
some info about <strong>apache2</strong> and
make sure it is <em>enabled</em> and <em>running</em>:</p>
<pre><code>systemctl list-unit-files apache2.service
systemctl status apache2
</code></pre>
<p>The output shows that <strong>apache2</strong> is enabled,
which means that it will start running automatically
when the computer gets rebooted.</p>
<p>The output of the second command also shows
that <strong>apache2</strong> is active,
which means that it has started working.</p>
<h2 id="creating-a-web-page"><a class="header" href="#creating-a-web-page">Creating a web page</a></h2>
<p>Since <strong>apache2</strong> is up and running,
let's look at the default web page.</p>
<p>There are two ways we can look
at the default web page.
We can use a command line web browser.
There are a number available, but
I like <code>w3m</code>.</p>
<p>We can also use our regular web browsers
and view the site by entering the
IP address of the server
in our browser URL bar.</p>
<p>To check with <code>w3m</code>,
we have to install it first:</p>
<pre><code>sudo apt install w3m
</code></pre>
<p>Once it's installed,
we can visit our default site using the
loopback IP address
(aka, <em>localhost</em>).
From the command line on our server,
we can run either of these two commands:</p>
<pre><code>w3m 127.0.0.1
w3m localhost
</code></pre>
<p>We can also get the subnet/private IP address
using the <code>ip a</code> command, and
then use that with <code>w3m</code>.
For example, if <code>ip a</code> showed that my NIC
has an IP address of <strong>10.0.1.1</strong>, then
I could use <code>w3m</code> with that IP address:</p>
<pre><code>w3m 10.0.1.1
</code></pre>
<p>If the <strong>apache2</strong> installed and
started correctly,
then you should see the
following text at the top
of the screen:</p>
<p><strong>Apache2 Ubuntu Default Page</strong><br />
<strong>It works!</strong></p>
<p>To exit <code>w3m</code>,
press <strong>q</strong> and then <strong>y</strong> to confirm exit.</p>
<p>To view the default web page using
a regular web browser,
like Firefox, Chrome, Safari, Edge, or etc.,
you need to get your server's public IP address.
To do that,
log into the
<a href="https://console.cloud.google.com/">Google Cloud Console</a>.
In the left hand navigation panel,
hover your cursor over the <strong>Compute Engine</strong> link, and
then click on <strong>VM instances</strong>.
You should see your <strong>External IP</strong> address
in the table on that page.
You can copy that external IP address or
simply click on it to open it in a new browser tab.
Then you should see the graphical version of the
<strong>Apache2 Ubuntu Default Page</strong>.</p>
<blockquote>
<p>Note that most browsers nowadays may try to force HTTPS
mode, and they also often hide the protocal from the URL.
If your web page is not loading, make sure your URL is
<strong>http://IP-ADDRESS</strong> and not <strong>https://IP-ADDRESS</strong>.</p>
</blockquote>
<p>Please take a moment to read through
the text on the default page.
It provides important information about
where Ubuntu stores configuration files and
what those files do, and
the document root,
which is where website files are stored.</p>
<h2 id="create-a-web-page"><a class="header" href="#create-a-web-page">Create a Web Page</a></h2>
<p>Let's create our first web page.
The default page described above provides
the location of the document root at
<strong>/var/www/html</strong>.
When we navigate to that location
on the command line,
we'll see that there is already an <strong>index.html</strong>
file located in that directory.
This is the <strong>Apache2 Ubuntu Default Page</strong>
that we visited above in our browsers.
Let's rename that <strong>index.html</strong> file,
and create a new one:</p>
<pre><code>cd /var/www/html/
sudo mv index.html index.html.original
sudo nano index.html
</code></pre>
<blockquote>
<p>Note: we use <code>sudo</code> in this directory because we are
working on files and directories outside our home
directories. Thus, be careful here about the commands you
run. Any mistake may result in deleting necessary files or
directories.</p>
</blockquote>
<p>If you know HTML,
then feel free to write some
basic HTML code to get started.
Otherwise, you can re-type the content below
in <code>nano</code>, and
then save and exit out.</p>
<pre><code>&lt;html&gt;
&lt;head&gt;
&lt;title&gt;My first web page using Apache2&lt;/title&gt;
&lt;/head&gt;
&lt;body&gt;

&lt;h1&gt;Welcome&lt;/h1&gt;

&lt;p&gt;Welcome to my web site.
I created this site using the Apache2 HTTP server.&lt;/p&gt;

&lt;/body&gt;
&lt;/html&gt;
</code></pre>
<p>If you have your site open in your web browser,
reload the page, and you should see
the new text.</p>
<p>You can still view the original default page by
specifying its name in the URL.
Remember that web browsers are,
at their most basic,
simply file viewers.
So it makes sense that you simply
have to specify the name of the file
you want to view.
For example, if your <strong>external IP address</strong> is
<strong>55.222.55.222</strong>, then you'd specify it like so:</p>
<pre><code>http://55.222.55.222/index.html.original
</code></pre>
<h2 id="conclusion-8"><a class="header" href="#conclusion-8">Conclusion</a></h2>
<p>In this section,
we learned about the Apache2 HTTP server.
We learned how to install it on Ubuntu,
how to use systemd (<code>systemctl</code>) commands
to check its status,
how to create a basic web page in <code>/var/www/html</code>,
how to view that web page using the <code>w3m</code>
command line browser and 
our regular graphical browser,</p>
<p>In the next section,
we will install PHP,
which will provide the language
needed to connect to MySQL,
and thus enable more data
driven web sites.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="installing-and-configuring-php"><a class="header" href="#installing-and-configuring-php">Installing and Configuring PHP</a></h1>
<h2 id="introduction-7"><a class="header" href="#introduction-7">Introduction</a></h2>
<p>Client-side programming languages,
like JavaScript,
are handled by the browser.
Major browsers like Firefox, Chrome, Safari, Edge, etc.
all include <a href="https://en.wikipedia.org/wiki/JavaScript_engine">JavaScript engines</a> that use
just-in-time compilers to execute JavaScript code
(Mozilla has a <a href="https://blog.mozilla.org/javascript/">nice description</a> of the process.)
From an end user's perspective,
you basically install JavaScript when you install a web browser.</p>
<p><a href="https://www.php.net/">PHP</a>, on the other hand,
is a server-side programming language,
which means it must be installed on the server
in order to be used.
From a system or web administrator's perspective,
this means that not only does PHP have be installed
on a server, but
it must also be configured to work with the HTTP server,
which in our case is Apache2.</p>
<p>The main use of PHP is to interact with databases,
like MySQL, MariaDB, PostgreSQL, etc.,
in order to create data-based page content.
To begin to set this up,
we have to:</p>
<ol>
<li>Install PHP and relevant Apache2 modules</li>
<li>Configure PHP and relevant modules to work with Apache2</li>
<li>Configure PHP and relevant modules to work with MySQL</li>
</ol>
<h2 id="install-php"><a class="header" href="#install-php">Install PHP</a></h2>
<p>As usual, we will use <code>apt install</code>
to install PHP and relevant modules.
Then we will restart Apache2
using the <code>systemctl</code> command.
Use <code>apt show [package_name]</code>
to read more about each package
we will install.
The first command below installs
the <strong>php</strong> and the <strong>libapache2-mod-php</strong>
packages.
The latter package is used to
create a connection between PHP
and Apache2.</p>
<pre><code>sudo apt install php libapache2-mod-php
sudo systemctl restart apache2
</code></pre>
<p>We can check its status and
see if there are any errors:</p>
<pre><code>systemctl status apache2
</code></pre>
<h2 id="check-install"><a class="header" href="#check-install">Check Install</a></h2>
<p>To check that it's been installed and that
it's working with Apache2,
we can create a small PHP file in our
web document root.
To do that,
we <code>cd</code> to the <code>/var/www/html/</code> directory
and create a file called <strong>info.php</strong>:</p>
<pre><code>cd /var/www/html/
sudo nano info.php
</code></pre>
<p>In that file,
add the following text,
then save and close the file:</p>
<pre><code>&lt;?php
phpinfo();
?&gt;
</code></pre>
<p>No visit that file using the external IP address
for your server.
For example, in Firefox, Chrome, etc, go to:</p>
<pre><code>http://55.333.55.333/info.php
</code></pre>
<blockquote>
<p>Again, be sure to replace the IP below with the IP address
of your server and be sure to use <strong>http</strong> and not
<strong>https</strong>.</p>
</blockquote>
<p>You should see a page that provides system information
about PHP, Apache2, and the server.
The top of the page should look like Figure 1 below:</p>
<figure>
<img src="images/24-phpinstall.png"
alt="PHP install page"
title="PHP install page">
<figcaption>
Fig. 1. A screenshot of the title of the PHP install page.
</figcaption>
</figure>
<h2 id="basic-configurations"><a class="header" href="#basic-configurations">Basic Configurations</a></h2>
<p>By default, when Apache2 serves a web page,
it looks for and serves a
<a href="https://httpd.apache.org/docs/current/mod/mod_dir.html">file titled <strong>index.html</strong></a>,
even if it does not display that file in the URL bar.
Thus, <code>http://example.com/</code> actually
resolves to <code>http://example.com/index.html</code>
in such cases.</p>
<p>However, if our plan is to provide for PHP,
we want Apache2 to default to a file
titled <strong>index.php</strong> instead of
<strong>index.html</strong> file.
To configure that,
we need to edit the <strong>dir.conf</strong> file
in the <strong>/etc/apache2/mods-enabled/</strong> directory.
In that file there is a line that starts with
<strong>DirectoryIndex</strong>.
The first file in that line is <strong>index.html</strong>, and then
there are a series of other files that Apache2 will
look for in the order listed.
If any of those files exist in the document root,
then Apache2 will serve those before proceeding to the next.
We simply want to put <strong>index.php</strong> first and let
<strong>index.html</strong> be second on that line.
Before modifying this file,
it's good practice to create a backup
of the original.
So we will use the <code>cp</code> command
to create a copy with a new name,
and then we will use <code>nano</code>
to edit the file.</p>
<pre><code>cd /etc/apache2/mods-enabled/
sudo cp dir.conf dir.conf.bak
sudo nano dir.conf
</code></pre>
<p>Next we change the line to this:</p>
<pre><code>DirectoryIndex index.php index.html index.cgi index.pl index.xhtml index.htm
</code></pre>
<p>Whenever we make a configuration change,
we can use the <code>apachectl</code> command to
check our configuration:</p>
<pre><code>apachectl configtest
</code></pre>
<p>If we get a <strong>Syntax Ok</strong> message,
we can reload the Apache2 configuration and
restart the service:</p>
<pre><code>sudo systemctl reload apache2
sudo systemctl restart apache2
</code></pre>
<h2 id="create-an-indexphp-file"><a class="header" href="#create-an-indexphp-file">Create an index.php File</a></h2>
<p>Now create a basic PHP page.
<code>cd</code> back to the Apache2
document root directory and
use <code>nano</code> to create and
open an <code>index.php</code> file:</p>
<pre><code>cd /var/www/html/
sudo nano index.php
</code></pre>
<p>Let's add some HTML and PHP to it.
We will add PHP that functions as a
simple <a href="https://stackoverflow.com/questions/8754080/how-to-get-exact-browser-name-and-version">browser detector</a>.
Add the following code:</p>
<pre><code>&lt;html&gt;
&lt;head&gt;
&lt;title&gt;Broswer Detector&lt;/title&gt;
&lt;/head&gt;
&lt;body&gt;
&lt;p&gt;You are using the following browser to view this site:&lt;/p&gt;

&lt;?php
$user_agent = $_SERVER['HTTP_USER_AGENT'];

if(strpos($user_agent, 'Edge') !== FALSE) {
    $browser = 'Microsoft Edge';
} elseif(strpos($user_agent, 'Firefox') !== FALSE) {
    $browser = 'Mozilla Firefox';
} elseif(strpos($user_agent, 'Chrome') !== FALSE) {
    $browser = 'Google Chrome';
} elseif(strpos($user_agent, 'Opera Mini') !== FALSE) {
    $browser = &quot;Opera Mini&quot;;
} elseif(strpos($user_agent, 'Opera') !== FALSE) {
    $browser = 'Opera';
} elseif(strpos($user_agent, 'Safari') !== FALSE) {
    $browser = 'Safari';
} else {
    $browser = 'Unknown';
}

if(strpos($user_agent, 'Windows') !== FALSE) {
    $os = 'Windows';
} elseif(strpos($user_agent, 'Linux') !== FALSE) {
    $os = 'Linux';
} elseif(strpos($user_agent, 'Mac') !== FALSE) {
    $os = 'Mac';
} elseif(strpos($user_agent, 'iOS') !== FALSE) {
    $os = 'iOS';
} elseif(strpos($user_agent, 'Android') !== FALSE) {
    $os = 'Android';
} else {
    $os = 'Unknown';
}

if($browser === 'Unknown' || $os === 'Unknown') {
    echo 'No browser detected.';
} else {
    echo 'Your browser is ' . $browser . ' and your operating system is ' . $os . '.';
}
?&gt;

&lt;/body&gt;
&lt;/html&gt;
</code></pre>
<p>Next, save the file and exit <code>nano</code>.
In your browser,
visit your external IP address site
(again, replace your server's IP address):</p>
<pre><code>http://55.333.55.333/
</code></pre>
<p>Although your <strong>index.html</strong> file still exists
in your document root,
Apache2 now returns the <strong>index.php</strong> file
instead.
However, if for some reason the <strong>index.php</strong>
was deleted,
then Apache2 would revert to the <strong>index.html</strong> file
since that's what is listed next in the <strong>dir.conf</strong>
<strong>DirectoryIndex</strong> line.</p>
<h2 id="conclusion-9"><a class="header" href="#conclusion-9">Conclusion</a></h2>
<p>In this section,
we installed PHP and configured it work with Apache2.
We also created a simple PHP test page
that reported our browser user agent information
on our website.</p>
<p>In the next section,
we'll learn how to complete the LAMP stack
by adding the MySQL relational database
to our setup.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="installing-and-configuring-mysql"><a class="header" href="#installing-and-configuring-mysql">Installing and Configuring MySQL</a></h1>
<h2 id="introduction-8"><a class="header" href="#introduction-8">Introduction</a></h2>
<p>We started our LAMP stack when we installed
Apache2 on Linux, and
then we added extra functionality when
we installed and configured PHP to work with Apache2.
In this section,
our objective is to complete
the LAMP stack and install and
configure <a href="https://en.wikipedia.org/wiki/MySQL">MySQL</a>.</p>
<p>If you need a refresher on relational databases, see:
<a href="https://mariadb.com/kb/en/introduction-to-relational-databases/">Introduction to Relational Databases</a>.</p>
<h2 id="install-and-set-up-mysql"><a class="header" href="#install-and-set-up-mysql">Install and Set Up MySQL</a></h2>
<p>In this section, we'll learn how to install,
setup, secure, and configure the MySQL
relational database so that it works
with the Apache2 web server and
the PHP programming language.</p>
<p>First, let's install MySQL Community Server, and
then log into the MySQL shell
under the <strong>MySQL root</strong> account.</p>
<pre><code>sudo apt install mysql-server
</code></pre>
<p>This should also start and
enable the database server, but
we can check if it's running and enabled
using the <code>systemctl</code> command:</p>
<pre><code>systemctl status mysql 
</code></pre>
<!--
Next we need to run a post installation script
called ``mysql_secure_installation``
that sets up the MySQL root password and 
performs some security checks.
To do that, run the following command, and
**be sure to save the MySQL root password you create**:

```
sudo mysql_secure_installation
```

Here you create a root password
for the MySQL database server.
**Be sure to save that password.**
When you run the above script,
you'll get a series of prompts
to respond to like below.
Press **enter** for the first prompt,
press **Y** for the prompts marked **Y**,
and input your own password.
Since this server is exposed to the internet,
be sure to use a complex password.

```
Enter the current password for root (enter for none):
Set root password: Y
New Password: XXXXXXXXX
Re-enter new password: XXXXXXXXX
Remove anonymous users: Y
Disallow root login remotely: Y
Remove test database and access to it: Y
Reload privilege tables now: Y
```
-->
<p>We can login to the database to test it.
In order to do so,
we have to become the <strong>root Linux user</strong>,
which we can do with the following command:</p>
<pre><code>sudo su
</code></pre>
<blockquote>
<p>Note: we need to be careful when we enter commands on the
command line, because it's a largely unforgiving computing
environment. But we need to be especially careful when we
are logged in as the Linux root user. This user can delete
anything, including files that the system needs in order
to boot and operate.</p>
</blockquote>
<p>After we are Linux root,
we can login to MySQL,
run the <code>show databases;</code> command, and
then exit with the <code>\q</code> command:</p>
<blockquote>
<p><strong>NOTE:</strong> we need to distinguish between the regular user
prompt of our Linux accounts and the MySQL prompt below.
In the following, I will use the greater than symbol &gt; to
represent the MySQL prompt. Do not type that prompt when
you are using MySQL.</p>
</blockquote>
<p>First, connect to the MySQL server as the MySQL root user:</p>
<pre><code>mysql -u root
</code></pre>
<p>Then request a list of the databases:</p>
<pre><code>show databases;
</code></pre>
<p>And the following databases should be returned:</p>
<pre><code>+--------------------+
| Database           |
+--------------------+
| information_schema |
| mysql              |
| performance_schema |
+--------------------+
3 rows in set (0.002 sec)
</code></pre>
<blockquote>
<p>Note: If we are logging into the root database account
as the root Linux user, we don't need to enter our password.</p>
</blockquote>
<h2 id="create-and-set-up-a-regular-user-account"><a class="header" href="#create-and-set-up-a-regular-user-account">Create and Set Up a Regular User Account</a></h2>
<p>We need to reserve the <strong>root MySQL user</strong> for
special use cases and
instead create a <strong>regular MySQL user</strong>, or
more than one MySQL user, as needed.</p>
<p>To create a regular MySQL user,
we use the <code>create</code> command.
In the command below,
I'll create a new user called <strong>opacuser</strong>
with a complex password within the single quotes
at the end (marked with a series of Xs here for demo purposes).
From the MySQL prompt:</p>
<pre><code>create user 'opacuser'@'localhost' identified by 'XXXXXXXXX';
</code></pre>
<p>If the prompt returns a <strong>Query OK</strong> message,
then the new user should have been created without any issues.</p>
<h2 id="create-a-practice-database"><a class="header" href="#create-a-practice-database">Create a Practice Database</a></h2>
<p>As the root database user,
let's create a new database for a regular, new user.</p>
<p>The regular user will be
granted <strong>all privileges</strong>
on the new database,
including all its tables.
Other than granting <strong>all privileges</strong>,
we could limit the user to specific privileges, including:
<strong>CREATE, DROP, DELETE, INSERT, SELECT, UPDATE, and GRANT OPTION</strong>.
Such privileges may be called operations or functions, and
they allow MySQL users to use and modify the databases,
where appropriate.
For example,
we may want to limit the <strong>opacuser</strong> user to
only be able to use <strong>SELECT</strong> commands.
It totally depends on the purpose of the database and
our security risks.</p>
<p>From the MySQL query prompt,
run the following commands to
create a new database <strong>opacdb</strong>
and to grant all privileges to <strong>opacdb</strong>
to the MySQL user <strong>opacuser</strong>:</p>
<pre><code>create database opacdb;
grant all privileges on opacdb.* to 'opacuser'@'localhost';
show databases;
</code></pre>
<p>Exit out of the MySQL database
as the <strong>root MySQL user</strong>, and
then exit out of the <strong>root
Linux user account</strong>, and
you should be back to your
normal Linux user account:</p>
<pre><code>\q
</code></pre>
<p>And then exit out of the Linux root user account:</p>
<pre><code>exit
</code></pre>
<blockquote>
<p>Note: relational database keywords are often written in
all capital letters. As far as I know, this is simply a
convention to make the code more readable. However, in
most cases I'll write the keywords in lower case letters.
This is simply because, by convention, I'm super lazy.</p>
</blockquote>
<h2 id="logging-in-as-regular-user-and-creating-tables"><a class="header" href="#logging-in-as-regular-user-and-creating-tables">Logging in as Regular User and Creating Tables</a></h2>
<p>We can now start doing MySQL work.
As a reminder,
we've created a new MySQL user named <strong>opacuser</strong> and
a new database for <strong>opacuser</strong> that is called <strong>opacdb</strong>.
When we run the <code>show databases</code> command as
the <strong>opacuser</strong> user,
we should see the <strong>opacdb</strong> database.
Note below that I use the <code>-p</code> option.
This instructs MySQL to request the password
for the <strong>opacuser</strong> user, which
is required to log in.</p>
<pre><code>mysql -u opacuser -p
</code></pre>
<p>Then from the MySQL prompt,
list the available databases and
switch to the new <strong>opacdb</strong> database:</p>
<pre><code>show databases;
use opacdb;
</code></pre>
<p>A database is not worth much without data.
In the following code,
I create and define a new table for our <strong>opacdb</strong> database.
The table will be called <strong>books</strong>, and
it will contain data describing some books.
We will keep this table very simple and
use only three fields:</p>
<pre><code>create table books (
id int unsigned not null auto_increment,
author varchar(150) not null,
title varchar(150) not null,
copyright date not null,
primary key (id)
);
</code></pre>
<p>You can confirm that the table
was created by running the following
two commands,
which lists the available tables
and then describes the <strong>books</strong> table:</p>
<pre><code>show tables;
describe books;
</code></pre>
<p>Congratulations! Now create some records for that table.</p>
<h3 id="adding-records-into-the-table"><a class="header" href="#adding-records-into-the-table">Adding records into the table</a></h3>
<p>We can populate our <strong>opacdb</strong> database
with some data.
(I simply picked the first book listed from
the NYTimes best lists of books for the years
2019-2022.)
We'll use the <code>insert</code> command to add our records
into our <strong>distribution</strong> table:</p>
<pre><code>insert into books (author, title, copyright) values
('Jennifer Egan', 'The Candy House', '2022-04-05'),
('Imbolo Mbue', 'How Beautiful We Were', '2021-03-09'),
('Lydia Millet', 'A Children\'s Bible', '2020-05-12'),
('Julia Phillips', 'Disappearing Earth', '2019-05-14');
</code></pre>
<p>Now we can view all the records
that we just created with the MySQL
<code>select</code> command:</p>
<pre><code>select * from books;
</code></pre>
<p>Success! Now let's test our table.</p>
<h3 id="testing-commands"><a class="header" href="#testing-commands">Testing Commands</a></h3>
<p>We will complete the following tasks
to refresh our MySQL knowledge:</p>
<ul>
<li>retrieve some records or parts of records, </li>
<li>delete a record,</li>
<li>alter the table structure so that it will hold more data, and</li>
<li>add a record</li>
</ul>
<p><strong>Reminder: each MySQL command ends with a semi-colon.
Some of the following MySQL commands are single-line,
but others are multi-line.
Regardless if a MySQL command is one-line or multi-line,
it doesn't end until it ends with a semi-colon:</strong></p>
<pre><code>select author from books;
select copyright from books;
select author, title from books;
select author from books where author like '%millet%';
select title from books where author like '%mbue%';
select author, title from books where title not like '%e';
select * from books;
alter table books add publisher varchar(75) after title;
describe books;
update books set publisher='Simon \&amp; Schuster' where id='1';
update books set publisher='Penguin Random House' where id='2';
update books set publisher='W. W. Norton \&amp; Company' where id='3';
update books set publisher='Knopf' where id='4';
select * from books;
delete from books where author='Julia Phillips';
insert into books
(author, title, publisher, copyright) values
('Emma Donoghue', 'Room', 'Little, Brown \&amp; Company', '2010-08-06'),
('Zadie Smith', 'White Teeth', 'Hamish Hamilton', '2000-01-27');
select * from books;
select author, publisher from books where copyright &lt; '2011-01-01';
select author from books order by copyright;
\q
</code></pre>
<h2 id="install-php-and-mysql-support"><a class="header" href="#install-php-and-mysql-support">Install PHP and MySQL Support</a></h2>
<p>The next goal is to complete the connection
between PHP and MySQL so that
we can use both for our websites.</p>
<p>First install PHP support for MySQL.
We're installing some modules alongside the basic support.
These may or may not be needed,
but I'm installing them to demonstrate some basics.</p>
<pre><code>sudo apt install php-mysql php-mysqli
</code></pre>
<p>And then restart Apache2 and MySQL:</p>
<pre><code>sudo systemctl restart apache2
sudo systemctl restart mysql
</code></pre>
<h3 id="create-php-scripts"><a class="header" href="#create-php-scripts">Create PHP Scripts</a></h3>
<p>In order for PHP to connect to MySQL,
it needs to authenticate itself.
To do that,
we will create a <strong>login.php</strong> file
in <strong>/var/www/html</strong>.
We also need to change the group ownership
of the file and its permissions so that
the file can be read by the Apache2 web server
but not by the world,
since this file will store password information.</p>
<pre><code>cd /var/www/html/
sudo touch login.php
sudo chmod 640 login.php
sudo chown :www-data login.php
ls -l login.php
sudo nano login.php
</code></pre>
<p>In the file,
add the following credentials.
If you used a different database name than <strong>opacdb</strong>
and a different username than <strong>opacuser</strong>,
then you need to substitute your names below. 
You need to use your own password where
I have the Xs:</p>
<pre><code>&lt;?php // login.php
$db_hostname = &quot;localhost&quot;;
$db_database = &quot;opacdb&quot;;
$db_username = &quot;opacuser&quot;;
$db_password = &quot;XXXXXXXXX&quot;;
?&gt;
</code></pre>
<p>Next we create a new PHP file for our website.
This file will display HTML but
will primarily be PHP interacting with our
<strong>books</strong> database.</p>
<p>Create a file titled <strong>opac.php</strong>.</p>
<pre><code>sudo nano opac.php
</code></pre>
<p>Then copy over the following text
(I suggest you transcribe it, especially
if you're interested in learning a bit of PHP, but
you can simply copy and paste it into the <code>nano</code> buffer):</p>
<pre><code>&lt;html&gt;
&lt;head&gt;
&lt;title&gt;MySQL Server Example&lt;/title&gt;
&lt;/head&gt;
&lt;body&gt;

&lt;h1&gt;A Basic OPAC&lt;/h1&gt;

&lt;p&gt;We can retrieve all the data from our database and book table
using a couple of different queries.&lt;/p&gt;

&lt;?php

// Load MySQL credentials
require_once 'login.php';

// Establish connection
$conn = mysqli_connect($db_hostname, $db_username, $db_password) or
  die(&quot;Unable to connect&quot;);

// Open database
mysqli_select_db($conn, $db_database) or
  die(&quot;Could not open database '$db_database'&quot;);

echo &quot;&lt;h2&gt;Query 1: Retrieving Publisher and Author Data&lt;/h2&gt;&quot;;

// Query 1
$query1 = &quot;select * from books&quot;;
$result1 = mysqli_query($conn, $query1);

while($row = $result1-&gt;fetch_assoc()) {
	echo &quot;&lt;p&gt;Publisher &quot; . $row[&quot;publisher&quot;] .
		&quot; published a book by &quot; . $row[&quot;author&quot;] .
		&quot;.&lt;/p&gt;&quot;;
}

mysqli_free_result($result1);

echo &quot;&lt;h2&gt;Query 2: Retrieving Author, Title, Date Published Data&lt;/h2&gt;&quot;;

$result2 = mysqli_query($conn, $query1);
while($row = $result2-&gt;fetch_assoc()) {
	echo &quot;&lt;p&gt;A book by &quot; . $row[&quot;author&quot;] .
		&quot; titled &lt;em&gt;&quot; . $row[&quot;title&quot;] .
		&quot;&lt;/em&gt; was released on &quot; . $row[&quot;copyright&quot;] .
		&quot;.&lt;/p&gt;&quot;;
}

// Free result2 set
mysqli_free_result($result2);

/* Close connection */
mysqli_close($conn);

?&gt;

&lt;/body&gt;
&lt;/html&gt;
</code></pre>
<p>Save the file and exit out of <code>nano</code>.</p>
<h3 id="test-syntax"><a class="header" href="#test-syntax">Test Syntax</a></h3>
<p>After you save the file and exit the text editor,
we need to test the PHP syntax.
If there are any errors in our PHP,
these commands will show the line numbers
that are causing errors or leading up to errors.
Nothing will output if all is well with the first command.
If all is well with the second command, HTML should be outputted:</p>
<pre><code>sudo php -f login.php
sudo php -f index.php
</code></pre>
<h2 id="conclusion-10"><a class="header" href="#conclusion-10">Conclusion</a></h2>
<p>Congratulations! If you've reached this far,
you have successfully created a LAMP stack.
In the process,
you have learned how to install and set up MySQL,
how to create MySQL root and regular user accounts,
how to create a test database
with play data for practicing, and
how to connect this with PHP for display on a webpage.</p>
<p>In regular applications of these technologies,
there's a lot more involved, but
completing the above process is a great start to
learning more.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="creating-a-bare-bones-opac"><a class="header" href="#creating-a-bare-bones-opac">Creating a Bare Bones OPAC</a></h1>
<p>In this section,
we're going to create a bare bones and
very basic OPAC.
The idea is simply to acquire an
intuition and understanding of how data
from a relational database is
retrieved and entered using
various technologies.</p>
<p>A real integrated library system
is much more complex than what
we are doing here, but
the fundamental ideas are the same:
we enter data into a database,
and we retrieve data from a database.
And then a whole slew of other technologies
are added to present the data in a user-friendly
way: HTML, CSS, and JavaScript.</p>
<p>Integrated library systems (ILS) also provide
multiple modules for patron management,
acquisitions, circulation, cataloging,
serials management, authorities, reporting,
and so forth
(see <a href="koha-about">Koha: About</a>].
All of those modules rely on some kind
of underlying relational database,
like MySQL
(which is what Koha uses).
And this results in a complex,
interconnected set of tables.
We are working with only one table
in our database,
the <strong>books</strong> table.
In reality, an ILS will rely on
dozens of tables.</p>
<p>In the prior section,
we created a MySQL database
called <strong>opacdb</strong>.
That database has one table,
called <strong>books</strong>.
Then we created a file that
used PHP to retrieve the data
from the <strong>books</strong> table
and present it on a web page.</p>
<p>In this section,
we are going to use different
PHP code that will allow us
to search the <strong>books</strong> table
and retrieve results based
on our search query.
In this way,
we are more closely mimicking
an OPAC,
even though we're still far from
creating anything that's full fledged.</p>
<h2 id="creating-the-html-page-and-a-php-search-page"><a class="header" href="#creating-the-html-page-and-a-php-search-page">Creating the HTML Page and a PHP Search Page</a></h2>
<p>The first thing we do is
create a basic HTML page that
contains a form for entering queries.
We'll call this HTML page with the form
<strong>opacbb.html</strong> (just a made up name).
When a user clicks on the submit button
in the form,
the form will activate a PHP script
called <strong>search.php</strong>.
That <strong>search.php</strong> will establish
a connection to the OPAC database
that we already have created.
Our PHP script will contain a special
MySQL query that will allow us to
search all the fields in our <strong>books</strong> table.
The it will iterate through each row of
the <strong>books</strong> table and return results
that match our query.
We also add two date fields to our form
to limit results by publication dates,
which we labeled as <strong>copyright</strong> in our
MySQL <strong>books</strong> table.</p>
<h3 id="html-form"><a class="header" href="#html-form">HTML Form</a></h3>
<p>Here is the HTML for our search page:</p>
<pre><code>&lt;html&gt;
&lt;head&gt;
&lt;title&gt;MySQL Server Example&lt;/title&gt;
&lt;/head&gt;
&lt;body&gt;

&lt;h1&gt;A Basic OPAC&lt;/h1&gt;

&lt;p&gt;In the form below,
&lt;b&gt;optionally&lt;/b&gt; enter text in the search field.
You can search by author, title, or publisher.
Capitalization is not necessary.
It's okay to enter partial information,
like part of an author's, title's, or publisher's name.&lt;/p&gt;

&lt;p&gt;The date fields are &lt;b&gt;required&lt;/b&gt;.
You can use the date fields to limit results.
I added some extra records,
which you can view to know what you can query:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://11.111.222.222/opac.php&quot;&gt;http://11.111.222.222/opac.php&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This is very much a toy, stripped down OPAC.
The records are basic.
Not only do they not conform to MARC,
but they don't even conform to something
as simple as Dublin Core.
I also don't provide options
to select different fields,
like author, title, or publisher fields.
Instead the search field below searches
all the fields in our &lt;b&gt;books&lt;/b&gt; table.
The key idea is to get a sense,
an intuition, of how an OPAC works, though.&lt;/p&gt;

&lt;h2&gt;My Basic Library OPAC&lt;/h2&gt;
&lt;form method=&quot;post&quot; action=&quot;search.php&quot;&gt;
    &lt;label for=&quot;search&quot;&gt;Search:&lt;/label&gt;
    &lt;input type=&quot;text&quot; name=&quot;search&quot; id=&quot;search&quot;&gt;
    &lt;br&gt;
    &lt;label for=&quot;start_date&quot;&gt;Start Date:&lt;/label&gt;
    &lt;input type=&quot;date&quot; name=&quot;start_date&quot; id=&quot;start_date&quot;&gt;
    &lt;br&gt;
    &lt;label for=&quot;end_date&quot;&gt;End Date:&lt;/label&gt;
    &lt;input type=&quot;date&quot; name=&quot;end_date&quot; id=&quot;end_date&quot;&gt;
    &lt;br&gt;
    &lt;input type=&quot;submit&quot; value=&quot;Search&quot;&gt;
&lt;/form&gt;


&lt;/body&gt;
&lt;/html&gt;
</code></pre>
<h3 id="php-search-script"><a class="header" href="#php-search-script">PHP Search Script</a></h3>
<p>Here is the PHP for our search script:</p>
<pre><code>&lt;?php
// Load MySQL credentials
require_once 'login.php';

// Establish connection
$conn = mysqli_connect($db_hostname, $db_username, $db_password) or
  die(&quot;Unable to connect&quot;);

// Open database
mysqli_select_db($conn, $db_database) or
  die(&quot;Could not open database '$db_database'&quot;);

// Check if search query was submitted
if (isset($_POST['search'])) {
    // Sanitize user input to prevent SQL injection attacks
    $search = mysqli_real_escape_string($conn, $_POST['search']);

    // Get the start and end dates for the date range
    $start_date = mysqli_real_escape_string($conn, $_POST['start_date']);
    $end_date = mysqli_real_escape_string($conn, $_POST['end_date']);

    // Build the MySQL query with a WHERE
    // clause that includes the date range filter
    $query = &quot;SELECT * FROM books WHERE
	    (author LIKE '%$search%' OR
		title LIKE '%$search%' OR
		publisher LIKE '%$search%') AND
		copyright BETWEEN '$start_date' AND '$end_date'&quot;;

    // Execute the query
    $result = mysqli_query($conn, $query);

    // Check if any results were returned
    if (mysqli_num_rows($result) &gt; 0) {
        // Loop through the results and output them
        while ($row = mysqli_fetch_assoc($result)) {
            echo &quot;ID: &quot; . $row[&quot;id&quot;] . &quot;&lt;br&gt;&quot;;
            echo &quot;Author: &quot; . $row[&quot;author&quot;] . &quot;&lt;br&gt;&quot;;
            echo &quot;Title: &quot; . $row[&quot;title&quot;] . &quot;&lt;br&gt;&quot;;
            echo &quot;Publisher: &quot; . $row[&quot;publisher&quot;] . &quot;&lt;br&gt;&quot;;
            echo &quot;Copyright: &quot; . $row[&quot;copyright&quot;] . &quot;&lt;br&gt;&lt;br&gt;&quot;;
        }
    } else {
        echo &quot;No results found.&quot;;
    }

    // Free up memory by closing the MySQL result set
    mysqli_free_result($result);
}

// Close the MySQL connection
mysqli_close($conn);

echo &quot;&lt;p&gt;Return to search page: &lt;a href='http://11.111.222.222/opacbb.php'&gt;http://11.111.222.222/opacbb.php&lt;/a&gt;&lt;/p&gt;&quot;;

?&gt;
</code></pre>
<h2 id="modifications"><a class="header" href="#modifications">Modifications</a></h2>
<p>Replace my IP address (11.111.222.222) above
with your IP address.
Add more records,
using MySQL,
to your <strong>books</strong> table,
and test your queries.</p>
<p>To add records to your <strong>books</strong> table,
recall that we used the <strong>insert into</strong>
MySQL statements.
Here's the example from the prior lesson.
Use it to add titles that are of interest to you.</p>
<p>First connect to the MySQL server:</p>
<pre><code>mysql -u opacuser -p
</code></pre>
<p>Then run the <code>insert</code> command with
the data for the new records:</p>
<pre><code>insert into books
(author, title, publisher, copyright) values
('Emma Donoghue', 'Room', 'Little, Brown \&amp; Company', '2010-08-06'),
('Zadie Smith', 'White Teeth', 'Hamish Hamilton', '2000-01-27');
</code></pre>
<h2 id="conclusion-11"><a class="header" href="#conclusion-11">Conclusion</a></h2>
<p>In this lesson,
we created a very bare bones OPAC
simply to express the fundamental idea
of how data is stored and retrieved on the web.
In reality, what separates an OPAC,
or a discovery service in a modern
integrated library system
or library service platform,
from other databases on the web
is the structure of the records
that are stored in the relational database.
Such records are structured using MARC.
Our records are very simply structured,
but still,
I hope this helps in creating an intuition
about how OPACs and like function.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="creating-a-bare-bones-cataloging-module"><a class="header" href="#creating-a-bare-bones-cataloging-module">Creating a Bare Bones Cataloging Module</a></h1>
<p>If you have worked with an integrated library system
(or took my electronic resource management class),
then you know that an OPAC is simply one module out
of several that makeup an integrated library system (ILS).
Integrated library systems, and the
newer library service platforms (LSP),
provide <a href="https://cseanburns.net/WWW/ERM-book/04-erm-ils.html#administration">other modules for other types of work</a>.
These include modules for acquisitions, authority files,
circulation, course reserves, patron management, and more.</p>
<p>In this section,
we are going to create a bare bones cataloging module in
the same kind of way that we created a bare bones OPAC.
Up until this point,
you have been adding records to your OPAC
using the MySQL command interface.
But unless you are a full time database administrator
or programmer,
it's unlikely that you would add data to your system
via that interface.
Instead you would use a fancy graphical user interface,
which is what integrated library systems provide.
The reason we started off with MySQL is not because
you would necessarily use this interface on a daily basis.
Rather, it's because I want you to understand the
foundations of these technologies.</p>
<h2 id="creating-the-html-page-and-a-php-cataloging-page"><a class="header" href="#creating-the-html-page-and-a-php-cataloging-page">Creating the HTML Page and a PHP Cataloging Page</a></h2>
<p>Like in the last excerise,
the first thing we do is create a basic HTML page that
contains a form for entering our bibliographic data.
Again, our cataloging <em>module</em> will not be
real world like.
The goal here is to build an intuition about
how these technologies work and
to also provide some grounding if you do want
to pursue a more technical path.</p>
<p>The form that we will create also needs to mirror
the data structure in the <strong>books</strong> table that we
created in our prior lesson.
That means it will only contain four fields:</p>
<ul>
<li>author</li>
<li>title</li>
<li>publisher</li>
<li>copyright</li>
</ul>
<p>I'll call this page <strong>index.html</strong>.
I'll create a new directory for this module:</p>
<pre><code>cd /var/www/html
sudo mkdir cataloging
</code></pre>
<p>Then I'll use nano to create the index.html
file and add the content:</p>
<pre><code>cd cataloging
sudo nano index.html
</code></pre>
<p>In <strong>index.html</strong>, 
we add the following content:</p>
<pre><code>&lt;!DOCTYPE html&gt;
&lt;html&gt;
&lt;head&gt;
	&lt;title&gt;Enter Records&lt;/title&gt;
&lt;/head&gt;
&lt;body&gt;
	&lt;h1&gt;OPAC Library Administration&lt;/h1&gt;

	&lt;p&gt;This is the library administration page for entering records into the OPAC.&lt;/p&gt;
	&lt;p&gt;Please do not use this page unless you are an authorized cataloger.&lt;/p&gt;

	&lt;form action=&quot;insert.php&quot; method=&quot;post&quot;&gt;
		&lt;label for=&quot;author&quot;&gt;Author:&lt;/label&gt;
		&lt;input type=&quot;text&quot; name=&quot;author&quot; id=&quot;author&quot; required&gt;&lt;br&gt;&lt;br&gt;

		&lt;label for=&quot;title&quot;&gt;Book Title:&lt;/label&gt;
		&lt;input type=&quot;text&quot; name=&quot;title&quot; id=&quot;title&quot; required&gt;&lt;br&gt;&lt;br&gt;

		&lt;label for=&quot;publisher&quot;&gt;Publisher:&lt;/label&gt;
		&lt;input type=&quot;text&quot; name=&quot;publisher&quot; id=&quot;publisher&quot; required&gt;&lt;br&gt;&lt;br&gt;

		&lt;label for=&quot;copyright&quot;&gt;Copyright:&lt;/label&gt;
		&lt;input type=&quot;date&quot; id=&quot;copyright&quot; name=&quot;copyright&quot;&gt;

		&lt;input type=&quot;submit&quot; value=&quot;Submit&quot;&gt;
	&lt;/form&gt;
&lt;/body&gt;
&lt;/html&gt;
</code></pre>
<h2 id="php-insert-script"><a class="header" href="#php-insert-script">PHP Insert Script</a></h2>
<p>The <strong>index.html</strong> page will provide a user interface,
that is, a form,
for entering our bibliographic data.
However, the PHP script is needed
to communicate and add the data from our
form into our MySQL database and <strong>books</strong> table.</p>
<p>Also, just as the HTML form has to
match the data structure of the <strong>books</strong> table,
the PHP script also needs to match the form
from the HTML page and the data structure
in the <strong>books</strong> table.</p>
<p>Here is the PHP script,
which I call <strong>insert.php</strong>:</p>
<pre><code>&lt;?php

// Load MySQL credentials
require_once '../login.php';

// Establish connection
$conn = mysqli_connect($db_hostname, $db_username, $db_password) or
  die(&quot;Unable to connect&quot;);

// Open database
mysqli_select_db($conn, $db_database) or
  die(&quot;Could not open database '$db_database'&quot;);

// Prepare and bind SQL statement
$stmt = $conn-&gt;prepare(&quot;INSERT INTO books (author, title, publisher, copyright) VALUES (?, ?, ?, ?)&quot;);
$stmt-&gt;bind_param(&quot;ssss&quot;, $author, $title, $publisher, $copyright);

// Set parameters and execute statement
$author = $_POST[&quot;author&quot;];
$title = $_POST[&quot;title&quot;];
$publisher = $_POST[&quot;publisher&quot;];
$copyright = $_POST[&quot;copyright&quot;];

if ($stmt-&gt;execute() === TRUE) {
    echo &quot;New record created successfully&quot;;
} else {
    echo &quot;Error: &quot; . $stmt-&gt;error;
}

// Close statement and connection
$stmt-&gt;close();
$conn-&gt;close();

echo &quot;&lt;p&gt;Return to the cataloging page: &lt;a href='http://11.111.111.111/cataloging/'&gt;http://11.111.111.111/cataloging/&lt;/a&gt;&lt;/p&gt;&quot;;
?&gt;
</code></pre>
<h2 id="security"><a class="header" href="#security">Security</a></h2>
<p>Since our HTML and PHP files allow us
to enter data into our MySQL database
from a simple web interface,
we need to limit access to the module.
Again, in a real-world situation,
modules like these would have a variety of
security measures in place to prevent
wrongful data entry.
In our case,
we will rely on a simple authorization
mechanism provided by the Apache2 server
called <a href="https://www.digitalocean.com/community/tutorials/how-to-set-up-password-authentication-with-apache-on-ubuntu-18-04">htpasswd</a>.</p>
<p>First, we create an authentication file
in our <strong>/etc/apache2</strong> directory,
which is where the <strong>Apache2</strong> web server
stores its configuration files.
The file will contain a <strong>hashed</strong> password
and a username we give it.
In the following command,
I set the username to <strong>libcat</strong>, but
it could be anything:</p>
<pre><code>sudo htpasswd -c /etc/apache2/.htpasswd libcat
</code></pre>
<p>Next we need to tell the Apache2 web server
that we will use the <code>htpasswd</code> to control
access to our cataloging module.
To do that,
we use <code>nano</code> to open the <strong>apache2.conf</strong> file.
We need</p>
<pre><code>sudo nano /etc/apache2/apache2.conf
</code></pre>
<p>In the <strong>apache2.conf</strong> file,
look for the following code block / stanza.
We are interested in the third line in the stanza,
which is line 173 for me, and
probably is for you, too.</p>
<pre><code>&lt;Directory /var/www/&gt;
  Options Indexes FollowSymLinks
  AllowOverride None
  Require all granted
&lt;/Directory&gt;
</code></pre>
<p>Carefully, we need to change the word
<strong>None</strong> to the word <strong>All</strong>:</p>
<pre><code>&lt;Directory /var/www/&gt;
  Options Indexes FollowSymLinks
  AllowOverride All
  Require all granted
&lt;/Directory&gt;
</code></pre>
<p>Next, change to the <strong>cataloging</strong> directory and
use <code>nano</code> to create a file called <strong>.htaccess</strong>
(note the leading period):</p>
<pre><code>cd /var/www/html/cataloging
sudo nano .htaccess
</code></pre>
<p>Add the following content to <strong>.htaccess</strong>:</p>
<pre><code>AuthType Basic
AuthName &quot;Authorization Required&quot;
AuthUserFile /etc/apache2/.htpasswd
Require valid-user
</code></pre>
<p>Check that the configuration file is okay:</p>
<pre><code>apachectl configtest
</code></pre>
<p>If you get a <strong>Syntax OK</strong> message,
then restart Apache2 and
check its status:</p>
<pre><code>sudo systemctl restart apache2
systemctl status apache2
</code></pre>
<p>Now visit your cataloging module.
You should be required to enter the username
and password that you created with <code>htpasswd</code>.</p>
<h2 id="conclusion-12"><a class="header" href="#conclusion-12">Conclusion</a></h2>
<p>In the last lesson,
we created a very bare bones OPAC
that would allow patrons to
search our catalog.
In this lesson,
we learned how to create a very
bare bones cataloging module
that would allow librarians
to add bibliographic data
and records to our OPAC.</p>
<p>Add some records using the above form,
and then return to your OPAC and
conduct some queries to confirm
that the new records have been added.</p>
<p>You can also use the MySQL command line
interface to view the new records,
just like we did a couple of lessons ago.</p>
<p>In a production level environment,
we would add quite a bit more.
Our MySQL database would contain
many more tables that allow storing
data related to the modules listed above.
We would also like to make our modules
graphically attractive and provide more content.
That would mean we would add
<a href="https://en.wikipedia.org/wiki/CSS">Cascading Style Sheets (CSS)</a> and
<a href="https://en.wikipedia.org/wiki/JavaScript">JavaScript</a> to create an
attractive and usable interface.
But that would be a whole other class.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="installing-content-management-systems"><a class="header" href="#installing-content-management-systems">Installing Content Management Systems</a></h1>
<p>Many library websites are compositions of interconnected resources.
For example, a library may have a front-facing website that provides
basic information about the library, its physical locations, and its services.
That front-facing website may be connected to an integrated library system (ILS)
or library service platform (LSP) that is itself a different website.
The front-facing website may also be connected to other sites
that provide access to all sorts of databases.
In the end, this means that a library website is not just one place.
It is much more like a series of interconnected buildings,
each of which has its own entry points.</p>
<p>In this section,
we will learn how to build these interconnected resources.
First, we learn how to use <a href="https://wordpress.org/">WordPress</a> to setup a library's
front-facing web presence.
The basic process is similar to the process we used when building
our bare bones OPAC.
We will then use the instructions for the WordPress install to
install and configure <a href="https://omeka.org/">Omeka</a>,
which we might imagine is used to build a digital library for our library.</p>
<p>At the end of this section,
we will have begun creating a library web presence that is more
than a basic front-facing web presence.
Instead, it will start the infrastructure for an ecosystem that
provides access to all sorts of library resources.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="install-wordpress"><a class="header" href="#install-wordpress">Install WordPress</a></h1>
<h2 id="introduction-9"><a class="header" href="#introduction-9">Introduction</a></h2>
<p><a href="https://en.wikipedia.org/wiki/WordPress">WordPress</a> is a free and open source
content management system (CMS).
Originally, its focus was on providing
a platform for blogging, but
throughout the last decade plus,
it has become a general purpose CMS
that can serve as a website builder.
Two sites exist to provide access to WordPress:
<a href="https://wordpress.com">WordPress.com</a> and <a href="https://wordpress.org">Wordpress.org</a>.
WordPress.com is a hosting solution,
which means that customers can sign up and
create a free WordPress site.
Since its hosted,
customers are only responsible for
their content and not for managing
the WordPress installation and its updates.
Various paid plans can extend the functionality
offered to WordPress.com customers.</p>
<p>WordPress.org is maintained by
the <a href="https://wordpressfoundation.org/">WordPress Foundation</a>, which 
oversees the development of and
provides access to the WordPress software.
When we download the WordPress software,
we download it from WordPress.org.
Unlike the hosted solution,
when we install and setup WordPress
on our own servers,
we become responsible for administrating
its installation and for keeping the software updated.</p>
<p>WordPress is widely used software,
and because of that,
it's often the focus of attack.
Take a moment to read about the developers's
efforts to protect WordPress: <a href="https://wordpress.org/about/security/">Security</a>.
We will not need to update our WordPress installs
during the course of this course, but
you should be familiar with the update process
in case you decide to maintain your install or
an install at a future date:
<a href="https://wordpress.org/documentation/article/updating-wordpress/">Updating WordPress</a>.</p>
<h2 id="libraries-and-wordpress"><a class="header" href="#libraries-and-wordpress">Libraries and WordPress</a></h2>
<p>Many libraries use WordPress as
as their main website and
a quick web search will reveal them.
For example, I quickly found an
example of a (beautiful) WordPress library site for
the <a href="https://readingpl.org/">Reading Public Library (RPL)</a>
in Massachusetts.
These library websites coordinate with additional
solutions that provide integrated library systems
and other electronic resource services.
RPL, for instance, connects their WordPress
installation,
which serves as their main website page,
with the open source <a href="https://evergreen-ils.org/">Evergreen ILS</a>,
which serves their OPAC.
Check this by clicking on RPL's <strong>Library Catalog</strong> link,
and you will see that it takes you to a different URL.</p>
<blockquote>
<p>Aside: it is this need to coordinate so many services
across all these websites that in part drives the need to
develop standards for data exchange and work flow
processes. For those of you have taken my electronic
resource management course, you will recall we spent an
entire module on this topic.</p>
</blockquote>
<p>Many library websites are partitioned like this.
Thus, when we install WordPress soon,
it is as if we are only
installing the <em>front entrance</em>
to the library.
Libraries are generally like this.
They have one main website (like https://libraries.uky.edu)
but then connect to other sites that provide access
to OPACS, discovery systems, OverDrive or other eBook
vendors, bibliographic databases, and more.
This is part of the confusion
around how libraries provide electronic resources.
There are efforts to make all
these components connect more seamlessly
(e.g., through discovery systems),
but if we were to model this to the
walking around world,
it would be like having a library that
has multiple buildings,
where each building provides one thing:
one building for books,
one building for journals,
another building for other journals,
another building for another set of journals,
another building for looking up where to find journals,
another building for special collections,
and so on.
I digress.</p>
<p>You can read the announcement
about RPL's WordPress launch at:
<a href="https://www.bartlettinteractive.com/blog/libraries-using-wordpress">Reading Public Library Launches New WordPress Site</a>.
The above announcement page also describes how
various plugins were used to offer patrons
additional functionality.
These include plugins to display
business hours and to manage events and
event attendees.
Plugins are often used with WordPress sites
to offer all sorts of additional capabilities.
Currently, there are over <a href="https://wordpress.org/plugins/">60 thousand plugins</a>
available for WordPress, but
some are of higher quality and utility than others.
In addition to the thousands of available plugins,
there are over <a href="https://wordpress.org/themes/">10 thousand free themes</a> for
WordPress sites.
Plus, many businesses offer paid themes or can
offer customized themes based on customer needs.
These themes can drastically alter the
appearance and usability of a WordPress site.</p>
<h2 id="installation-2"><a class="header" href="#installation-2">Installation</a></h2>
<p>So far I have shown you how to install
software using two methods:</p>
<ul>
<li>using the <code>apt</code> command</li>
<li>downloading from GitHub</li>
</ul>
<p>In this lesson,
we are going to install WordPress by
downloading the most recent version
from WordPress.org
and installing it manually.
The WordPress application is available
via the <code>apt</code> command, but
the <code>apt</code> process makes it a bit more
confusing than it should be, oddly.</p>
<p>We are going to <em>kind of</em> follow
the documentation provided by WordPress.org.
You should read through the documentation <em><strong>before</strong></em>
following my instructions, but
then follow the process I outline here instead
because the documentation uses some different
tools than we'll use.</p>
<p>Another reason we do this manually is because it
builds on what we have learned by building
our bare bones ILS.
That is, the two processes are similar.
In both cases,
we create a specific database for our platform,
we create a specific user for that database,
and we provide login credentials in a specific file.</p>
<p>First, read through but don't follow the following instructions:</p>
<p><a href="https://wordpress.org/documentation/article/how-to-install-wordpress/">How to install WordPress</a></p>
<h2 id="customized-installation-process"><a class="header" href="#customized-installation-process">Customized Installation Process</a></h2>
<p>After you have read through the WordPress.org
documentation,
follow the steps below to complete the manual install:</p>
<h3 id="step-1-requirements"><a class="header" href="#step-1-requirements">Step 1: Requirements</a></h3>
<p>All major software has dependencies.
For example, our bare bones OPAC depends on
MySQL and PHP to provide the database (MySQL) and
the glue (PHP) between our HTML and the database.
The same is true for WordPress.
However, since WordPress is much more complicated
software than our bare bones OPAC,
its dependencies are stricter.
This means that when
we plan to download software outside
of the <code>apt</code> ecosystem,
we need to make sure that our systems
meet the requirements for our installation.
The <a href="https://wordpress.org/about/requirements/">WordPress.org Requirements</a> page
states that the WordPress installation requires
at least PHP version 7.4 and MySQL version 5.7.
We can check that our systems meet these
requirements with the following commands:</p>
<pre><code>php --version
mysql --version
</code></pre>
<p>The output from <code>php --version</code> shows that our systems
have PHP 7.4.3,
which is greater than PHP 7.4.
The output from <code>mysql --version</code> show that our systems
have MySQL 8.0,
which is greater than MySQL 5.7.
This means we can proceed.</p>
<p>Next, we need to add some additional PHP
modules to our system to let WordPress operate
at full functionality.
We can install these using the <code>apt</code> command:</p>
<pre><code>sudo apt install php-curl php-xml php-imagick php-mbstring php-zip php-intl
</code></pre>
<p>Then restart Apache2 and MySQL:</p>
<pre><code>sudo systemctl restart apache2
sudo systemctl restart mysql
</code></pre>
<h3 id="step-2-download-and-extract"><a class="header" href="#step-2-download-and-extract">Step 2: Download and Extract</a></h3>
<p>The next step is to download and
extract the WordPress software,
which is downloaded as a <strong>tar.gz</strong> file.
This is very much like a compressed
<strong>zip</strong> file.
Although we only download one file,
when we extract it with the <code>tar</code> command,
the extraction will result in a new directory
that contains multiple files and subdirectories.
The general instructions include:</p>
<ol>
<li>Change to the <strong>/var/www/html</strong> directory.</li>
<li>Download the latest version of WordPress using the <code>wget</code>
program.</li>
<li>Extract the package using the <code>tar</code> program.</li>
</ol>
<p>Specifically, we do the following on the command line:</p>
<pre><code>cd /var/www/html
sudo wget https://wordpress.org/latest.tar.gz
sudo tar -xzvf latest.tar.gz
</code></pre>
<p>As noted in the WordPress documentation,
this will create a directory
called <strong>wordpress</strong> in the same directory.
Therefore the full path of your
installation will located at
<strong>/var/www/html/wordpress</strong></p>
<h3 id="step-3-create-the-database-and-a-user"><a class="header" href="#step-3-create-the-database-and-a-user">Step 3: Create the Database and a User</a></h3>
<p>The WordPress documentation describes how
to use <strong>phpMyAdmin</strong> to create the database
and a user for WordPress.
<strong>phpMyAdmin</strong> is a graphical front end to the
MySQL relational database that you would access
through the browser.
But I like to minimize the software that we install
on servers to reduce the server's security exposure.
Therefore, we are going to create the WordPress database
and a database user using the same process we used
to create a database and user for our bare bones OPAC.
The general instructions are:</p>
<ol>
<li>Switch to the root Linux user</li>
<li>Login as the MySQL root user</li>
</ol>
<p>Specifically, we do the following on the command line:</p>
<pre><code>sudo su
mysql -u root
</code></pre>
<p>The <code>mysql -u root</code> command places
us in the MySQL command prompt.
The next general instructions are to:</p>
<ol>
<li>Create a new user for the WordPress database</li>
<li>Be sure to replace the Xs with a strong password</li>
<li>Create a new database for WordPress</li>
<li>Grant all privileges to the new user for the new database</li>
<li>Examine the output</li>
<li>Exit the MySQL prompt</li>
</ol>
<p>Specifically, this means the following
(be sure to replaces the <strong>Xs</strong> with a unique
and strong password of your own):</p>
<pre><code>create user 'wordpress'@'localhost' identified by 'XXXXXXXXX';
create database wordpress;
grant all privileges on wordpress.* to 'wordpress'@'localhost';
show databases;
\q
</code></pre>
<h3 id="step-4-set-up-wp-configphp"><a class="header" href="#step-4-set-up-wp-configphp">Step 4: Set up wp-config.php</a></h3>
<p>When we created our bare bones OPAC,
we created a file called <strong>login.php</strong>
that contained the name of the database (e.g., opacdb),
the name of the database user (e.g., opacuser),
and the user's password.
WordPress follows a similar process, but
instead of <strong>login.php</strong>,
it uses a file called <strong>wp-config.php</strong>.</p>
<p>Follow these general steps:</p>
<ol>
<li>Change to the <strong>wordpress</strong> directory, if you haven't
already.</li>
<li>Copy and rename the <strong>wp-config-sample.php</strong> file to
<strong>wp-config.php</strong>.</li>
<li>Edit the file and add your WordPress database name, user
name, and password in the fields for <strong>DB_NAME</strong>,
<strong>DB_USER</strong>, and <strong>DB_PASSWORD</strong>.</li>
</ol>
<p>This means that we specifically do the following:</p>
<pre><code>cd /var/www/html/wordpress
sudo cp wp-config-sample.php wp-config.php
sudo nano wp-config.php
</code></pre>
<p>In <code>nano</code>,
add your database name, user, and password
in the appropriate fields,
just like we did with our <strong>login.php</strong> file
for our bare bones OPAC.</p>
<p>Additionall, we want to disable FTP uploads
to the site.
To do that,
navigate to the end of the file and
add the following line:</p>
<pre><code>define('FS_METHOD','direct');
</code></pre>
<h3 id="step-5-optional"><a class="header" href="#step-5-optional">Step 5: <strong>Optional</strong></a></h3>
<p>The WordPress files were installed at
<strong>/var/www/html/wordpress</strong>.
This means that your site would be located at:</p>
<pre><code>http://11.111.111.11/wordpress
</code></pre>
<p>If you want to,
you can rename your <strong>wordpress</strong> directory
to something else.
The WordPress documentation
uses <strong>blog</strong> as an example.
But it could be something else,
like the name of a fictional library
that you might be using WordPress
to build a site.
If you decide to change it,
be sure to keep the name lowercase
and one word (no spaces and only alphabetic characters).
For example, if I want to change mine to <strong>blog</strong>, then:</p>
<pre><code>cd /var/www/html
sudo mv wordpress blog
</code></pre>
<h3 id="step-6-change-file-ownership"><a class="header" href="#step-6-change-file-ownership">Step 6: Change File Ownership</a></h3>
<p>WordPress will need to write to files
in the base directory.
Assuming your still in your base directory,
whether that is <code>/var/www/html/wordpress</code> or
<code>/var/www/html/blog</code> or like,
run the following command:</p>
<pre><code>sudo chown -R www-data:www-data *
</code></pre>
<h3 id="step-7-run-the-install-script"><a class="header" href="#step-7-run-the-install-script">Step 7: Run the Install Script</a></h3>
<p>The next part of the process takes
place in the browser.
The location (URL) that you visit in the browser
depends on your specific IP address and also
includes the directory in <strong>/var/www/html</strong> that
we extracted WordPress to or that you renamed
if you followed <strong>Step 5</strong>.
Thus, if my IP address is 11.111.111.11 and
I renamed by directory to <strong>blog</strong>, then
I need to visit the following URL:</p>
<pre><code>http://11.111.111.11/blog/wp-admin/install.php
</code></pre>
<p><strong>IF</strong> I kept the directory named <strong>wordpress</strong>, then
this is the URL that I use:</p>
<pre><code>http://11.111.111.11/wordpress/wp-admin/install.php
</code></pre>
<h3 id="finishing-installation"><a class="header" href="#finishing-installation">Finishing installation</a></h3>
<p>From this point forward,
the steps to complete the installation are
exactly the steps you follow using
WordPress's documentation.</p>
<p>Most importantly, you should see a <strong>Welcome</strong> screen
where you enter your site's information.
The site <strong>Username</strong> and <strong>Password</strong> <em>should not</em>
be the same as the username and password you used
to create your WordPress database in MySQL.
Rather, the username and password you enter here
are for WordPress users; i.e.,
those who will add content and manage the website.</p>
<p><strong>Two things to note:</strong></p>
<p>We have not setup <strong>Email</strong>
on our servers.
It's actually quite complicated to setup an email
server correctly and securely, but
it wouldn't work well without having a domain name
setup anyway.
So know that you probably should enter an email
when setting up the user account,
but it won't work.</p>
<p>Second, when visiting your site,
your browser may throw an error.
Make sure that the URL is set to <strong>http</strong>
and that it's not trying to access <strong>https</strong>.
Setting up an <strong>https</strong> site also generally
requires a domain name, but
we are not doing that here.
So if there are any problems accessing your
site in the browser,
be sure to check that the URL starts off with <strong>http</strong>.</p>
<h2 id="conclusion-13"><a class="header" href="#conclusion-13">Conclusion</a></h2>
<p>Congrats on setting up your WordPress library site.
It's now time to explore and build a website.
Use free themes and free plugins to alter
the look of the site, its usability, and
its functionality.
Try to create a nice looking website.
Generally, your goal for the next week
is to create an attractive, yet fictional,
<em>front entrance</em> for a library website.
It's also a break from the command line!</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="install-omeka"><a class="header" href="#install-omeka">Install Omeka</a></h1>
<p><a href="https://omeka.org/">Omeka</a> is an
&quot;Open-source web publishing platforms for sharing
digital collections and creating media-rich online exhibits.&quot;
Most if not all of you have already used Omeka
in a prior course.
Here our task is not to learn information/knowledge organization,
per se,
but to learn how to administer the Omeka digital library platform.</p>
<h2 id="the-task"><a class="header" href="#the-task">The Task</a></h2>
<p>So far we have created our own bare bones OPAC/ILS
and we have downloaded, installed, and configured
WordPress on our servers.
We will use the same basic process to download,
install, and configure Omeka.</p>
<p>However, instead of providing comprehensive instructions,
your goal is to take what you learned from the
bare bones OPAC/ILS and WordPress assignments,
and apply them to the Omeka installation and setup.
Below are some additional <strong>prerequisites</strong> that you
should complete first.
After you've completed them,
move on to the <strong>General Steps</strong> section to
remind yourself of the overall process.</p>
<p>You can do it!
Be sure to ask and discuss on our chat server.</p>
<h2 id="prerequisites"><a class="header" href="#prerequisites">Prerequisites</a></h2>
<p>When we installed WordPress,
we installed most of the prerequisites
that Omeka needs, but
there are a couple of additional things we need to do.</p>
<p>Some prerequisites:</p>
<ul>
<li>Install ImageMagick: this is a suite of utilities to work with photo files.
It's used by Omeka to create thumbnail images of any photo uploaded to the
digital library. See <a href="https://imagemagick.org/index.php">Imagemagick</a> for more information.</li>
</ul>
<pre><code>sudo apt install imagemagick
</code></pre>
<ul>
<li>Enable Apache <code>mod_rewrite</code>. This is an Apache module used to rewrite URLs.
Omeka uses this to create appropriate URLs for items and collections in its
digital libraries.</li>
</ul>
<pre><code>sudo a2enmod rewrite
</code></pre>
<p>You should be instructed to restart Apache after enabling <strong>rewrite</strong>:</p>
<pre><code>sudo systemctl restart apache2
</code></pre>
<h2 id="general-steps"><a class="header" href="#general-steps">General Steps</a></h2>
<p>You have already completed all the steps below when you
created a bare bones OPAC/ILS and installed WordPress.
Your task is to apply what you've learned by completing
an Omeka installation on your own.
(You can work together and discuss on our chat server.)</p>
<p><strong>Note</strong> that the process is very similar to what we have
already done with our bare bones OPAC/ILS and
our WordPress installations.
Use this handbook to remind
you of the specific commands.
In short, you are going to complete the following steps:</p>
<ul>
<li>Create a new user and a new database in MySQL for the
Omeka installation (do not re-use the WordPress database,
user, or credentials).</li>
<li>Use <code>wget</code> from your server to download Omeka Classic as a
Zip file and extract it in <code>/var/www/html</code>:
<ul>
<li>https://github.com/omeka/Omeka/releases/download/v3.1/omeka-3.1.zip</li>
<li>unzip it with the <code>unzip</code> command, which you will have
to install with the <code>apt</code> command.</li>
<li>the extracted directory will be named <strong>omeka-3.1</strong>.
You might want to <strong>rename</strong> it simply <strong>omeka</strong>.</li>
</ul>
</li>
<li>In the extracted directory, find the <strong>db.ini</strong> file and
add your database credentials, and replace all values
containing <strong>XXXXXX</strong>, with the appropriate information.
This is the same thing we did with the <strong>login.php</strong> file
for our bare bones OPAC/ILS and the <strong>wp-config.php</strong> file
for WordPress.</li>
<li>Use the <code>chown</code> command like we did with WordPress on the
<code>files</code> directory in the <code>omeka</code> directory. The user and
owner should again be <strong>www-data</strong>.</li>
<li>Restart Apache2 and MySQL</li>
<li>In your web browser, go to
<strong>http://your-ip-address/omeka/</strong> and complete the setup
via the web form, just like you did with WordPress.</li>
</ul>
<h2 id="helpful-links"><a class="header" href="#helpful-links">Helpful Links</a></h2>
<p>The user manual below is helpful, but
it does not provide explicit instructions.</p>
<p>Be sure to download <strong>Omeka Classic</strong> and not <strong>Omeka S</strong>.</p>
<ul>
<li>Omeka: <a href="https://omeka.org/">https://omeka.org/</a></li>
<li>Omeka Classic: <a href="https://omeka.org/classic/">https://omeka.org/classic/</a></li>
<li>Omeka Classic User Manual: <a href="%5Bhttps://omeka.org/classic/docs/%5D">https://omeka.org/classic/docs/</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="installing-an-ils"><a class="header" href="#installing-an-ils">Installing an ILS</a></h1>
<p>In the last section,
we built a WordPress site that functions as
our library's front-facing presence, and
then we built an Omeka site that could serve as
our library's digital library.
In this section,
we complete our infrastructure building by installing
the <a href="https://koha-community.org/">Koha ILS</a>.</p>
<p>Koha is a free and open source library system that
provides modules for patron accounts, circulation,
cataloging, serials, an OPAC, and more.
The process of installing and using Koha is more
complicated than the processes we used to installing
and using WordPress and Omeka.
This is because Koha,
like other ILS software,
is a complex project that must provide a lot of different
functionality for a library and its patrons.
Fortunately, the documentation makes the process pretty
straightforward.
We will rely on that documentation and other resources
to install Koha and complete our library's interconnected web presence.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="install-the-koha-ils"><a class="header" href="#install-the-koha-ils">Install the Koha ILS</a></h1>
<h2 id="koha-ils"><a class="header" href="#koha-ils">Koha ILS</a></h2>
<p><a href="https://koha-community.org/">Koha</a> is an open source
&quot;library management system&quot;,
otherwise called an integrated library system (ILS).
These kinds of systems provide modules
that perform specific kinds of functionality.
Koha's modules include:</p>
<ul>
<li>Administration</li>
<li>Patron management</li>
<li>Cash management</li>
<li>Circulation</li>
<li>Cataloging</li>
<li>Course reserves</li>
<li>Serials</li>
<li>Acquisitions</li>
<li>Reports</li>
<li>OPAC</li>
</ul>
<p>According to <a href="https://librarytechnology.org/product/koha">Library Technology Guides</a>,
Koha is installed in
&quot;4,040 libraries [around the world],
spanning 5,677 facilities or branches&quot;.
Most installations are in medium sized
or small libraries.
Koha is well represented in academic libraries,
but the majority of installations are in public libraries.</p>
<p>Although Koha is an open source ILS and
free to download, install, and administer
without external support,
librarians can hire companies that support
open source library management solutions, like 
<a href="https://bywatersolutions.com/">ByWater Solutions</a> or
the <a href="https://www.equinoxoli.org/">Equinox Open Library Initiative</a>
These companies support ILS migration,
hosting, training, and more.
They also provide support for
other library software services, such as
open source discovery systems and
electronic resource management systems.</p>
<p>In addition to Koha,
<a href="https://evergreen-ils.org/">Evergreen</a>
is also an open source integrated library system.
According to <a href="https://librarytechnology.org/product/evergreen-equinox">Library Technology Guides</a>,
Evergreen is primarily installed at small and medium
size public libraries, and
most installations are in the U.S. and Canada.</p>
<p>There is currently a migration to what has been
called <em>library service platforms (LSP)</em> in recent years.
The LSP is a next generation ILS that is designed
from the start to integrate electronic resources.
For example, the ILS has an OPAC which was designed
to search a library's print collections.
Modern OPACs have been adapted for
electronic resources,
but they are still limited because of the older design model.
LSPs use a <em>discovery service</em> instead of an OPAC.
Discovery services are designed to search a
library's entire collection,
including the content in third party databases
and journals.
Example LSPs include
Ex Libris Primo (used by UK Libraries),
OCLC's WorldCat Discovery Service,
and open source solutions
like <a href="https://bywatersolutions.com/products/aspen-discovery">Aspen Discovery</a> and <a href="https://vufind.org/vufind/">VuFind</a>.</p>
<p>It is probably unnecessary to state that
integration of library systems like the ILS
and the LSP is a major part of modern libraries.
When we visit a library's website,
we will first interact with a normal website that
might be built on WordPress, <a href="https://www.drupal.org/">Drupal</a>,
or some other content management system.
But these websites will link to the public
facing components of an ILS or LSP,
as well as other services, such
as bibliographic database, journal publishers,
ebook services, and more.
It may therefore be the systems librarians
job to help build and connect these services.
In this demo,
we will continue that work by installing,
configuring, and setting up the Koha ILS.</p>
<h2 id="google-cloud-setup"><a class="header" href="#google-cloud-setup">Google Cloud Setup</a></h2>
<p>Before we begin to install Koha,
we need to create a new virtual machine instance
and configure the Google firewall to allow HTTP
traffic to our Koha install.</p>
<h3 id="new-virtual-instance"><a class="header" href="#new-virtual-instance">New Virtual Instance</a></h3>
<p>The virtual instance we have been using does not meet
the memory (RAM) needs required by the
Koha integrated library system.
We therefore need to create a new virtual instance
that has more RAM.
As a refresher,
see the section titled <strong>gcloud VM Instance</strong> at
<a href="05-using-gcloud-virtual-machines.html">Using gcloud Virtual Machines</a>.
However, we will modify the <strong>Series</strong> to <strong>E2</strong>
and set the <strong>Machine Type</strong> to <strong>2 vCPU, 4 GB memory</strong>.
All else,
including the operating system (Ubuntu 20.04),
should remain the same.
Note that this is a more expensive setup.
Therefore, feel free to delete this instance
at the end of the semester.</p>
<h3 id="google-cloud-firewall"><a class="header" href="#google-cloud-firewall">Google Cloud firewall</a></h3>
<p>Later, after we install Koha,
we will need to access the staff interface
on a special HTTP port.
HTTP (i.e., web) traffic is delivered through
what are called <strong>ports</strong>.
The default port for HTTP is 80, and
the default port for HTTPS is 443.
Since we do not have encryption enabled,
this means that the Apache2 web server
listens on port 80 by default for all web traffic.
Firewalls are used to control incoming and
outcoming traffic via ports.
When we selected <strong>Allow HTTP traffic</strong> when
we created our virtual instance,
we instructed the Google Console firewall
to allow traffic through port 80.
We need to add a firewall rule to allow
web traffic through port 8080.
We will use port 8080 to access
the Koha staff interface.</p>
<blockquote>
<p>Please take a moment to read more about ports: <a href="https://www.cloudflare.com/learning/network-layer/what-is-a-computer-port/">What is a
computer port? | Ports in networking</a>.</p>
</blockquote>
<p>To create a firewall rule to allow traffic
to port 8080,
go to the Google Cloud Console:</p>
<ul>
<li>Click on the <em>hamburger</em> ☰ icon at the top left.</li>
<li>Click on <strong>VPN Network</strong></li>
<li>Click on <strong>Firewall</strong></li>
<li>At the top of the page, choose <strong>Create a firewall rule</strong>
(do not choose <strong>Create a firewall policy</strong>)
<ul>
<li>Add name: <strong>koha</strong></li>
<li>Add description: <strong>open port 8080</strong></li>
</ul>
</li>
<li>Next to <strong>Targets</strong>, click on <strong>All instances in the
network</strong></li>
<li>In the <strong>Source IPv4 ranges</strong>, add <strong>0.0.0.0/0</strong></li>
<li>Click on <strong>Specified protocols and ports</strong>
<ul>
<li>Click on TCP</li>
<li>Add <strong>8080</strong> in the <strong>Ports</strong> box</li>
</ul>
</li>
<li>Click on <strong>Create</strong></li>
</ul>
<h2 id="install-koha-repo"><a class="header" href="#install-koha-repo">Install Koha Repo</a></h2>
<h3 id="server-setup"><a class="header" href="#server-setup">Server setup</a></h3>
<p>Now let's log onto our new server and prepare
it for the Koha installation.</p>
<p>First we need to update our local repositories:</p>
<pre><code>sudo apt update
</code></pre>
<p>And then upgrade our servers:</p>
<pre><code>sudo apt upgrade
</code></pre>
<p>The next two commands help save disk space.
The <code>apt autoremove</code> command &quot;is used
to remove packages that were automatically
installed to satisfy dependencies for other
packages and are now no longer needed
as dependencies changed or the package(s)
needing them were removed in the meantime&quot;
(see <code>man apt</code>).
The <code>apt clean</code> command 
&quot;clears out the local repository
of retrieved package files&quot; (see <code>man apt-get</code>).
In the following example,
I combine both commands on one line:</p>
<pre><code>sudo apt autoremove -y &amp;&amp; sudo apt clean
</code></pre>
<p>Next we need to install <strong>gnupg2</strong>,
which is used to create digital signatures,
encrypt data, and aid in secure communication.</p>
<pre><code>sudo apt install gnupg2
</code></pre>
<p>At the time of this demo,
the update above downloaded a new Linux kernel.
Using the new kernel requires a reboot.
The reboot command will disconnect
you from the server.
Just wait a minute or so and then re-connect.</p>
<pre><code>sudo reboot now
</code></pre>
<h3 id="add-koha-repository"><a class="header" href="#add-koha-repository">Add Koha Repository</a></h3>
<p>When you run the <code>sudo apt update</code> command,
Ubuntu syncs the local repository database with
several remote repositories.
These remote repositories contain metadata about the
packages they contain.
The syncing process identifies if any new software
updates are available.
The remote repositories are also used to retrieve software.</p>
<p>We can add repositories to sync with and
to use to download software, and
this includes the Koha ILS.
To add the special Koha repository to
our system,
we use the following command:</p>
<blockquote>
<p>Most of the following commands require administrator
access. Therefore, I will login as the <strong>root</strong> user to
make it a bit easier. If you do not log in as the root
user, be sure to use the <code>sudo</code> command.</p>
</blockquote>
<pre><code>sudo su
</code></pre>
<p>Add the Koha repository to our server:</p>
<pre><code>echo 'deb http://debian.koha-community.org/koha stable main' | sudo tee /etc/apt/sources.list.d/koha.list
</code></pre>
<p>We then add the digital signature that verifies the above repo:</p>
<!-- use for Ubuntu 22.04 or later 
```
wget -qO - https://debian.koha-community.org/koha/gpg.asc | gpg --dearmor -o /usr/share/keyrings/koha-keyring.gpg
```
-->
<pre><code>wget -q -O- https://debian.koha-community.org/koha/gpg.asc | sudo apt-key add -
</code></pre>
<h2 id="install-koha"><a class="header" href="#install-koha">Install Koha</a></h2>
<p>Next we need to update/sync the new repository
with the Koha remote repository.
This just means that we use <code>apt update</code> again.</p>
<pre><code>apt update
</code></pre>
<p>Now we view the package information for Koha:</p>
<pre><code>apt show koha-common
</code></pre>
<p>And install it:</p>
<pre><code>apt install koha-common
</code></pre>
<p>The above command will download and install
a lot of additional software, and
therefore the process will take several minutes.</p>
<h3 id="configure-koha"><a class="header" href="#configure-koha">Configure Koha</a></h3>
<p>Next we need to edit some configuration
files for Koha:</p>
<pre><code>nano /etc/koha/koha-sites.conf
</code></pre>
<p>In the above <strong>koha-sites.conf</strong> file,
change the line that contains 
the following information:</p>
<pre><code>INTRAPORT=&quot;80&quot;
</code></pre>
<p>To:</p>
<pre><code>INTRAPORT=&quot;8080&quot;
</code></pre>
<p>Next install and setup <strong>mysql-server</strong>:</p>
<pre><code>apt install mysql-server
</code></pre>
<p>Next we set the root MySQL password:</p>
<pre><code>mysqladmin -u root password bibliolib1
</code></pre>
<p>When we installed Koha,
the Apache2 web server was installed 
with it as a prerequisite.
We need to enable URL rewriting and
<a href="https://en.wikipedia.org/wiki/Common_Gateway_Interface">CGI</a> functionality.</p>
<pre><code>a2enmod rewrite
a2enmod cgi 
</code></pre>
<p>Now we need to restart Apache2 in the normal way:</p>
<pre><code>systemctl restart apache2
</code></pre>
<p>Next we create a database for Koha:</p>
<pre><code>koha-create --create-db bibliolib
</code></pre>
<p>We need to tell Apache2 to listen on port 8080:</p>
<pre><code>nano /etc/apache2/ports.conf 
</code></pre>
<p>And add:</p>
<pre><code>Listen 8080
</code></pre>
<p>Make sure Apache configuration changes are valid:</p>
<pre><code>apachectl configtest
</code></pre>
<p>If you get an error message,
trace the error in the file and line listed.</p>
<p>Let's restart Apache2.</p>
<pre><code>systemctl restart apache2
</code></pre>
<p>We'll disable the default Apache2 setup,
enable traffic compression using <strong>deflate</strong>,
enable the <strong>bibliolib</strong> site,
and then reload Apache2's configurations and
restart again:</p>
<pre><code>a2dissite 000-default
a2enmod deflate
a2ensite bibliolib
systemctl reload apache2
systemctl restart apache2
</code></pre>
<h3 id="koha-web-installer"><a class="header" href="#koha-web-installer">Koha Web Installer</a></h3>
<p>All the backend work is complete, and
like we did with WordPress and Omeka,
we can complete the installation through
a web installer.</p>
<p>First, get Koha username and password in the following file:</p>
<pre><code>nano /etc/koha/sites/bibliolib/koha-conf.xml
</code></pre>
<p>Look for the <code>&lt;config&gt;</code> stanza (line number 252) and the
line beginning with <code>&lt;user&gt;</code> (line number 257).
The password is on the line after (line number 258).</p>
<p>Make sure your URL begins with <em>http</em>* and not <strong>https</strong>,
and visit the web installer at:</p>
<pre><code>http://IP-ADDRESS:8080
</code></pre>
<p>The documentation for the web installer is helpful.
One thing to do is to add sample libraries and sample patrons.
More generally, be sure to follow instructions as you
click through each step.</p>
<p><a href="https://koha-community.org/manual//22.11/en/html/installation.html">Introduction to the Koha installation process</a></p>
<h2 id="public-opac"><a class="header" href="#public-opac">Public OPAC</a></h2>
<p>When the install and setup are complete,
you will have access to the staff interface.
To view the public facing OPAC,
you need to make a setting change.</p>
<ul>
<li>Click on <strong>More</strong> in the top drop down box</li>
<li>Click on <strong>Administration</strong></li>
<li>Click on <strong>Global System Preferences</strong></li>
<li>Click on <strong>OPAC</strong> in the left hand side bar</li>
<li>Scroll down to the <strong>OPACBaseURL</strong> line.</li>
<li>Enter the IP address of your server: <strong>http://IP-ADDRESS</strong></li>
<li>Click on <strong>Save all OPAC Preferences</strong></li>
</ul>
<p>Once you save these preferences,
you should be able to visit your public facing
OPAC at the server IP address.</p>
<h2 id="additional-tasks"><a class="header" href="#additional-tasks">Additional Tasks</a></h2>
<p>Once you've installed and setup Koha,
begin to learn the system.
Some example tasks:</p>
<ul>
<li>Create patron accounts</li>
<li>Create bibliographic records</li>
<li>Check out books to patrons</li>
<li>Delete patron circulation history</li>
</ul>
<h2 id="conclusion-14"><a class="header" href="#conclusion-14">Conclusion</a></h2>
<p>In this final section,
you learned how to install
and setup a Koha ILS installation
on a Linux server.</p>
<h2 id="references-2"><a class="header" href="#references-2">References</a></h2>
<p>Helpful documentation and demos:</p>
<ul>
<li><a href="https://koha-community.org/">Koha ILS</a> documentation.</li>
<li><a href="https://wiki.koha-community.org/wiki/Koha_on_Debian">Koha on Debian</a></li>
<li><a href="https://www.youtube.com/watch?v=mzUop9R4sKc">Install Koha on Google Cloud Platform</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="conclusion-15"><a class="header" href="#conclusion-15">Conclusion</a></h1>
<h2 id="accomplishments"><a class="header" href="#accomplishments">Accomplishments</a></h2>
<p>In this course, we learned how to:</p>
<ul>
<li>work with the Google Cloud console</li>
<li>install and setup a new Ubuntu Linux server</li>
<li>use the Linux command line</li>
<li>use a command line text editor</li>
<li>search text</li>
<li>install and manage software</li>
<li>use Git and GitHub</li>
<li>build a LAMP server</li>
<li>create a barebones integrated library system</li>
<li>install and configure WordPress, Omeka, and Koha
sites</li>
<li>connect these sites to create a full library web
presence</li>
</ul>
<p>In order to avoid continued billing,
be sure to stop and delete
all virtual machines in your project.</p>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->


                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">

            </nav>

        </div>




        <script>
            window.playground_copyable = true;
        </script>


        <script src="elasticlunr.min.js"></script>
        <script src="mark.min.js"></script>
        <script src="searcher.js"></script>

        <script src="clipboard.min.js"></script>
        <script src="highlight.js"></script>
        <script src="book.js"></script>

        <!-- Custom JS scripts -->

        <script>
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>

    </div>
    </body>
</html>
